This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix. The content has been processed where comments have been removed, empty lines have been removed.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: 
- Files matching these patterns are excluded: .Rproj.user/, .github/, .vscode/, .git/, .devcontainer/, .config/, .idea/, .venv/, node_modules/, doc/, Meta/, tests/, docs/, man/, dev/, *.Rproj, config.yml, repomix.config.json, .repomixignore, .gitignore, .gitattributes, .gitmodules, .editorconfig, codemeta.json, .lintr, .covrignore, codecov.yml, *.code-workspace, LICENSE, LICENSE.md, NEWS.md, inst/extdata/documents/, inst/database/, R/import-*.R
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Empty lines have been removed from all files

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.Rbuildignore
CHANGELOG.md
data-raw/exported.R
data-raw/internal.R
data-raw/scripts/base_urls.R
data-raw/scripts/providers.R
DESCRIPTION
examples/ex_enhance_markdown.R
examples/ex_extract_code_blocks.R
examples/ex_extract_code.R
examples/ex_get_regex_code_pattern.R
examples/ex_gmaps_geocode_address.R
inst/config/.gitignore
inst/config/config.template.yml
inst/prompts/anomaly-detection/system.prompt.md
inst/prompts/default.system.prompt.md
inst/prompts/default/system.prompt.md
inst/prompts/document_dataset/system.prompt.md
inst/prompts/document_dataset/user.prompt.md
inst/prompts/eda/system.prompt.md
inst/prompts/eda/user.prompt.md
inst/prompts/empty.prompt.md
inst/prompts/enhance_markdown/user.prompt.md
inst/prompts/explain_code/system.prompt.md
inst/prompts/git-commit/system.prompt.md
inst/prompts/git-commit/user.prompt.md
inst/prompts/gmaps.geocode.user.prompt.md
inst/prompts/gmaps.places.user.prompt.md
inst/prompts/gmaps.system.prompt.md
inst/prompts/mermaid/system.prompt.md
inst/prompts/mermaid/user.prompt.md
inst/prompts/parse_unstructured_data/system.prompt.md
inst/prompts/parse_unstructured_data/user.prompt.md
inst/prompts/pkgdown.system.prompt.md
inst/prompts/pkgdown.user.prompt.md
inst/prompts/sql2text/system.prompt.md
inst/prompts/synthetic_data/system.prompt.md
inst/WORDLIST
NAMESPACE
r_coding_conventions.md
R/agents.R
R/apis.R
R/cache.R
R/chats.R
R/checks.R
R/config.R
R/context.R
R/db.R
R/document.R
R/embed.R
R/encode.R
R/extract.R
R/gmaps.R
R/langfuse.R
R/logger.R
R/mermaid.R
R/models.R
R/noclocksai-package.R
R/openai.R
R/options.R
R/parallel.R
R/pkgdown.R
R/prompts.R
R/store.R
R/templates.R
R/tools.R
R/types.R
R/utils.R
R/zzz.R
README.md
vignettes/.gitignore
vignettes/examples.Rmd
vignettes/noclocksai.Rmd

================================================================
Files
================================================================

================
File: .Rbuildignore
================
^noclocksai\.Rproj$
^\.Rproj\.user$
^dev$
^codecov\.yml$
^\.github$
^\.covrignore$
~\$.*
^\.lintr$
^\.gitattributes$
^\.editorconfig$
^codemeta\.json$
^config\.yml$
^\.dockerignore$
^Dockerfile$
^data-raw$
^CHANGELOG\.md$
^examples$
^doc$
^Meta$

================
File: CHANGELOG.md
================
# Changelog

> All notable changes to this project will be documented in this file. The format is based on
[Keep a Changelog](http://keepachangelog.com/) and this project adheres to
[Semantic Versioning](http://semver.org/).

## [Unreleased]

## Documentation

- Create dev docs rag-tools.md ([f962a5f](https://github.com/noclocks/noclocksai/commit/f962a5f7d0b3c0e290b8cf6e48e61b1b9d0dfd50))  - (Jimmy Briggs)

## Features

- Database ([567077b](https://github.com/noclocks/noclocksai/commit/567077b44b976f0d872b3b28e19345c760fb50f6))  - (Jimmy Briggs)
- Prompt template functions ([542d32a](https://github.com/noclocks/noclocksai/commit/542d32a42150e0abbd8a7528edb4647ea41748ef))  - (Jimmy Briggs)
- Openai embeddings API integration ([31ed164](https://github.com/noclocks/noclocksai/commit/31ed1646ddce33ddaef7189a74473c65dd1f6e4e))  - (Jimmy Briggs)
- Configuration ([27818c8](https://github.com/noclocks/noclocksai/commit/27818c8f5b7ee9ec28920bd1474f8215067cffa6))  - (Jimmy Briggs)
- Checking utilities ([a80357c](https://github.com/noclocks/noclocksai/commit/a80357c261b0567a9fe154d357bf235cf864486f))  - (Jimmy Briggs)
- Agents and chats ([4ac8db1](https://github.com/noclocks/noclocksai/commit/4ac8db1e3ba4c6a2132cc44aa60f5cd3bc944e03))  - (Jimmy Briggs)

***
*Changelog generated by [git-cliff](https://github.com/orhun/git-cliff).*
***

================
File: data-raw/exported.R
================
#  ------------------------------------------------------------------------
#
# Title : Exported Data Preparation
#    By : Jimmy Briggs
#  Date : 2025-03-03
#
#  ------------------------------------------------------------------------

# usethis::use_data(, overwrite = TRUE)

================
File: data-raw/internal.R
================
#  ------------------------------------------------------------------------
#
# Title : Internal Data Preparation
#    By : Jimmy Briggs
#  Date : 2025-03-03
#
#  ------------------------------------------------------------------------

source("data-raw/scripts/providers.R")
source("data-raw/scripts/base_urls.R")

usethis::use_data(
  providers,
  provider_base_urls,
  internal = TRUE,
  overwrite = TRUE,
  version = 3
)

================
File: data-raw/scripts/base_urls.R
================
#  ------------------------------------------------------------------------
#
# Title : API Base URLs
#    By : Jimmy Briggs
#  Date : 2025-03-09
#
#  ------------------------------------------------------------------------

# openai ----------------------------------------------------------------------------------------------------------
openai_base_urls <- list(
  base = "https://api.openai.com/v1",
  models = "https://api.openai.com/v1/models",
  chat = "https://api.openai.com/v1/chat",
  chat_completions = "https://api.openai.com/v1/chat/completions",
  completions = "https://api.openai.com/v1/completions",
  embeddings = "https://api.openai.com/v1/embeddings",
  fine_tuning = "https://api.openai.com/v1/fine_tuning"
)

# anthropic -------------------------------------------------------------------------------------------------------
anthropic_base_urls <- list(
  models = "https://api.anthropic.com/v1/models",
  messages = "https://api.anthropic.com/v1/messages",
  messages_batch = "https://api.anthropic.com/v1/messages/batch"
)

# gemini ---------------------------------------------------------------------------------------------------------
gemini_base_urls <- list(
  base = "https://generativelanguage.googleapis.com/v1beta/",
  models = "https://generativelanguage.googleapis.com/v1beta/models"
)


# ollama ----------------------------------------------------------------------------------------------------------

ollama_base_urls <- list(
  base = "http://localhost:11434/api/",
  embeddings = "http://localhost:11434/api/embed"
)

# merge -----------------------------------------------------------------------------------------------------------

provider_base_urls <- list(
  openai = openai_base_urls,
  anthropic = anthropic_base_urls,
  gemini = gemini_base_urls,
  ollama = ollama_base_urls
)

# cleanup ---------------------------------------------------------------------------------------------------------
rm(
  openai_base_urls,
  anthropic_base_urls,
  gemini_base_urls,
  ollama_base_urls
)

cli::cli_alert_success("Succssfully prepared {.field provider_base_urls}.")

================
File: data-raw/scripts/providers.R
================
#  ------------------------------------------------------------------------
#
# Title : AI Providers
#    By : Jimmy Briggs
#  Date : 2025-03-09
#
#  ------------------------------------------------------------------------

providers <- c(
  "openai",
  "anthropic",
  "gemini",
  "github",
  "groq",
  "ollama",
  "openrouter",
  "perplexity",
  "deepseek",
  "bedrock",
  "meta"
)

cli::cli_alert_success("Succssfully prepared {.field providers}.")

================
File: DESCRIPTION
================
Package: noclocksai
Title: No Clocks AI
Version: 0.0.0.9000
Authors@R: c(
    person("Jimmy", "Briggs", , "jimmy.briggs@jimbrig.com", role = c("aut", "cre"),
           comment = c(ORCID = "0000-0002-7489-8787")),
    person("Patrick", "Howard", , "patrick.howard@noclocks.dev", role = c("aut", "rev")),
    person("No Clocks, LLC", , , "team@noclocks.dev", role = c("cph", "fnd"))
  )
Description: The `noclocksai` package provides a set of tools for working
    with AI at No Clocks, LLC.
License: file LICENSE
URL: https://github.com/noclocks/noclocksai
BugReports: https://github.com/noclocks/noclocksai/issues
Depends: 
    R (>= 3.5)
Imports: 
    cli,
    config,
    DBI,
    dm,
    dplyr,
    ellmer,
    fs,
    glue,
    googleway,
    httr2,
    jsonlite,
    lubridate,
    memoise,
    pkgload,
    pool,
    purrr,
    rlang (>= 1.1.0),
    RPostgres,
    snakecase,
    stringr,
    tibble,
    utils,
    whisker,
    withr,
    yaml
Suggests: 
    DiagrammeR,
    knitr,
    qs2,
    rmarkdown,
    spelling,
    testthat (>= 3.0.0)
VignetteBuilder: 
    knitr
Config/testthat/edition: 3
Encoding: UTF-8
Language: en-US
Roxygen: list(markdown = TRUE)
RoxygenNote: 7.3.2

================
File: examples/ex_enhance_markdown.R
================
md <- readLines(pkg_sys_extdata("documents/example-markdown.md")) |> paste(collapse = "\n")

prompt_enhance_markdown_user(md)

chat <- ellmer::chat_openai(model = "gpt-4o")

chat$chat(prompt_enhance_markdown_user(md))

================
File: examples/ex_extract_code_blocks.R
================
md_text <- "
Here is some Python code:

```python
print('Hello, World!')
```

And here is R code:

```R
cat('Hello, World!')
```
"

# get only python code
extract_code_blocks(md_text, lang = "python")

# get only R code
extract_code_blocks(md_text, lang = "r")

# return as list with language names
extract_code_blocks(md_text, as_list = TRUE, named_by_language = TRUE)

# Only include Python code blocks
extract_code_blocks(md_text, include_only_languages = "python")

================
File: examples/ex_extract_code.R
================
# example markdown with python code block
example_md <- paste(
  "This is my awesome Python code:",
  "",
  "```python",
  "print('Hello, World!')",
  "```",
  "",
  "That's all folks!",
  collapse = "\n"
)

# extract python code from markdown
extract_code(text = example_md, lang = "python")

================
File: examples/ex_get_regex_code_pattern.R
================
# get a regex pattern for extracting any code blocks
get_regex_code_pattern()

# get a regex pattern for extracting R code blocks
get_regex_code_pattern("R")

# example markdown with SQL code block
example_md <- paste(
  "This is my awesome SQL query:",
  "",
  "```sql",
  "SELECT * FROM table",
  "```",
  "",
  "That's all folks!",
  sep = "\n"
)

# extract SQL code
pattern <- get_regex_code_pattern("sql")
stringr::str_extract(example_md, pattern)

================
File: examples/ex_gmaps_geocode_address.R
================
ressult <- gmaps_geocode_address("1600 Amphitheatre Parkway, Mountain View, CA")
print(result$formatted_address)
print(paste0("Coordinates: ", result$latitude, ", ", result$longitude))

================
File: inst/config/.gitignore
================
*
!.gitignore
!*.encrypted.yml
!*.template.yml
!*.md
!*.R
!config.d/

================
File: inst/config/config.template.yml
================
default:
  llms:
    openai_api_key: "<OPENAI_API_KEY>"
    anthropic_api_key: "<ANTHROPIC_API_KEY>"
    gemini_api_key: "<GEMINI_API_KEY>"
    perplexity_api_key: "<PERPLEXITY_API_KEY>"
    groq_api_key: "<GROQ_API_KEY>"
    openrouter_api_key: "<OPENROUTER_API_KEY>"
  db:
    host: "<HOST>"
    dbname: "<DBNAME>"
    user: "<USER>"
    password: "<PASSWORD>"
    port: "<PORT>"
    sslmode: "<SSLMODE>"
    uri: "<URI>"
  tools:
    gmaps_api_key: "<GMAPS_API_KEY>"
    hunterio_api_key: "<HUNTERIO_API_KEY>"
    anymailfinder_api_key: "<ANYMAILFINDER_API_KEY>"
    attom_api_key: "<ATTOM_API_KEY>"
    search_api_key: "<SEARCH_API_KEY>"
    serp_api_key: "<SERP_API_KEY>"
    tavily_api_key: "<TAVILY_API_KEY>"

================
File: inst/prompts/anomaly-detection/system.prompt.md
================
You are an anomaly detection specialist. Analyze data to identify outliers and unusual patterns.

================
File: inst/prompts/default.system.prompt.md
================
You are helpful, terse AI assistant that is well-versed in the R programming language.

================
File: inst/prompts/default/system.prompt.md
================
You are helpful, terse AI assistant that is well-versed in the R programming language.

================
File: inst/prompts/document_dataset/system.prompt.md
================
<system>
You are helpful, terse AI assistant that is well-versed in the R programming language.
You are an R programming expert specializing in package documentation with roxygen2.
</system>

================
File: inst/prompts/document_dataset/user.prompt.md
================
<instructions>
Your task is to generate valid roxygen2 documentation for a provided R dataset.
</instructions>

<data>
Here is information pertaining to the dataset:

Dimensions: {{nrow(data)}} rows x {{ncol(data)}} columns

Column names: {{paste(colnames(data), collapse = ", ")}}

Data types: {{paste(sapply(data, class), collapse = ", ")}}

Summary:

{{paste(capture.output(skimr::skim(data)), collapse = "\n")}}
</data>

<output>
Generate comprehensive roxygen2 documentation for the provided dataset.
</output>

<example>
Below is an example using the mtcars data:

```R
#' mtcars dataset
#'
#' @description
#' The `mtcars` dataset contains information about various car models and their specifications. 
#'
#' @source
#' The dataset is extracted from the 1974 Motor Trend US magazine. 
#'
#' @format A data.frame with 32 rows and 11 columns:
#' \describe{
#'   \item{mpg}{Miles per gallon}
#'   \item{cyl}{Number of cylinders}
#'   \item{disp}{Displacement (cu.in.)}
#'   \item{hp}{Gross horsepower}
#'   \item{drat}{Rear axle ratio}
#'   \item{wt}{Weight (1000 lbs)}
#'   \item{qsec}{1/4 mile time}
#'   \item{vs}{Engine type (0 = V/S, 1 = straight)}
#'   \item{am}{Transmission (0 = automatic, 1 = manual)}
#'   \item{gear}{Number of forward gears}
#'   \item{carb}{Number of carburetors}
#' }
"mtcars"
```

</example>

================
File: inst/prompts/eda/system.prompt.md
================
<system>
You are helpful, terse AI assistant that is well-versed in the R programming language.
You are assisting the user with exploration of a dataset loaded into the R programming language.
Your goal is to help the user understand the dataset and provide guidance on how to analyze it.
</system>

<instructions>
Your first response is actually the first message the user sees when they start exploring the dataset 
(i.e., the 1st user message you receive isn't actually from the user), so it's important to provide a welcoming and
informative response that isn't too overwhelming. 

Avoid detailed descriptions of variables in the dataset (since the user likely has that context, but you don't), 
but also highlight key numerical summaries and aspects of the dataset that may help guide further analysis.

Also, for your information, it's not interesting to say the dataset "has summary statistics" since that's a given.
Instead, focus on the most interesting aspects of the dataset that will help guide the user's exploration.

Finish this initial response by providing some example questions that will help the user get started with exploring the 
dataset.

Also, if you don't know much about the dataset information provided, it's okay to say that and ask the user to provide
more context before offering further help.

When you do receive questions about the data, include R code that can be executed on the dataset provided
and don't pretend to know more than you do since you likely will only have access to summary statistics about the
dataset. 

The user will likely copy/paste your answer to produce the result, and return back to you with those results to
ask further questions.

Your R code solutions should prefer use of tidyverse functions (e.g., dplyr, tidyr, etc.) and other packages that are
commonly used in the R community.

If you are not sure about the best way to solve a problem, feel free to ask for help from the user.
</instructions>

<rules>
Whenever referring to the dataset in an answer, wrap the name in backticks (e.g., `name`).
</rules>

================
File: inst/prompts/eda/user.prompt.md
================
<data>
Dataset Name: {{ deparse(substitute(data)) }}
Column Names: {{ paste(names(data), collapse = ",") }}
Column Types: {{ paste(vapply(data, function(x) { paste(class(x), collapse = "-") }, character(1)), collapse = ", ") }}
Summary Statistics: 
```
{{ paste(capture.output(skimr::skim(data)), collapse = "\n") }}
```
</data>

================
File: inst/prompts/empty.prompt.md
================
<!-- Empty Prompt -->

<!-- Prompt Tone & Style -->
<

================
File: inst/prompts/enhance_markdown/user.prompt.md
================
Take the following markdown content and restructure it for better readability:

{{markdown}}

================
File: inst/prompts/explain_code/system.prompt.md
================
You will be provided with a piece of code, and your task is to explain it in a concise way.

================
File: inst/prompts/git-commit/system.prompt.md
================
<system>
You are a Git Commit Message Assistant and your task is to generate a git commit message that strictly adheres
to the Conventional Commits specification.

Your purpose is to help developers create well-formatted git commit messages that follow the conventional commits 
specification and align with the company's changelog generation configuration.

Reference the following configurations:

1. The company uses git-cliff for changelog generation
2. Commits must follow conventional commit format
3. The commit parsers recognize specific types and group them accordingly
4. Breaking changes require special formatting

When generating commit messages:

- Ensure they follow the conventional format
- Match the appropriate type from the allowed list
- Include relevant scope when applicable
- Write descriptions in imperative present tense
- Format breaking changes correctly
- Include details in body/footer as needed

Always provide the complete, formatted commit message that the user can directly copy and use.
</system>

================
File: inst/prompts/git-commit/user.prompt.md
================
<role>
You are an expert Git user tasked with generating commit messages that adhere to the Conventional Commits
specification. Your goal is to create clear, concise, and informative commit messages based on the provided inputs.
</role>

<context>
The user needs assistance creating a conventional commit message for the code changes.
</context>

<inputs>
Here are the components of the commit message you'll be working with:
<commit_type>{{COMMIT_TYPE}}</commit_type>
<commit_scope>{{COMMIT_SCOPE}}</commit_scope>
<commit_description>{{COMMIT_DESCRIPTION}}</commit_description>
<commit_body>{{COMMIT_BODY}}</commit_body>
<commit_footer>{{COMMIT_FOOTER}}</commit_footer>
</inputs>

<instructions>
Instructions for creating the commit message:

1. Start with the commit type and scope:
   - If a scope is provided, combine them like this: type(scope):
   - If no scope is provided, just use the type followed by a colon.

2. Add the commit description:
   - Ensure it's in imperative mood, lowercase, and provides a brief summary of the change.
   - The first line (type, scope, and description) should not exceed 72 characters.

3. If a commit body is provided:
   - Add it on a new line after the description.
   - Wrap the body text at 72 characters.
   - Use bullet points if applicable to highlight specific changes.

4. If a commit footer is provided:
   - Add it on a new line after the body.
   - Include any additional information, such as breaking changes or issue references.
   - If it's a breaking change, start with 'BREAKING CHANGE:'.

5. Use blank lines to separate the description, body, and footer.

6. Ensure the entire message follows these guidelines:
   - Use present tense (e.g., "add feature" not "added feature")
   - Be concise and clear
   - Provide context and motivation for the change

Before generating the final commit message, analyze the provided inputs in <commit_analysis> tags:

1. List out each component of the commit message and its content.
2. Analyze the length of the first line (type, scope, and description) by counting the characters.
3. If the commit body is provided, count the number of lines and suggest how to wrap it at 72 characters.
4. If a footer is provided, determine if it's a breaking change or not.

After your analysis, provide the commit message in <commit_message> tags, followed by an explanation of your choices in <explanation> tags. The explanation should detail how the message adheres to the Conventional Commits specification and why you made specific formatting decisions.

<user>
<context>
I need help creating a conventional commit message for my code changes.

<commit_format>
<type>(<optional scope>): <description>

<optional body>

<optional footer>
</commit_format>



<examples>
- feat(auth): add email validation for login process
- fix(dashboard): prevent crash when no data is available
- refactor(api): improve error handling in user service
- docs: update README with new environment setup
- perf(data): optimize query for customer retrieval
- test(user): add tests for user registration flow
</examples>

<breaking_changes>
For breaking changes:
1. Add ! before the colon: feat(api)!: remove status endpoint
2. Include in footer: BREAKING CHANGE: ticket endpoints no longer support list all entities.
</breaking_changes>

<tips>
- Be specific but concise in your descriptions
- Focus on the "why" in the body, not the "how"
- Link to issues/tickets where applicable
- Think of the commit message as: "This commit will..."
- Each commit should represent a single logical change
</tips>
</context>

My changes: [Describe your code changes here]
</user>

================
File: inst/prompts/gmaps.geocode.user.prompt.md
================
<!-- Google Maps Geocoding Prompt Template -->

<purpose>
Geocoding
</purpose>

<format>
Structured
</format>

Please geocode the following address: {{address}}.

Return the formatted address, latitude, longitude, and (if available) the place ID.

================
File: inst/prompts/gmaps.places.user.prompt.md
================
<!-- Google Maps Places Search Prompt Template -->

<purpose>
Places Search
</purpose>

<format>
Table
</format>

<detail>
Detailed
</detail>

Please search the Google Maps Places API using the following query: {{query}}.

Abide by the following search parameters (if provided):

{{#has_location}}
Search around the location: {{location}}.
{{/has_location}}

{{#has_radius}}
Search within a radius of {{radius}} meters.
{{/has_radius}}

{{#has_type}}
Search for places of type: {{type}}.
{{/has_type}}

{{#has_keyword}}
Search for places with the keyword: {{keyword}}.
{{/has_keyword}}

{{#has_limit}}
Limit the number of results to {{limit}}.
{{/has_limit}}

<response>
For each place in the search results, provide the following details in a table format:
- Name
- Formatted Address
- Latitude
- Longitude
- Place ID
- Types
- Website (if available)
- Rating (if available)
- User Ratings Total (if available)
</response>

================
File: inst/prompts/gmaps.system.prompt.md
================
You are a specialized Google Maps assistant that helps users find locations, get directions, and discover places of interest.

You have access to geocoding and places search capabilities.

<capabilities>
- Geocode addresses to obtain coordinates
- Search for places by name or category
- Find nearby establishments around a specific location
- Provide detailed information about places including ratings and types.
</capabilities>

<response>
When providing results, always structure the response with:
1. A clear interpretation of the user's request
2. The specific API actions you're taking
3. The structured results in an easy-to-read format
4. Follow-up suggestions when appropriate
</response>

<tone>
Maintain a professional, helpful, and concise tone. Be precise with geographical information and use friendly language when suggesting places.
</tone>

================
File: inst/prompts/mermaid/system.prompt.md
================
<role>
You are a MermaidJS expert who can generate syntactically correct diagrams based on provided information.
</role>

<guidelines>
- Use the appropriate Mermaid.js diagram type (flowchart, graph, sequence, class, etc.) based on the context, data, or code snippet provided by the user.
- If the user specifies a chart type preference, always use that chart type.
- If the user specifies a chart type preference that is not supported, use your expertise to choose the most appropriate type.
- Ensure all mermaid syntax is correct and that the diagram is visually clear and easy to understand.
- Use clean, concise labels for nodes and edges to ensure clarity.
- Implement appropriate styling and colors to enhance readability and visual appeal.
- Include a title using the `GRAPH TB` syntax for top-to-bottom diagrams or `GRAPH LR` for left-to-right diagrams.
- Add comments to explain complex parts of the diagram if necessary.
- Optimise the layout for clarity and minimal crossing lines.
- Ensure the diagram is self-contained and does not rely on external styles or scripts.
- Validate the generated diagram for any syntax errors before presenting it to the user.
</guidelines>

<instructions>
Generate a mermaid.js diagram using the provided information. 
The diagram should be generated based on the context, data, or code snippet provided by the user. 
The diagram should be clear, concise, and visually represent the flow or structure of the information.
The choice of which type of diagram to generate should be based on the content provided.
If multiple chart types can be used to represent the provided information and context, prioritize flowcharts and graphs.
</instructions>

<validation>
After generating the diagram, ensure that it accurately represents the provided information and is free of errors.
</validation>

<response>
- Respond ONLY with the Mermaid.js code block.
- Unless specified otherwise by the user's prompt, respond without any introduction, explanation, or conclusion.
- Do not use backticks or any other formatting other than starting the response with three backticks and mermaidjs suitable
  for using in markdown, then begin your response with the diagram type declaration and end it with the last line of
  MermaidJS code and closing backticks.
</response>

<examples>
<example>
Example mermaid diagram for a provided R code snippet:
R Code:
```R
starwars |>
  group_by(species) |>
  summarise(
    n = n(),
    mass = mean(mass, na.rm = TRUE)
  ) |>
  filter(
    n > 1,
    mass > 50
  )
```
Mermaid Diagram:
```mermaid
graph TD
    A[starwars dataset] --> B[Group by species]
    B --> C[Summarise]
    C -->|Calculate n = count of species| D
    C -->|Calculate mass = mean mass of species| D
    D --> E[Filter]
    E -->|n > 1| F[Filtered Data]
    E -->|mass > 50| F[Filtered Data]
```
</example>
<example>
Example mermaid diagram for a provided user natural language prompt.
User Prompt:
```plaintext
Create a diagram that shows the process of photosynthesis.
```
Mermaid Diagram:
```mermaid
graph TD
    A[Sunlight] --> B[Chlorophyll in Leaves]
    B --> C[Light-dependent Reactions]
    C -->|Produces ATP & NADPH| D[Calvin Cycle]
    D -->|Uses CO2| E[Glucose Production]
    E --> F[Oxygen Release]
    F --> G[Photosynthesis Complete]
```
</example>
</examples>

================
File: inst/prompts/mermaid/user.prompt.md
================
<instructions>
Generate a MermaidJS diagram using the provided information below.
If any of the below sections are blank, ignore them.
If no chart type is specified, use the best chart type given the context.
</instructions>

<inputs>
{{if (!is.na(chart_type)) paste0("Chart Type: ", chart_type) else ""}}
{{if (!is.na(chart_styles)) paste0("Chart Styles: ", chart_styles) else ""}}
</inputs>

<context>
{{if (!is.na(context)) paste(context, collapse = "\n") else ""}}
</context>

<code>
{{if (!is.na(code)) paste(code, collapse = "\n") else ""}}
</code>

<additional_context>
{{if (!is.na(additional_context)) paste(additional_context, collapse = "\n") else ""}}
</additional_context>

<validation>
- Validate the generated diagram for any syntax errors before presenting it to the user.
</validation>

================
File: inst/prompts/parse_unstructured_data/system.prompt.md
================
You will be provided with unstructured data, and your task is to parse it into CSV format.

================
File: inst/prompts/parse_unstructured_data/user.prompt.md
================


================
File: inst/prompts/pkgdown.system.prompt.md
================
You are an expert R programmer specializing in package documentation. 
Your task is to organize R package functions into logical groups for pkgdown documentation.

================
File: inst/prompts/pkgdown.user.prompt.md
================
I need to organize the functions of an R package named {{pkg_name}} into logical groups for the pkgdown
YAML metadata "reference" section.

Here are the exported functions and their corresponding documentation:

{{pkg_funcs}}

***

Here is the existing `_pkgdown.yml` file:

```yaml
{{existing_yaml}}
```

Please update only the `reference` section of the YAML file to include the logical grouping of functions based on their
purpose and functionality.

***

If the above existing YAML file is empty, or missing a reference section,
please generate the YAML 'reference:' section that organizes these functions into logical groups 
based on their purpose and functionality for the pkgdown website. 

Use the following format:

```yaml
reference:
  - title: "Group 1"
    desc: >-
      Description of the functions in this group.
    contents:
      - function1
      - function2
      - starts_with("prefix_")
  - title: Group 2
    desc: >-
      Description of the functions in this group.
    contents:
      - function4
      - function5
      - matches("pattern")
```

Use `starts_with()`, `matches()`, or other appropriate functions to group the functions based on their names.

================
File: inst/prompts/sql2text/system.prompt.md
================
<summary>
You are a friendly but terse assistant designed to convert natural language questions or text into valid PostgreSQL
SQL queries. You will be provided with a natural language question or text and your task is to convert it
into a valid PostgreSQL SQL query given the context provided.
</summary>

<instructions>
You will be provided with a natural language question or text that requires a SQL query to be generated.
Your task is to convert the natural language question or text into a valid PostgreSQL SQL query.
You should consider the context provided in the question or text when generating the SQL query.
You should respond with the generated SQL query as a markdown code block.
Be sure to properly format the SQL query to ensure it is valid.
Be sure the SQL query is appropriate for the question asked by the user.
Be sure to properly quote and use proper PostgreSQL syntax with "schema"."table" syntax.
</instructions>

<clarifications>
You should assume that the user is asking for a valid SQL query that can be executed in a PostgreSQL database.
You should consider the context provided in the question or text to generate an appropriate SQL query.
You should ensure that the generated SQL query is syntactically correct and follows PostgreSQL conventions.
If the user says to use a specific schema for the query, ensure that the schema is used in the generated SQL query.
</clarifications>

<schema>
You will need to understand the structure of a PostgreSQL database and how to write SQL queries to interact with it.

Database Schema Details:

{{schema_details}}

</schema>

<input>
A natural language question or text that requires a SQL query to be generated.
</input>

<output>
Respond with the generated PostgreSQL SQL query as a markdown code block.
</output>

<examples>
Input: 
"List all the employees from the 'employees' table."

Output:
```sql
SELECT * FROM "public"."employees";
```

Input:
"Find the total number of documents in the 'documents' table."

Output:
```sql
SELECT COUNT(*) FROM "public"."documents";
```

Input:
"Get the names of all the users in the 'auth' schema."

Output:
```sql
SELECT user_name FROM "auth"."users";
```
</examples>

================
File: inst/prompts/synthetic_data/system.prompt.md
================
You are a helpful assistant designed to generate data. You will be given a format for the data to generate and some examples of the data.

================
File: inst/WORDLIST
================
Codecov
LLC
ORCID

================
File: NAMESPACE
================
# Generated by roxygen2: do not edit by hand

export(check_anthropic_api_key)
export(check_chat)
export(check_col_names)
export(check_date)
export(check_db_config)
export(check_db_conn)
export(check_inherits)
export(check_installed)
export(check_list)
export(check_list_names)
export(check_openai_api_key)
export(check_r6)
export(check_request)
export(check_response)
export(check_row)
export(check_s7)
export(check_tibble)
export(check_tool)
export(check_type)
export(db_connect)
export(db_get_documents)
export(db_preload_documents)
export(db_store_document)
export(embed_openai)
export(extract_code)
export(get_anthropic_api_key)
export(get_anthropic_models)
export(get_api_url)
export(get_db_config)
export(get_gemini_api_key)
export(get_gmaps_api_key)
export(get_llms_config)
export(get_openai_api_key)
export(get_openai_models)
export(get_regex_code_pattern)
export(gmaps_extract_place_info)
export(gmaps_find_best_match)
export(gmaps_geocode_address)
export(gmaps_places_search)
export(initialize_chat)
export(pkg_sys)
export(pkg_sys_config)
export(pkg_sys_database)
export(pkg_sys_extdata)
export(pkg_sys_prompt)
export(pkg_sys_template)
export(pkg_sys_www)
export(prompt_default_sys)
export(set_anthropic_api_key)
export(set_gemini_api_key)
export(set_gmaps_api_key)
export(set_openai_api_key)
export(tool_extract_code)
export(tool_mermaid_diagram)
import(rlang)
importFrom(DBI,SQL)
importFrom(DBI,dbConnect)
importFrom(DBI,dbIsValid)
importFrom(cli,cli_abort)
importFrom(cli,cli_alert_danger)
importFrom(cli,cli_alert_info)
importFrom(cli,cli_alert_success)
importFrom(cli,cli_alert_warning)
importFrom(config,get)
importFrom(dplyr,arrange)
importFrom(dplyr,bind_rows)
importFrom(dplyr,collect)
importFrom(dplyr,desc)
importFrom(dplyr,filter)
importFrom(dplyr,mutate)
importFrom(dplyr,select)
importFrom(dplyr,tbl)
importFrom(ellmer,chat_openai)
importFrom(ellmer,interpolate_file)
importFrom(ellmer,tool)
importFrom(fs,path)
importFrom(glue,glue)
importFrom(googleway,google_geocode)
importFrom(googleway,set_key)
importFrom(httr2,req_auth_bearer_token)
importFrom(httr2,req_body_json)
importFrom(httr2,req_headers)
importFrom(httr2,req_method)
importFrom(httr2,req_perform)
importFrom(httr2,request)
importFrom(httr2,resp_body_json)
importFrom(httr2,resp_check_status)
importFrom(jsonlite,toJSON)
importFrom(lubridate,as_date)
importFrom(memoise,memoise)
importFrom(pool,dbExecute)
importFrom(pool,dbGetQuery)
importFrom(pool,dbIsValid)
importFrom(pool,dbPool)
importFrom(purrr,partial)
importFrom(purrr,pluck)
importFrom(purrr,pluck_exists)
importFrom(rlang,arg_match)
importFrom(rlang,arg_match0)
importFrom(rlang,caller_arg)
importFrom(rlang,caller_env)
importFrom(rlang,inject)
importFrom(snakecase,to_title_case)
importFrom(stringr,str_extract)
importFrom(tibble,deframe)

================
File: r_coding_conventions.md
================
Let's incorporate your feedback about organizing all projects into R packages into the conventions document:

---

# R Coding Conventions

## 1. Project Organization and Naming
- **R Packages**: Organize all projects as R packages. This ensures a standardized structure, facilitates dependency management, and supports documentation generation and testing.
- **Naming Convention**: Use `snake_case` for file names within packages, avoiding special characters aside from underscores (_) and hyphens (-) for readability.
  - Example: `data_analysis.R`, `config-setup.R`
- **Structure**: Maintain a clear package structure that separates functionality appropriately, including directories such as `R/`, `tests/`, `data/`, `vignettes/`, and `man/`.

## 2. Function and Variable Naming Conventions
- **Function Naming**: Use `snake_case` for functions. Functions should start with a verb, indicating the action they perform, such as `calculate_mean()` or `extract_data()`.
- **Variable Naming**: Use `snake_case` for variables. Use descriptive names that reflect the variable's purpose, like `mean_value` or `user_list`.
- **Constants**: Use `UPPER_SNAKE_CASE` for constants, e.g., `MAX_LIMIT`.
- **Avoiding Abbreviations**: While abbreviations can be useful (like `cfg` for config), prioritize clarity over brevity.

## 3. Code Formatting
- **Indentation**: Use 2 spaces for indentation. Ensure consistent indentation to improve code readability.
- **Line Length**: Limit lines to a maximum of 80 characters. This helps in maintaining readable code and is compatible with most editors.
- **Braces**: Follow the convention of placing the opening brace `{` on the same line as the function, if, for, or while keyword. The closing brace `}` should be aligned with the line of code that contains the opening brace.
- **Quotes**: Prefer double quotes (`"`) for consistency unless single quotes (`'`) increase readability.

## 4. Documentation Practices
- **Function Documentation**: Use Roxygen2 for documenting functions. Include sections such as `@param`, `@return`, and `@examples` to clarify function usage.
- **Inline Comments**: Use inline comments judiciously to explain non-obvious code segments. Avoid stating the obvious which can lead to code bloat.

## 5. Functional Programming Patterns
- **Purity**: Aim for function purity (functions that always produce the same output for the same input and produce no side effects) wherever feasible to improve testability.
- **Vectorization**: Leverage R's inherent vectorization capabilities instead of using loops for better performance.
- **Use of Apply Functions**: Prefer `apply`, `lapply`, `sapply`, etc., over explicit loops for cleaner and more efficient code.

## 6. Error Handling Conventions
- **Try-Catch**: Use `try` and `tryCatch` to handle potential errors gracefully, providing meaningful error messages or fallback behaviors.
- **Assertions**: Use assertions to validate inputs and outputs, ensuring that functions behave correctly under expected conditions.

## 7. Package and Dependency Management
- **Dependencies**: Declare necessary packages at the beginning of your scripts within the package. Utilize `library()` calls for installed packages and consider using `renv` or similar tools for handling package dependencies.
- **Package Naming**: Use CRAN-approved naming conventions and always check for name conflicts before importing packages.

## 8. Interactive Exploration
- **Live Console**: Utilize the live console for interactive exploration and prototyping. It allows you to quickly test snippets of code and explore data interactively, enhancing understanding and experimentation during development.
- **Code Analyzer**: Use `code_analyzer` for assessing code quality and structure during the interactive exploration phase to ensure adherence to coding standards and identify potential improvements.

---

This updated document now includes the organization of all projects as R packages, reinforcing structure and standardization across your R projects. It continues to provide a comprehensive set of guidelines for maintaining consistency and enhancing code quality.

================
File: R/agents.R
================
#
# #  ------------------------------------------------------------------------
# #
# # Title : AI Agents
# #    By : Jimmy Briggs
# #  Date : 2025-03-03
# #
# #  ------------------------------------------------------------------------
#
#
# # class -----------------------------------------------------------------------------------------------------------
#
# Agent <- R6::R6Class(
#   "Agent",
#   public = list(
#     chat = NULL,
#     memory = NULL,
#     prompts = NULL,
#     resources = NULL,
#     config = NULL,
#     vector_store = NULL,
#     initialize = function(
#       provider = c("openai", "anthropic", "gemini", "ollama", "groq"),
#       model = "gpt-4o",
#       system_prompt = NULL,
#       prompts = list(),
#       config = list(
#         temperature = 0,
#         timeout = 6000,
#         max_tokens = 1000,
#         echo = FALSE,
#         logger = NULL,
#         capabilities = list(
#           memory = TRUE,
#           tools = TRUE,
#           rag = FALSE,
#           vector_store = FALSE,
#           resources = FALSE
#         )
#       ),
#       resources = list(),
#       ...
#     ) {
#
#       provider <- match.arg(provider)
#
#       chat_func <- switch(
#         provider,
#         "openai" = ellmer::chat_openai,
#         "anthropic" = ellmer::chat_claude,
#         "gemini" = ellmer::chat_gemini,
#         "ollama" = ellmer::chat_ollama,
#         "groq" = ellmer::chat_groq
#       )
#
#       self$chat <- chat_func(
#         model = model,
#         system_prompt = system_prompt,
#         api_args = list(
#           temperature = config$temperature
#         ),
#         echo = config$echo
#       )
#
#       self$prompts <- list(
#         system = system_prompt,
#         prompts
#       )
#
#       self$resources <- resources
#
#       self$config <- list(
#         provider = provider,
#         model = model,
#         system_prompt = system_prompt,
#         config
#       )
#
#       self$memory <- list()
#
#       self$vector_store <- list()
#
#       private$setup_agent_tools()
#
#       cli::cli_alert_success(
#         "Agent {.field {self$name}} initialized using {.field {provider}} provider and the {.field {model}} model."
#       )
#
#     },
#     chat = function(query, echo = TRUE) {
#
#       memory_entry <- list(
#         timestamp = Sys.time(),
#         query = paste0("User: ", query),
#         response = NULL
#       )
#
#       if (self$config$use_memory) {
#         query <- private$augment_with_memory(query)
#       }
#
#       response <- self$chat$chat(query, echo = echo)
#
#       memory_entry$response <- paste0("AI: ", response)
#       self$memory <- append(self$memory, list(memory_entry))
#
#       return(response)
#     },
#
#     register_tool = function(tool) {
#       check_tool(tool)
#       self$chat$register_tool(tool)
#       cli::cli_alert_success("Tool {.field {tool@name}} registered successfully.")
#       invisible(self)
#     },
#
#     db_connect = function(db_config, pool = TRUE) {
#       check_db_config(db_config)
#       db_conn <- db_connect(db_config, pool = pool)
#       private$vector_store$db_conn <- db_conn
#       check_db_conn(db_conn)
#       cli::cli_alert_success("Vector store database connection established successfully.")
#       search_tool <- ellmer::tool(
#         .name = "search_vector_store",
#         .fun = private$search_vector_store,
#         .description = "Search the vector store for relevant information.",
#         query = ellmer::type_string(
#           description = "The search query to be performed to find relevant information",
#           required = TRUE
#         )
#       )
#       invisible(self)
#     },
#
#     db_schema_info = function(pool, schema = NULL) {
#       check_db_conn(pool)
#       schema_info <- db_schema_info(pool, schema = schema)
#       return(schema_info)
#     },
#
#     save_state = function(file_path) {
#       check_file_path(file_path)
#       state <- list(
#         memory = self$memory,
#         config = self$config,
#         resources = self$resources,
#         history = self$chat$get_turns()
#       )
#       qs2::qs_save(state, file_path)
#       cli::cli_alert_success("Agent state saved to {.field {file_path}}.")
#       invisible(self)
#     },
#
#     load_state = function(file_path) {
#       check_file_path(file_path)
#       state <- qs2::qs_load(file_path)
#       self$memory <- state$memory
#       self$config <- state$config
#       self$resources <- state$resources
#       self$chat$set_turns(state$history)
#       cli::cli_alert_success("Agent state loaded from {.field {file_path}}.")
#       invisible(self)
#     }
#   )
# )
#
#
#
#
eda_agent <- function(data, anomaly_threshold = 0.95) {

  anomaly_detector_agent <- ellmer::chat_openai(
    model = "gpt-4o",
    system_prompt = "You are an anomaly detection specialist. Analyze data to identify outliers and unusual patterns.",
  )

  root_cause_agent <- ellmer::chat_openai(
    model = "gpt-4o",
    system_prompt = "You are a root cause analysis expert. Your job is to determine potential causes for data anomalies."
  )

  recommendation_agent <- ellmer::chat_openai(
    model = "gpt-4o",
    system_prompt = "You are a data science recommendation engine. Suggest specific actions to address identified issues."
  )

  anomaly_detector_agent$register_tool(tool_anomaly_detection(data = data))
  root_cause_agent$register_tool(tool_root_cause_analysis(data = data))



}

# mermaid ---------------------------------------------------------------------------------------------------------

mermaid_agent <- function() {
  ellmer::chat_openai(
    system_prompt = prompt_mermaid_sys(),
    echo = "none",
    api_args = list(temperature = 0)
  )
}


# git -------------------------------------------------------------------------------------------------------------


git_agent <- function() {



}

================
File: R/apis.R
================
#  ------------------------------------------------------------------------
#
# Title : APIs
#    By : Jimmy Briggs
#  Date : 2025-03-09
#
#  ------------------------------------------------------------------------


# topic -----------------------------------------------------------------------------------------------------------

#' AI APIs
#'
#' @name apis
#'
#' @description
#' These functions are helpers for working with various AI APIs.
#'
#' - `get_api_url()`: Retrieve the base URL for a given API provider and service.
#'
#' @param provider A character string specifying the API provider.
#' @param name A character string specifying the service name.
#'
#' @returns
#' A character string of the base URL for the specified API service.
NULL

# base URLs -------------------------------------------------------------------------------------------------------

#' @rdname apis
#' @export
#' @importFrom rlang arg_match0
#' @importFrom purrr pluck
get_api_url <- function(provider, name = NULL) {

  provider <- rlang::arg_match0(provider, providers)
  available <- provider_base_urls[[provider]] |> names()

  if (is.null(name)) name <- "base"
  name <- rlang::arg_match0(name, available)

  provider_base_urls |>
    purrr::pluck(provider, name) |>
    as.character()

}

================
File: R/cache.R
================
noclocksai_cache_env <- rlang::new_environment()

cache_last_chat <- function(chat, ...) {

  last_turn_user <- chat$last_turn(role = "user")
  last_turn_assistant <- chat$last_turn(role = "assistant")

  obj <- list(
    user = last_turn_user,
    assistant = last_turn_assistant,
    chat = chat
  )

  noclocksai_cache_env[["last_chat"]] <- obj

  invisible(obj)

}

#' Caching Utility Functions
#'
#' @name cache
#'
#' @description
#' These functions provide a simple caching mechanism for storing and retrieving objects to and from disk.
#'
#' - `write_cache()`: Save an object to disk using the `qs` format.
#' - `read_cache()`: Read an object from disk using the `qs` format.
#'
#' @param obj The object to be cached.
#' @param name The name of the object to be cached. If `NULL`, the name of the object in the environment will be used.
#' @param path The directory where the object will be cached. Default is `"cache"`.
#' @param overwrite If `TRUE`, overwrite the existing file if it exists. Default is `FALSE`.
#' @param ... Additional arguments passed to the `qs2` functions.
#'
#' @returns
#' - `write_cache()`: Invisible object.
#' - `read_cache()`: Invisible path to the cached file.
#'
#' @seealso [qs2::qs_read()] and [qs2::qs_save()]
NULL


#' @rdname cache
#' @export
#' @importFrom cli cli_alert_success cli_alert_warning cli_alert_danger
#' @importFrom qs2 qs_save qs_read
#' @importFrom fs dir_create
write_cache <- function(
  obj,
  name = NULL,
  path = "cache",
  overwrite = FALSE,
  ...
) {

  check_dir(path)
  if (is.null(name)) name <- deparse(substitute(obj))
  qs_file <- file.path(path, paste0(name, ".qs"))
  if (file.exists(qs_file) && !overwrite) {
    cli::cli_alert_warning("File {.file {qs_file}} already exists. Use {.code overwrite = TRUE} to overwrite.")
    return(invisible(NULL))
  }
  tryCatch({
    qs2::qs_save(obj, qs_file, ...)
    cli::cli_alert_success("Object {.field {name}} saved to {.file {qs_file}}.")
  }, error = function(e) {
    cli::cli_alert_danger("Failed to cache object {.field {name}}: {.error {e$message}}")
    return(invisible(NULL))
  })
  invisible(obj)
}

#' @rdname cache
#' @export
#' @importFrom cli cli_alert_success cli_alert_warning cli_alert_danger
#' @importFrom qs2 qs_read
read_cache <- function(
  name,
  path = "cache",
  ...
) {

  check_dir(path)
  qs_file <- file.path(path, paste0(name, ".qs"))
  if (!file.exists(qs_file)) {
    cli::cli_alert_warning("File {.file {qs_file}} does not exist.")
    return(NULL)
  }
  tryCatch({
    obj <- qs2::qs_read(qs_file, ...)
    cli::cli_alert_success("Object {.field {name}} read from {.file {qs_file}}.")
    return(obj)
  }, error = function(e) {
    cli::cli_alert_danger("Failed to read object {.field {name}}: {.error {e$message}}")
    return(NULL)
  })
  invisible(qs_file)
}

================
File: R/chats.R
================
#  ------------------------------------------------------------------------
#
# Title : AI Chats
#    By : Jimmy Briggs
#  Date : 2025-03-03
#
#  ------------------------------------------------------------------------

#' Initialize AI Chat
#'
#' @description
#' Initialize an AI chat via [ellmer::chat_openai()] and optionally register tools.
#'
#' @param model The model to use for the chat. Default is `gpt-4o`.
#' @param system_prompt The system prompt to use for the chat. Default is `prompt_default_sys()`.
#' @param tools A list of tools to register with the chat.
#' @param api_key The OpenAI API key to use for the chat. Default is `get_openai_api_key()`.
#' @param ... Additional arguments to pass to [ellmer::chat_openai()].
#'
#' @returns
#' An [ellmer::Chat] S7 object.
#'
#' @export
#'
#' @seealso [ellmer::chat_openai()]
#'
#' @importFrom ellmer chat_openai
#'
#' @examples
#' \dontrun{
#' chat <- initialize_chat()
#' chat$chat("What is the meaning of life?")
#' }
initialize_chat <- function(
    model = "gpt-4o",
    system_prompt = prompt_default_sys(),
    tools = NULL,
    temperature = 0,
    api_key = get_openai_api_key(),
    ...
) {

  chat <- ellmer::chat_openai(
    model = model,
    system_prompt = system_prompt,
    api_key = api_key,
    api_args = list(temperature = temperature),
    ...
  )

  if (!is.null(tools)) {
    register_tools(chat, tools)
  }

  return(chat)

}

chat_eda <- function(
  data,
  chat = NULL,
  ...
) {

  check_data_frame(data)

  sys_prompt <- prompt_eda_sys()

  if (is.null(chat)) {
    chat <- initialize_chat(system_prompt = prompt_eda_sys())
  } else {
    check_chat(chat)
    old_sys_prompt <- chat$get_system_prompt()
    withr::defer(chat$set_system_prompt(old_sys_prompt))
    chat$set_system_prompt(prompt_eda_sys())
  }

  check_chat(chat)

  prompt <- prompt_eda_user(data)

  chat$chat(prompt, ...)

}

================
File: R/checks.R
================
#  ------------------------------------------------------------------------
#
# Title : Check Utilities
#    By : Jimmy Briggs
#  Date : 2025-03-03
#
#  ------------------------------------------------------------------------

#' Check Functions
#'
#' @name checks
#'
#' @description
#' A collection of functions for checking the validity of function arguments.
#'
#' Below are the `check_` functions grouped by category:
#'
#' ## Classes
#'
#' - `check_inherits()`: Check if an object inherits from a specific class.
#' - `check_s7()`: Check if an object is an S3 object.
#' - `check_r6()`: Check if an object is an R6 object.
#'
#' ## Database
#' - `check_db_conn()`: Check if an object is a valid database connection (DBI or Pool).
#' - `check_db_config()`: Check if an object is a valid database configuration list.
#'
#' ## `ellmer`
#'
#' - `check_chat()`: Check if an object is a [ellmer::Chat] object.
#' - `check_tool()`: Check if an object is an [ellmer::tool()] object.
#' - `check_type()`: Check if an object is an [ellmer::Type] object.
#'
#' ## `tibble`
#'
#' - `check_tibble()`: Check if an object is a [tibble::tibble()] data frame.
#' - `check_row()`: Check if an object is a single-row data frame.
#' - `check_col_names()`: Check if a data frame contains specific column names.
#'
#' ## Lists
#'
#' - `check_list()`: Check if an object is a list.
#' - `check_list_names()`: Check if a list contains specific names.
#'
#' ## Dates
#'
#' - `check_date()`: Check if an object is a valid date object.
#'
#' ## Packages
#'
#' - `check_installed()`: Check if a package is installed.
#'
#' ## API Keys
#'
#' - `check_openai_api_key()`: Check if an object is a valid OpenAI API key.
#' - `check_anthropic_api_key()`: Check if an object is a valid Anthropic API key.
#'
#' @param x,conn,cfg,chat,tool,data,row,req,resp,lst,date,pkg,api_key The object to check.
#' @param class A character string representing the class to check against.
#' @param req_cols A character vector representing the required column names.
#' @param arg,x_arg,call Internal arguments used for [rlang::args_error_context] features.
#'
#' @importFrom cli cli_abort
#' @importFrom rlang caller_arg caller_env
NULL

# classes --------------------------------------------------------------------------------------------------------

#' @rdname checks
#' @export
check_inherits <- function(obj, class, arg = rlang::caller_arg(obj), call = rlang::caller_env()) {
  if (!inherits(obj, class)) {
    cli::cli_abort(
      "{.arg {arg}} must inherit from class {.cls {class}}, not {.obj_type_friendly {obj}}.",
      call = call
    )
  }
  invisible(NULL)
}

#' @rdname checks
#' @export
check_s7 <- function(obj, arg = rlang::caller_arg(obj), call = rlang::caller_env()) {
  check_inherits(obj, "S7_object", arg = arg, call = call)
  S7::check_is_S7(obj, arg = arg)
}

#' @rdname checks
#' @export
check_r6 <- function(obj, arg = rlang::caller_arg(obj), call = rlang::caller_env()) {
  if (R6::is.R6Class(obj)) obj <- obj$new()
  check_inherits(obj, "R6", arg = arg, call = call)
  if (!R6::is.R6(obj)) {
    cli::cli_abort("{.arg {arg}} must be an R6 object.", call = call)
  }
}


# database --------------------------------------------------------------------------------------------------------

#' @rdname checks
#' @export
#' @importFrom pool dbIsValid
#' @importFrom DBI dbIsValid
check_db_conn <- function(conn, arg = rlang::caller_arg(conn), call = rlang::caller_env()) {

  is_dbi <- any(grepl("Connection", class(conn)))
  is_pool <- inherits(conn, "Pool")
  is_rstudio <- inherits(conn, "connConnection")

  if (!is_dbi && !is_pool && !is_rstudio) {
    cli::cli_abort("{.arg {arg}} must be a database connection object.", call = call)
  }

  if (is_pool) {
    if (!pool::dbIsValid(conn)) {
      cli::cli_abort("{.arg {arg}} is not a valid database connection.", call = call)
    }
  }

  if (is_dbi) {
    if (!DBI::dbIsValid(conn)) {
      cli::cli_abort("{.arg {arg}} is not a valid database connection.", call = call)
    }
  }

  invisible(conn)

}

#' @rdname checks
#' @export
check_db_config <- function(cfg, arg = rlang::caller_arg(cfg), call = rlang::caller_env()) {
  req_keys <- c("host", "dbname", "user", "password", "port")
  check_list(cfg, arg = arg, call = call)
  check_names(cfg, req_keys, arg = arg, call = call)
  invisible(NULL)
}

# ellmer ------------------------------------------------------------------

#' @rdname checks
#' @export
check_chat <- function(chat, arg = rlang::caller_arg(chat), call = rlang::caller_env()) {
  check_inherits(chat, "Chat", arg = arg, call = call)
  invisible(NULL)
}

#' @rdname checks
#' @export
check_tool <- function(tool, arg = rlang::caller_arg(tool), call = rlang::caller_env()) {
  check_inherits(tool, "ellmer::ToolDef", arg = arg, call = call)
  invisible(NULL)
}

#' @rdname checks
#' @export
check_type <- function(type, arg = rlang::caller_arg(type), call = rlang::caller_env()) {
  check_s7(type, arg = arg, call = call)
  check_inherits(type, "ellmer::Type", arg = arg, call = call)
}

#' @rdname checks
#' @export
check_turn <- function(turn, arg = rlang::caller_arg(turn), call = rlang::caller_env()) {
  check_s7(turn, arg = arg, call = call)
  check_inherits(turn, "ellmer::Turn", arg = arg, call = call)
  invisible(NULL)
}

# httr2 -----------------------------------------------------------------------------------------------------------

#' @rdname checks
#' @export
check_request <- function(req, arg = rlang::caller_arg(req), call = rlang::caller_env()) {
  check_inherits(req, "httr2_request", arg = arg, call = call)
  invisible(NULL)
}

#' @rdname checks
#' @export
check_response <- function(resp, arg = rlang::caller_arg(resp), call = rlang::caller_env()) {
  check_inherits(resp, "httr2_response", arg = arg, call = call)
  invisible(NULL)
}

# tibble ----------------------------------------------------------------------------------------------------------

#' @rdname checks
#' @export
check_tibble <- function(data, arg = rlang::caller_arg(data), call = rlang::caller_env()) {
  check_inherits(data, "tbl_df", obj_arg = arg, call = call)
  invisible(NULL)
}

#' @rdname checks
#' @export
check_row <- function(row, arg = rlang::caller_arg(row), call = rlang::caller_env()) {
  check_inherits(row, "data.frame", x_arg = arg, call = call)
  if (nrow(row) != 1) {
    cli::cli_abort("{.arg {arg}} must be a single-row data frame.", call = call)
  }
  invisible(NULL)
}

#' @rdname checks
#' @export
check_col_names <- function(data, req_cols, arg = rlang::caller_arg(data), call = rlang::caller_env()) {
  check_inherits(data, "data.frame", x_arg = arg, call = call)
  missing_cols <- setdiff(req_cols, colnames(data))
  if (length(missing_cols) > 0) {
    cli::cli_abort(
      "{.arg {arg}} must contain the following columns: {.field {missing_cols}}.",
      call = call
    )
  }
}


# httr2 -----------------------------------------------------------------------------------------------------------

#' @rdname checks
#' @export
check_request <- function(req, arg = rlang::caller_arg(req), call = rlang::caller_env()) {
  check_inherits(req, "httr2_request", x_arg = arg, call = call)
  invisible(NULL)
}

#' @rdname checks
#' @export
check_response <- function(resp, arg = rlang::caller_arg(resp), call = rlang::caller_env()) {
  check_inherits(resp, "httr2_response", x_arg = arg, call = call)
  invisible(NULL)
}


# lists -----------------------------------------------------------------------------------------------------------

#' @rdname checks
#' @export
check_list <- function(lst, arg = rlang::caller_arg(lst), call = rlang::caller_env()) {
  if (!is.list(lst)) {
    cli::cli_abort("{.arg {arg}} must be a list.", call = call)
  }
  invisible(NULL)
}

# names -------------------------------------------------------------------

#' @rdname checks
#' @export
check_named <- function(obj, arg = rlang::caller_arg(obj), call = rlang::caller_env()) {
  if (!rlang::is_named(obj)) {
    cli::cli_abort("{.arg {arg}} must be named.", call = call)
  }
  invisible(NULL)
}

#' @rdname checks
#' @export
check_names <- function(obj, req_names, arg = rlang::caller_arg(lst), call = rlang::caller_env()) {
  check_named(obj, arg = arg, call = call)
  missing_names <- setdiff(req_names, names(obj))
  if (length(missing_names) > 0) {
    cli::cli_abort(
      "{.arg {arg}} must contain the following names: {.field {missing_names}}.",
      call = call
    )
  }
}

#' @rdname checks
#' @export
check_col_names <- function(data, req_cols, arg = rlang::caller_arg(data), call = rlang::caller_env()) {
  check_data_frame(data, arg = arg, call = call)
  missing_cols <- setdiff(req_cols, colnames(data))
  if (length(missing_cols) > 0) {
    cli::cli_abort(
      "{.arg {arg}} must contain the following columns: {.field {missing_cols}}.",
      call = call
    )
  }
}

#' @rdname checks
#' @export
check_date <- function(date, arg = rlang::caller_arg(date), call = rlang::caller_env()) {
  if (!is.Date(date) && !is.POSIXt(date)) {
    cli::cli_abort("{.arg {arg}} must be a valid date object.", call = call)
  }
  invisible(NULL)
}


# paths -----------------------------------------------------------------------------------------------------------

#' @rdname checks
#' @export
check_path <- function(path, arg = rlang::caller_arg(path), call = rlang::caller_env()) {
  if (!file.exists(path)) {
    cli::cli_abort("{.arg {arg}} must be a valid file or directory path.", call = call)
  }
  invisible(NULL)
}

#' @rdname checks
#' @export
check_dir <- function(path, arg = rlang::caller_arg(path), call = rlang::caller_env()) {
  if (!dir.exists(path)) {
    cli::cli_abort("{.arg {arg}} must be a valid directory path.", call = call)
  }
  invisible(NULL)
}

#' @rdname checks
#' @export
check_cache <- function(path, arg = rlang::caller_arg(path), call = rlang::caller_env()) {
  check_dir(path, arg = arg, call = call)
  if (!file.exists(file.path(path, "cache"))) {
    cli::cli_abort("{.arg {arg}} must be a valid cache directory.", call = call)
  }
  invisible(NULL)
}

# packages --------------------------------------------------------------------------------------------------------

#' @rdname checks
#' @export
check_installed <- function(pkg, arg = rlang::caller_arg(pkg), call = rlang::caller_env()) {
  if (!rlang::is_installed(pkg)) {
    cli::cli_abort("Package {.pkg {arg}} is not installed.", call = call)
  }
  invisible(NULL)
}

# api keys --------------------------------------------------------------------------------------------------------

#' @rdname checks
#' @export
check_openai_api_key <- function(api_key, arg = rlang::caller_arg(api_key), call = rlang::caller_env()) {
  # openai api key should be a string with 132 characters beginning with "sk-proj-"
  is_char <- is.character(api_key)
  valid_nchar <- nchar(api_key) == 132
  valid_prefix <- grepl("^sk-proj-", api_key)
  if (!is_char) cli::cli_abort("{.arg {arg}} must be a character string.", call = call)
  if (!valid_nchar) cli::cli_abort("{.arg {arg}} must be a valid OpenAI API key with 132 characters.", call = call)
  if (!valid_prefix) cli::cli_abort("{.arg {arg}} must be a valid OpenAI API key beginning with 'sk-proj-'.", call = call)
  invisible(NULL)
}

#' @rdname checks
#' @export
check_anthropic_api_key <- function(api_key, arg = rlang::caller_arg(api_key), call = rlang::caller_env()) {
  # anthropic api key should be a string with 108 characters beginning with "sk-ant-"
  is_char <- is.character(api_key)
  valid_nchar <- nchar(api_key) == 108
  valid_prefix <- grepl("^sk-ant-", api_key)
  if (!is_char) cli::cli_abort("{.arg {arg}} must be a character string.", call = call)
  if (!valid_nchar) cli::cli_abort("{.arg {arg}} must be a valid Anthropic API key with 108 characters.", call = call)
  if (!valid_prefix) cli::cli_abort("{.arg {arg}} must be a valid Anthropic API key beginning with 'sk-ant-'.", call = call)
  invisible(NULL)
}

================
File: R/config.R
================
#  ------------------------------------------------------------------------
#
# Title : Configuration
#    By : Jimmy Briggs
#  Date : 2025-03-03
#
#  ------------------------------------------------------------------------


# topic -----------------------------------------------------------------------------------------------------------

#' Configuration
#'
#' @name config
#'
#' @description
#' Functions for managing configuration settings and environment variables.
#'
#' Functions:
#'
#' - `get_db_config()`: Get the database configuration from the configuration file.
#'
#' - `get_llms_config()`: Get the LLM configuration from the configuration file.
#'
#' - `get_tools_config()`: Get the tools configuration from the configuration file.
#'
#' LLM API Keys:
#'
#' - `get_openai_api_key()`: Get the OpenAI API key from the configuration file.
#' - `set_openai_api_key()`: Set the OpenAI API key as an environment variable.
#'
#' - `get_gemini_api_key()`: Get the Gemini API key from the configuration file.
#' - `set_gemini_api_key()`: Set the Gemini API key as an environment variable.
#'
#' - `get_gmaps_api_key()`: Get the Google Maps API key from the configuration file.
#' - `set_gmaps_api_key()`: Set the Google Maps API key as an environment variable.
#'
#' - `get_hunterio_api_key()`: Get the Hunter.io API key from the configuration file.
#' - `set_hunterio_api_key()`: Set the Hunter.io API key as an environment variable.
#'
#' @returns
#' Each function returns the respective API key or sets it as an environment variable.
NULL


# encryption ------------------------------------------------------------------------------------------------------

#' Encrypt/Decrypt Configuration Files
#'
#' @name encrypt_config
#'
#' @description
#' Functions for encrypting and decrypting configuration files.
#'
#' Functions:
#'
#' - `encrypt_config()`: Encrypt a configuration file using a secret key.
#' - `decrypt_config()`: Decrypt an encrypted configuration file using a secret key.
#'
#' @param config_file A character string representing the path to the configuration file. If left
#'   `NULL`, the function will attempt to use the default configuration file via `pkg_sys_config("config.yml")`.
#'
#' @param encrypted_file A character string representing the path to the encrypted configuration file. If left
#'   `NULL`, the function will create a new file with the same name as the original file but with the extension
#'   `.encrypted.yml`.
#'
#' @param decrypted_file A character string representing the path to the decrypted configuration file. If left
#'   `NULL`, the function will create a new `config.yml` in the same directory as the encrypted file.
#'
#' @param overwrite A logical value indicating whether to overwrite an existing encrypted file. Default is `TRUE`.
#'
#' @param key A character string representing the name of the encryption key. Default is `NOCLOCKS_ENCRYPTION_KEY`.
#'
#' @param set_env A logical value indicating whether to set the `R_CONFIG_FILE` environment variable to the decrypted file.
#'
#' @returns
#' - `encrypt_config()`: Returns `0` invisibly.
#' - `decrypt_config()`: Returns the configuration invisibly.
#'
#' @export
#'
#' @importFrom cli cli_abort cli_alert_success cli_alert_warning cli_alert_info
#' @importFrom fs path path_ext_remove
#' @importFrom httr2 secret_encrypt_file secret_decrypt_file secret_has_key
#' @importFrom config get
#'
#' @examples
#' \dontrun{
#' # encrypt the default configuration file
#' encrypt_config()
#'
#' # decrypt the encrypted configuration file
#' decrypt_config()
#' }
encrypt_config <- function(
    config_file = NULL,
    encrypted_file = NULL,
    overwrite = TRUE,
    key = "NOCLOCKS_ENCRYPTION_KEY"
) {

  if (!httr2::secret_has_key(key)) {
    cli::cli_abort(
      c(
        "Encryption key: {.field {key}} not found.\n",
        "Please set the encryption key environment variable: {.envvar NOCLOCKS_ENCRYPTION_KEY}."
      )
    )
  }

  cfg_file <- file.path(cfg_file)

  if (!file.exists(cfg_file)) {
    cli::cli_abort(
      c(
        "Configuration file: {.file {cfg_file}} not found.\n",
        "Please ensure the file exists before attempting to encrypt it."
      )
    )
  }

  if (is.null(encrypted_file)) {
    encrypted_file <- fs::path_ext_remove(cfg_file) |>
      paste0(".encrypted.yml") |>
      fs::path()
  }

  if (file.exists(encrypted_file)) {
    if (!overwrite) {
      cli::cli_abort(
        c(
          "Encrypted configuration file: {.file {encrypted_file}} already exists.\n",
          "Please set the {.arg overwrite} argument to {.code TRUE} to overwrite the existing file."
        )
      )
    }

    cli::cli_alert_warning(
      c(
        "Encrypted configuration file: {.file {encrypted_file}} already exists.\n",
        "Overwriting the existing file with the encrypted configuration."
      )
    )
  }

  file.copy(cfg_file, encrypted_file, overwrite = TRUE)

  httr2::secret_encrypt_file(path = encrypted_file, key = key)
  cli::cli_alert_success("Successfully encrypted the config file: {.file {cfg_file_encrypted}}.")
  return(invisible(0))

}

#' @rdname encrypt_config
#' @export
#' @importFrom cli cli_abort cli_alert_success cli_alert_warning cli_alert_info
#' @importFrom fs path path_ext_remove
#' @importFrom httr2 secret_decrypt_file secret_has_key
#' @importFrom config get
decrypt_config <- function(
    encrypted_file = NULL,
    decrypted_file = NULL,
    key = "NOCLOCKS_ENCRYPTION_KEY",
    set_env = FALSE
) {

  if (!httr2::secret_has_key(key)) {
    cli::cli_abort(
      c(
        "Encryption key: {.field {key}} not found.",
        "Please set the encryption key environment variable: {.envvar NOCLOCKS_ENCRYPTION_KEY}."
      )
    )
  }

  if (is.null(encrypted_file)) {
    encrypted_file <- pkg_sys_config("config.encrypted.yml")
  }

  if (!file.exists(encrypted_file)) {
    cli::cli_abort(
      c(
        "Encrypted configuration file: {.file {encrypted_file}} not found.",
        "Please ensure the file exists before attempting to decrypt it."
      )
    )
  }

  cfg_file_decrypted_temp <- httr2::secret_decrypt_file(
    path = encrypted_file,
    key = key
  )

  withr::defer(file.remove(cfg_file_decrypted_temp))

  cli::cli_alert_success("Successfully decrypted the configuration file: {.file {encrypted_file}}")

  if (file.exists(decrypted_file)) {
    cli::cli_alert_warning(
      c(
        "Configuration file: {.file {decrypted_file}} already exists.",
        "Overwriting the existing file with the decrypted configuration."
      )
    )
  }

  file.copy(cfg_file_decrypted_temp, decrypted_file, overwrite = TRUE)

  cli::cli_alert_success("Successfully copied the decrypted configuration file to: {.file {decrypted_file}}")

  if (!set_env) { return(invisible(config::get())) }

  Sys.setenv("R_CONFIG_FILE" = decrypted_file)
  cli::cli_alert_info("Set Environment Variable {.envvar R_CONFIG_FILE} to: {.file {decrypted_file}}")

  return(invisible(config::get()))

}

# template --------------------------------------------------------------------------------------------------------

#' Create a Configuration Template
#'
#' @description
#' Create a template configuration file based on an existing configuration file with all values replaced by placeholders.
#'
#' @inheritParams encrypt_config
#' @param template_file A character string representing the path to the template file. If left `NULL`, the function will
#'   create a new file with the same name and path as the original file but with the extension `.template.yml`.
#'
#' @returns
#' The function writes the template configuration file to the specified location.
#'
#' @export
#'
#' @importFrom cli cli_abort cli_alert_success
#' @importFrom fs path path_ext_remove
#' @importFrom config get
#' @importFrom yaml as.yaml yaml.load_file
#' @importFrom purrr imap pluck
create_config_template <- function(
    config_file = Sys.getenv("R_CONFIG_FILE", unset = pkg_sys_config("config.yml")),
    template_file = NULL
) {

  if (!file.exists(config_file)) {
    cli::cli_abort(
      c(
        "Configuration file: {.file {config_file}} not found.\n",
        "Please ensure the file exists before attempting to create a template."
      )
    )
  }

  if (is.null(template_file)) {
    template_file <- gsub("\\.yml$", ".template.yml", config_file)
  }

  # Load the config.yml file
  config <- yaml::yaml.load_file(config_file)

  # Helper function to generate placeholders
  create_placeholder <- function(name) { paste0("<", toupper(name), ">") }

  # Recursively replace values with placeholders
  replace_values <- function(x) {
    if (is.list(x)) {
      purrr::imap(x, function(value, key) {
        browser()
        if (is.list(value)) {
          replace_values(value)
        } else {
          create_placeholder(key)
        }
      })
    } else {
      create_placeholder(x)
    }
  }

  # Recursively traverse the config and replace values
  config_template <- purrr::imap(config, function(value, key) {
    replace_values(value)
  })

  # Convert the list back to a YAML formatted string
  yaml_content <- yaml::as.yaml(config_template)

  # Ensure placeholders are quoted
  yaml_content <- gsub("(<[A-Z_]+>)", '"\\1"', yaml_content)

  # Write the content to the output file
  writeLines(yaml_content, con = output_file)
}

# configuration ---------------------------------------------------------------------------------------------------

#' Configuration
#'
#' @name config
#'
#' @description
#' Functions for managing configuration settings and environment variables.
#'
#' Main Functions:
#'
#' - `cfg_get()`: Get the configuration settings from a configuration file.
#' - `cfg_list()`: List the configuration settings from a configuration file.

#' @rdname config
#' @export
#' @importFrom config get
#' @importFrom cli cli_abort
cfg_get <- function(
    ...,
    file = Sys.getenv("R_CONFIG_FILE", unset = pkg_sys_config("config.yml")),
    config = Sys.getenv("R_CONFIG_ACTIVE", unset = "default")
) {

  file <- normalizePath(file)
  if (!file.exists(file)) cli::cli_abort("Provided configuration file ({.file {file}}) does not exist.")
  cfg <- tryCatch({
    config::get(file = file, config = config)
  }, error = function(e) {
    cli::cli_abort(
      c(
        "Error reading configuration file: {.file {file}}.\n",
        "Error: {.error {e$message}}"
      )
    )
  })

  dots <- list(...) |> purrr::compact()

  if (length(dots) > 0) {
    keys <- names(cfg)
    if (!(dots[[1]] %in% keys)) {
      cli::cli_abort(
        c(
          "Configuration key: {.field {dots[[1]]}} not found in configuration file: {.file {file}}.\n",
          "Please check the configuration file for the correct key."
        )
      )
    }
    keys <- names(cfg)
    cfg <- cfg[[dots[[1]]]]
    if (length(dots) > 1) {
      cfg <- purrr::pluck(cfg, !!!dots[-1])
    }
    cfg
  }

  cfg

}

#' @rdname config
#' @export
cfg_list <- function(
    file = Sys.getenv("R_CONFIG_FILE", unset = pkg_sys_config("config.yml")),
    config = Sys.getenv("R_CONFIG_ACTIVE", unset = "default")
) {
  cfg <- get_config(file = file, config = config)
  names(unlist(cfg))
}

# database --------------------------------------------------------------------------------------------------------

#' @rdname config
#' @export
#' @importFrom config get
#' @importFrom cli cli_abort
#' @importFrom rlang arg_match
get_db_config <- function(
    key = NULL,
    file = Sys.getenv("R_CONFIG_FILE", pkg_sys("config/config.yml")),
    config = Sys.getenv("R_CONFIG_ACTIVE", "default")
) {
  file <- normalizePath(file, mustWork = FALSE)
  if (!file.exists(file)) cli::cli_abort("Provided configuration file ({.file {file}}) does not exist.")
  cfg <- tryCatch({
    config::get(value = "db", file = file, config = config)
  }, error = function(e) {
    cli::cli_abort("Failed to load database configuration from {.file {file}}: {.error {e$message}}")
  })

  keys <- names(cfg)
  if (!is.null(key)) {
    key <- rlang::arg_match(key, keys)
    return(cfg[[key]])
  }

  return(cfg)
}

# llms ------------------------------------------------------------------------------------------------------------

#' @rdname config
#' @export
#' @importFrom config get
#' @importFrom cli cli_abort
#' @importFrom rlang arg_match
get_llms_config <- function(
  key = NULL,
  file = Sys.getenv("R_CONFIG_FILE", pkg_sys("config/config.yml")),
  config = Sys.getenv("R_CONFIG_ACTIVE", "default")
) {
  file <- normalizePath(file, mustWork = FALSE)
  if (!file.exists(file)) cli::cli_abort("Provided configuration file ({.file {file}}) does not exist.")
  cfg <- tryCatch({
    config::get(value = "llms", file = file, config = config)
  }, error = function(e) {
    cli::cli_abort("Failed to load LLM configuration from {.file {file}}: {.error {e$message}}")
  })

  keys <- names(cfg)
  if (!is.null(key)) {
    key <- rlang::arg_match(key, keys)
    return(cfg[[key]])
  }

  return(cfg)
}



# openai ----------------------------------------------------------------------------------------------------------

#' @rdname config
#' @export
#' @importFrom config get
#' @importFrom cli cli_abort
get_openai_api_key <- function() {

  envvar_val <- Sys.getenv("OPENAI_API_KEY")
  cfg_val <- get_llms_config("openai_api_key") %||%

  if (envvar_val == "" && cfg_val == "") {
    cli::cli_abort(
      "OpenAI API key is not set. Please set it using {.code set_openai_api_key()}."
    )
  }

  if (envvar_val != "" && cfg_val != "") {
    if (envvar_val != cfg_val) {
      cli::cli_alert_warning(
        "OpenAI API key is set as both an environment variable and in the configuration file. Using the environment variable."
      )
      return(envvar_val)
    }
  }

  if (envvar_val != "") return(envvar_val)
  if (cfg_val != "") {
    Sys.setenv("OPENAI_API_KEY" = cfg_val)
    cli::cli_alert_info("OpenAI API key set as environment variable: {.envvar OPENAI_API_KEY}")
    return(cfg_val)
  }

  cli::cli_abort(
    "OpenAI API key is not set. Please set it using {.code set_openai_api_key()}."
  )

}

#' @rdname config
#' @export
#' @importFrom cli cli_alert_success
set_openai_api_key <- function(key) {
  check_openai_api_key(key)
  Sys.setenv("OPENAI_API_KEY" = key)
  cli::cli_alert_success(
    "OpenAI API Key successfull set as environment variable {.envvar OPENAI_API_KEY}."
  )
}


# anthropic -------------------------------------------------------------------------------------------------------

#' @rdname config
#' @export
#' @importFrom config get
#' @importFrom cli cli_abort
get_anthropic_api_key <- function() {

  envvar_val <- Sys.getenv("ANTHROPIC_API_KEY")
  cfg_val <- get_llms_config("anthropic_api_key") %||%

    if (envvar_val == "" && cfg_val == "") {
      cli::cli_abort(
        "Anthropic API key is not set. Please set it using {.code set_anthropic_api_key()}."
      )
    }

  if (envvar_val != "" && cfg_val != "") {
    if (envvar_val != cfg_val) {
      cli::cli_alert_warning(
        "Anthropic API key is set as both an environment variable and in the configuration file. Using the environment variable."
      )
      return(envvar_val)
    }
  }

  if (envvar_val != "") return(envvar_val)
  if (cfg_val != "") {
    Sys.setenv("ANTHROPIC_API_KEY" = cfg_val)
    cli::cli_alert_info("Anthropic API key set as environment variable: {.envvar ANTHROPIC_API_KEY}")
    return(cfg_val)
  }

  cli::cli_abort(
    "Anthropic API key is not set. Please set it using {.code set_anthropic_api_key()}."
  )

}

#' @rdname config
#' @export
#' @importFrom cli cli_alert_success
set_anthropic_api_key <- function(key) {
  check_anthropic_api_key(key)
  Sys.setenv("ANTHROPIC_API_KEY" = key)
  cli::cli_alert_success(
    "Anthropic API Key successfull set as environment variable {.envvar ANTHROPIC_API_KEY}."
  )
}


# gemini ----------------------------------------------------------------------------------------------------------

#' @rdname config
#' @export
#' @importFrom config get
#' @importFrom cli cli_abort
get_gemini_api_key <- function() {

  if (Sys.getenv("GEMINI_API_KEY") != "") {
    Sys.setenv("GOOGLE_API_KEY" = Sys.getenv("GEMINI_API_KEY"))
    return(Sys.getenv("GEMINI_API_KEY"))
  }

  if (Sys.getenv("GOOGLE_API_KEY") != "") {
    Sys.setenv("GEMINI_API_KEY" = Sys.getenv("GOOGLE_API_KEY"))
    return(Sys.getenv("GOOGLE_API_KEY"))
  }

  if (!is.null(config::get("gemini_api_key"))) {
    key <- config::get("gemini_api_key")
    Sys.setenv("GEMINI_API_KEY" = key)
    Sys.setenv("GOOGLE_API_KEY" = key)
    return(key)
  }

  cli::cli_abort(
    "Gemini API key is not set. Please set it using {.code set_gemini_api_key()}."
  )

}

#' @rdname config
#' @export
set_gemini_api_key <- function(key) {
  Sys.setenv("GEMINI_API_KEY" = key)
  Sys.setenv("GOOGLE_API_KEY" = key)
  cli::cli_alert_success(
    "Gemini API Key successfull set as environment variable {.envvar GEMINI_API_KEY}."
  )
}


# external APIs ---------------------------------------------------------------------------------------------------

#' @rdname config
#' @export
#' @importFrom config get
#' @importFrom cli cli_abort
#' @importFrom googleway set_key
get_gmaps_api_key <- function() {

  if (Sys.getenv("GMAPS_API_KEY") != "") {
    return(Sys.getenv("GMAPS_API_KEY"))
  }

  if (!is.null(config::get("gmaps_api_key"))) {
    key <- config::get("gmaps_api_key")
    Sys.setenv("GMAPS_API_KEY" = key)
    googleway::set_key(key)
    return(key)
  }

  cli::cli_abort(
    "Google Maps API key is not set. Please set it using {.code set_gmaps_api_key()}."
  )

}

#' @rdname config
#' @export
#' @importFrom cli cli_alert_success
#' @importFrom googleway set_key
set_gmaps_api_key <- function(key) {
  Sys.setenv("GMAPS_API_KEY" = key)
  googleway::set_key(key)
  cli::cli_alert_success(
    "Google Maps API Key successfull set as environment variable {.envvar GMAPS_API_KEY}."
  )
}



# internal --------------------------------------------------------------------------------------------------------

#' @keywords internal
#' @noRd
#' @importFrom rappdirs user_config_dir
.default_config_path <- function() {
  normalizePath(
    rappdirs::user_config_dir(
      appname = "cspr",
      appauthor = "noclocks",
      expand = TRUE,
      os = "unix"
    ),
    mustWork = FALSE
  )
}

#' @keywords internal
#' @noRd
.default_config_file <- function() {
  normalizePath(file.path(.default_config_path(), "config.yml"), mustWork = FALSE)
}

# onLoad ----------------------------------------------------------------------------------------------------------

#' @noRd
#' @keywords internal
#' @importFrom rappdirs user_config_dir
#' @importFrom cli cli_alert_success cli_alert_warning
rlang::on_load(
  expr = {
    cfg_path <- .default_config_path()
    cfg_file <- .default_config_file()
    if (!dir.exists(cfg_path)) dir.create(cfg_path, recursive = TRUE)
    if (!file.exists(cfg_file)) {
      cli::cli_alert_warning("Configuration file: {.file {cfg_file}} does not exist.")
      decrypt_config(
        encrypted_file = pkg_sys_config("config.encrypted.yml"),
        decrypted_file = cfg_file,
        set_env = TRUE
      )
    } else {
      Sys.setenv("R_CONFIG_FILE" = cfg_file)
    }
    cli::cli_alert_success("Configuration file: {.file {cfg_file}} setup successfully.")
  }
)

================
File: R/context.R
================
fetch_code_context <- function(context = NULL) {

  if (is.null(context)) context <- rstudioapi::getActiveDocumentContext()

  contents <- context$contents
  selection <- context$selection

  end_before <- selection[[1]]$range$start[1] - 1
  start_after <- min(selection[[1]]$range$end[1] + 1, length(contents))

  before <- contents[seq_len(end_before)]
  after <- contents[seq(start_after, length(contents))]
  list(
    before = backtick_possibly(before),
    after = backtick_possibly(after),
    selection = backtick_possibly(
      contents[seq(selection[[1]]$range$start[1], selection[[1]]$range$end[1])]
    )
  )
}

backtick_possibly <- function(x) {
  if (length(x) == 0 || identical(x, "")) {
    return(character(0))
  } else {
    c("```", x, "```")
  }
}

fetch_env_context <- function(selection, input, env) {
  obj_names <- names(env)

  # is the object name present in the selection or mentioned in the input?
  mentioned <- obj_names[
    obj_names %in% selected_variables(selection) |
      unname(vapply(obj_names, grepl, logical(1), x = input))
  ]

  res <- describe_variables(mentioned, env)

  if (identical(res, character(0))) {
    return(res)
  }

  c("```", res, "```")
}

describe_variables <- function(variables, env) {
  if (length(variables) == 0) {
    return(character(0))
  }

  res <- character(0)
  for (variable in variables) {
    if (!env_has(env, variable)) next
    res <- c(res, describe_variable(env_get(env, variable), variable), "")
  }

  res
}

describe_variable <- function(x, x_name) {
  # to limit the number of tokens taken up by data frames, only print the
  # first few rows and columns of data frames
  if (inherits(x, "data.frame")) {
    dims <- fetch_gander_dims()
    n_row <- min(dims[1], nrow(x))
    n_col <- min(dims[2], ncol(x))
    x <- x[seq_len(n_row), seq_len(n_col), drop = FALSE]
    x_name <- c(
      cli::format_inline("# Just the first {n_row} row{?s} and {n_col} column{?s}:"),
      x_name
    )
  }

  # todo: large lists may still take up quite a few tokens here. should we just
  # subset this output to the first n entries?
  c(
    x_name,
    paste0("#> ", gsub("\t.*$", "", capture.output(str(x))))
  )
}

selected_variables <- function(selection) {
  language <- treesitter.r::language()
  parser <- treesitter::parser(language)
  tree <- treesitter::parser_parse(parser, selection)
  root <- treesitter::tree_root_node(tree)

  if (!is_syntactically_valid(root)) {
    # just split up by spaces and return---it's okay if this function's output
    # is a superset since its results will be filtered by the names of objects
    # in an environment
    return(strsplit(selection, " ", fixed = TRUE)[[1]])
  }

  query_source <- '
    (identifier) @id
    (call function: (identifier) @func)
  '

  query <- treesitter::query(language, query_source)
  captures <- treesitter::query_captures(query, root)
  identifiers <- unique(vapply(captures$node, treesitter::node_text, character(1)))

  unique(identifiers)
}

is_syntactically_valid <- function(root) {
  !treesitter::node_has_error(root) &&
    !treesitter::node_is_error(root) &&
    !treesitter::node_is_missing(root)
}

================
File: R/db.R
================
#  ------------------------------------------------------------------------
#
# Title : Database Functions
#    By : Jimmy Briggs
#  Date : 2025-03-03
#
#  ------------------------------------------------------------------------


# connect ---------------------------------------------------------------------------------------------------------

#' Connect to the Database
#'
#' @description
#' Connect to the database using the provided configuration.
#'
#' @param db_config A list containing the database configuration. Must include the following fields:
#'   `dbname`, `host`, `user`, `password`, `port`.
#'
#' @param pool Logical. If `TRUE`, the connection will be pooled using [pool::dbPool()], otherwise will
#'   create a single connection via [DBI::dbConnect()]. Default is `TRUE`.
#'
#' @param ... Additional arguments passed to the connection function, i.e. either [pool::dbPool()] or [DBI::dbConnect()].
#'
#' @returns
#' Database connection object.
#' If `pool = TRUE`, returns a [pool::Pool-class] (R6) object.
#' If `pool = FALSE`, returns a [DBI::DBIConnection-class] (S4) object.
#'
#' @export
#'
#' @importFrom pool dbPool
#' @importFrom DBI dbConnect
db_connect <- function(db_config = get_db_config(), pool = TRUE, ...) {

  check_db_config(db_config)

  if (pool) {
    tryCatch({
      pool <- pool::dbPool(
        drv = RPostgres::Postgres(),
        dbname = db_config$dbname,
        host = db_config$host,
        port = db_config$port,
        user = db_config$user,
        password = db_config$password,
        ...
      )
      cli::cli_alert_success("Database pooled connection successfully established.")
      return(pool)
    }, error = function(e) {
      cli::cli_alert_danger("Failed to establish database pooled connection: {e$message}.")
      cli::cli_abort(e)
    })
  } else {
    tryCatch({
      conn <- DBI::dbConnect(
        drv = RPostgres::Postgres(),
        dbname = db_config$dbname,
        host = db_config$host,
        port = db_config$port,
        user = db_config$user,
        password = db_config$password,
        ...
      )
      cli::cli_alert_success("Database connection successfully established.")
      return(conn)
    }, error = function(e) {
      cli::cli_alert_danger("Failed to establish database connection: {e$message}.")
      cli::cli_abort(e)
    })
  }

}

db_schema_info <- function(pool, schema = NULL) {

  check_db_conn(pool)

  conn <- pool::poolCheckout(pool)
  withr::defer(pool::poolReturn(conn))

  schema_dm <- dm::dm_from_con(conn, schema = schema, learn_keys = TRUE)
  schema_info <- capture.output(print(dm::dm_get_tables(schema_dm)))

  head <- paste0(
    "Database Schema Information\n",
    "---------------------------\n",
    "Schema: ", schema, "\n\n",
    "Tables:\n",
    "-------\n"
  )

  paste0(
    head,
    paste(schema_info, collapse = "\n")
  )

}

# embeddings ------------------------------------------------------------------------------------------------------

#' Store Embedded Document
#'
#' @description
#' This function will insert a new document into the database along with its metadata and embedding.
#'
#' @param pool Database connection object.
#' @param title Title of the document.
#' @param content Content of the document.
#' @param metadata List of metadata to store with the document.
#'
#' @returns
#' The ID of the document stored.
#'
#' @export
#'
#' @importFrom jsonlite toJSON
#' @importFrom pool dbGetQuery
#' @importFrom cli cli_alert_success cli_alert_danger
#'
#' @examples
#' \dontrun{
#' doc_text <- readLines("inst/extdata/documents/Anthropic-Building-Effective-AI-Agents-Comprehensive-Analysis.md") |>
#'   paste(collapse = "\n")
#' pool <- db_connect()
#' db_store_document(
#'   pool,
#'   title = "Anthropic Research: Building Effective Agents",
#'   content = doc_text,
#'   metadata = list(source = "Anthropic")
#' )
#' }
db_store_document <- function(pool, title, content, metadata = list()) {

  check_db_conn(pool)

  tryCatch({
    content <- as.character(paste(content, collapse = "\n"))
    embedding <- embed_openai(text = content)
    embedding_str <- paste0("[", paste(embedding, collapse = ","), "]")
    metadata_json <- jsonlite::toJSON(metadata, auto_unbox = TRUE)
    qry <- paste0(
      "INSERT INTO \"noclocks\".\"documents\" (\"title\", \"content\", \"metadata\", \"embedding\") ",
      "VALUES ($1, $2, $3, $4) ",
      "RETURNING \"id\";"
    )
    result <- pool::dbGetQuery(pool, qry, list(title, content, metadata_json, embedding_str))
    cli::cli_alert_success("Document stored successfully with ID: {.field {result$id}}.")
    return(result$id)
  }, error = function(e) {
    cli::cli_alert_danger("Failed to store document: {e$message}.")
    cli::cli_abort(e)
  })

}

#' Retrieve Documents
#'
#' @description
#' Retrieve documents from the database based on the provided `query`.
#'
#' @param pool Database connection pool object.
#' @param query The query to search for in the documents.
#' @param max_results Maximum number of documents to retrieve.
#' @param use_cache Logical. If `TRUE`, will attempt to retrieve documents from the cache first.
#'
#' @returns
#' A data frame containing the retrieved documents.
#'
#' @export
#'
#' @importFrom dplyr tbl filter arrange desc collect
#' @importFrom DBI SQL
#' @importFrom pool dbExecute dbGetQuery
#' @importFrom cli cli_alert_success cli_alert_danger cli_abort
#'
#' @examples
#' \dontrun{
#' pool <- db_connect()
#' db_get_documents(pool, "Anthropic Research", 5)
#' }
db_get_documents <- function(pool, query, max_results = 10L, use_cache = TRUE) {

  check_db_conn(pool)

  tryCatch({

    if (use_cache) {

      cached_docs <- dplyr::tbl(pool, I("noclocks.query_cache")) |>
        dplyr::filter(stringr::str_detect(.data$qry_text, query)) |>
        dplyr::arrange(dplyr::desc(.data$frequency)) |>
        dplyr::collect()

      if (nrow(cached_docs) > 0 && length(cached_docs$document_ids) > 0) {
        doc_ids <- paste(cached_docs$document_ids, collapse = ", ")
        docs <- dplyr::tbl(pool, DBI::SQL("noclocks.documents")) |>
          dplyr::filter(.data$id %in% doc_ids) |>
          dplyr::collect()
        qry <- paste0(
          "UPDATE \"noclocks\".\"documents\" ",
          "SET frequency = frequency + 1, last_accessed = CURRENT_TIMESTAMP ",
          "WHERE qry_text = $1"
        )
        pool::dbExecute(pool, qry, list(query))
        cli::cli_alert_success("Retrieved {.field {nrow(docs)}} documents from cache.")
        return(docs)
      }
    }

    query_embedding <- embed_openai(text = query)
    embedding_str <- paste0("[", paste(query_embedding, collapse = ","), "]")
    qry <- paste0(
      "SELECT * FROM \"noclocks\".\"find_similar_documents\"($1, 0.6, $2);"
    )
    docs <- pool::dbGetQuery(pool, qry, list(embedding_str, max_results))
    if (use_cache && nrow(docs) > 0L) {
      doc_ids <- docs$id
      qry <- paste0("SELECT noclocks.update_query_cache($1, $2, $3)")
      pool::dbExecute(pool, qry, list(query, embedding_str, stringr::str_c(doc_ids, collapse = ",")))
    }
    cli::cli_alert_success("Retrieved {.field {nrow(docs)}} documents.")
    return(docs)
  }, error = function(e) {
    cli::cli_alert_danger("Failed to retrieve documents: {e$message}.")
    cli::cli_abort(e)
  })

}

#' Pre-Load Documents
#'
#' @description
#' This function pre-loads documents for a "Cache Augmented Generation" (CAG) system, based on provided `topic`.
#'
#' @param pool Database connection pool object.
#' @param topic The topic to find documents for.
#' @param max_docs Maximum number of documents to load.
#'
#' @returns
#' A formatted string of documents
#'
#' @export
#'
#' @importFrom jsonlite toJSON
db_preload_documents <- function(pool, topic, max_docs = 10) {

  check_db_conn(pool)

  docs <- db_get_documents(pool, topic, max_docs)

  if (nrow(docs) == 0) {
    return("No relevant documents found.")
  }

  # Format documents for context
  formatted_docs <- paste(
    sapply(1:nrow(docs), function(i) {
      metadata_str <- if (!is.null(docs$metadata[[i]])) {
        paste0("\nMetadata: ", jsonlite::toJSON(docs$metadata[[i]], auto_unbox = TRUE))
      } else {
        ""
      }

      paste0("Document ", docs$id[i], " - ", docs$title[i], metadata_str,
             "\nContent: ", docs$content[i], "\n\n")
    }),
    collapse = ""
  )

  return(formatted_docs)
}

================
File: R/document.R
================
#  ------------------------------------------------------------------------
#
# Title : Document
#    By : Jimmy Briggs
#  Date : 2025-03-20
#
#  ------------------------------------------------------------------------


# document_dataset ------------------------------------------------------------------------------------------------

document_dataset <- function(
    data,
    include_examples = TRUE,
    verbose = FALSE
) {

  check_data_frame(data)

  chat <- initialize_chat(system_prompt = prompt_document_dataset_sys())

  dataset_name <- deparse(substitute(data))
  col_names <- names(data)
  col_types <- purrr::map_chr(data, typeof)

  data_skim <- skimr::skim(data)

  qry <- prompt_document_dataset_user(data = data)
  response <- chat$chat(qry)

}


generate_roxygen_doc <- function(data,
                                 model = "gpt-4o",
                                 include_examples = TRUE,
                                 verbose = FALSE) {

  # Validate input
  if (!is.data.frame(data)) {
    stop("Input must be a data.frame or tibble")
  }

  # Create a chat object with ellmer
  chat <- chat_openai(
    model = model,
    system_prompt = "You are an expert R programmer specializing in package documentation."
  )

  # Generate the prompt
  prompt <- prompt_document_dataset_user(data)

  resp <- chat$chat(prompt)

  # extract code
  code <- extract_code(resp, "r")

  # return code
  return(code)
}

================
File: R/embed.R
================
#'
#' #  ------------------------------------------------------------------------
#' #
#' # Title : Embeddings
#' #    By : Jimmy Briggs
#' #  Date : 2025-03-03
#' #
#' #  ------------------------------------------------------------------------
#'
#' # topic -----------------------------------------------------------------------------------------------------------
#'
#' #' Embeddings
#' #'
#' #' @name embeddings
#' #'
#' #' @description
#' #' These functions generate text embeddings using external APIs.
#' #'
#' #' Functions:
#' #'
#' #' - `embed_openai()`: Generate text embeddings using OpenAI's API ("text-embedding-3-small" model).
#' #' - `embed_ollama()`: Generate text embeddings using Ollama's API.
#' #'
#' #' @param text Character string to embed. Can be one of the following:
#' #'   - A character vector, in which case a matrix of embeddings is returned.
#' #'   - A `data.frame` with a column named `text`, in which case the `data.frame` is returned with
#' #'     an additional column added named `embedding`.
#' #'   - Missing of `NULL`, in which case a function is returned that can be called to get embeddings.
#' #' @param base_url The base URL for the API. Default is `get_api_url("openai", "embeddings")`.
#' #' @param model The model to use for the embedding. Default is `text-embedding-3-small`.
#' #' @param batch_size The batch size to use for the embedding. This will split `text` into batches when embedding.
#' #'   Default is `10L`.
#' #' @param api_key The API key to use for the embedding. Default is `get_openai_api_key()`.
#' #'
#' #' @returns
#' #' If `text` is a character vector, a matrix of embeddings is returned.
#' #' If `text` is a `data.frame`, the `data.frame` is returned with an additional column named `embedding`.
#' #' If `text` is missing or `NULL`, a function is returned that can be called to get embeddings.
#' #'
#' #' @export
#' #'
#' #' @examples examples/ex_embeddings.R
#' NULL
#'
#'
#' # openai ----------------------------------------------------------------------------------------------------------
#'
#' #' @export
#' #' @importFrom httr2 request req_method req_headers req_auth_bearer_token req_body_json req_perform resp_check_status resp_body_json
#' #' @importFrom cli cli_alert_success cli_abort
#' #' @importFrom purrr pluck
#' embed_openai <- function(
#'   text,
#'   base_url = get_api_url("openai", "embeddings"),
#'   model = c("text-embedding-3-small", "text-embedding-3-large"),
#'   dims = NULL,
#'   user = NULL,
#'   batch_size = 20L,
#'   api_key = get_openai_api_key()
#' ) {
#'
#'   if (missing(text) || is.null(text)) {
#'     args <- capture_args()
#'     func <- purrr::partial(quote(noclocksai::embed_openai), alist(text = ), args)
#'     return(func)
#'   }
#'
#'   if (is.data.frame(text)) {
#'     text[["embedding"]] <- Recall(
#'       text[["text"]],
#'       base_url = base_url,
#'       model = model,
#'       dims = dims,
#'       user = user,
#'       batch_size = batch_size,
#'       api_key = api_key
#'     )
#'     return(text)
#'   }
#'
#'   if (is.character(text)) {
#'     text <- list(text)
#'   }
#'
#'
#'
#' }
#'
#'   base_url <- "https://api.openai.com/v1/embeddings"
#'
#'   req_body <- list(
#'     "input" = text,
#'     "model" = model
#'   )
#'
#'   req <- httr2::request(base_url) |>
#'     httr2::req_method("POST") |>
#'     httr2::req_headers("Content-Type" = "application/json") |>
#'     httr2::req_auth_bearer_token(api_key) |>
#'     httr2::req_body_json(req_body)
#'
#'   tryCatch({
#'     resp <- httr2::req_perform(req)
#'     httr2::resp_check_status(resp)
#'     cli::cli_alert_success("Successfully called OpenAI embedding API")
#'   }, error = function(e) {
#'     cli::cli_abort("Failed to call OpenAI's Embeddings API\n{e$message}")
#'   })
#'
#'   resp_json <- httr2::resp_body_json(resp)
#'
#'   purrr::pluck(resp_json, "data", 1, "embedding")
#'
#' }

================
File: R/encode.R
================
#  ------------------------------------------------------------------------
#
# Title : Encoding
#    By : Jimmy Briggs
#  Date : 2025-03-13
#
#  ------------------------------------------------------------------------


# topic -----------------------------------------------------------------------------------------------------------

#' Encode Data
#'
#' @name encode_data
#'
#' @description
#' Encode a data frame into a specified format (e.g., JSON, CSV, or text) with optional
#' truncation of rows to a specified maximum number.
#'
#' Its primary purpose is to provide a convenient way to encode data for use with
#' AI Chat Agents.
#'
#' @param data A data frame to encode.
#' @param method A character string specifying the encoding method. Options include "json", "csv", or "text".
#'   The default value is "json".
#' @param max_rows An integer specifying the maximum number of rows to include in the encoded output.
#'   If the number of rows in the data frame exceeds this value, the output will be truncated.
#'   The default value is `100`.
#' @param show_end An integer specifying the number of rows to show at the end of the encoded output.
#'   The default value is `10`.
#'
#' @returns
#' A character string representing the encoded data.
#'
#' @export
#'
#' @importFrom jsonlite toJSON
#' @importFrom readr write_csv
#' @importFrom stringr str_remove str_trim
#' @importFrom cli cli_alert_warning cli_alert_info
#'
#' @examples
#' encode_data(hud_markets, "json", max_rows = 10, show_end = 5) |> cat()
#' encode_data(hud_markets, "csv", max_rows = 10, show_end = 5) |> cat()
#' encode_data(hud_markets, "text", max_rows = 10, show_end = 5) |> cat()
encode_data <- function(data, method = c("json", "csv", "text"), max_rows = 100, show_end = 10) {

  check_tibble(data)

  if (nrow(data) == 0) {
    cli::cli_alert_warning("Provided {.arg data} is empty. Encoding empty data as text.")
    return(encode_data_text(data))
  }

  method <- match.arg(method)
  encoder <- switch(
    method,
    json = encode_data_json,
    csv = encode_data_csv,
    text = encode_data_text
  )

  if (method == "text" || (nrow(data) <= max_rows)) { return(encoder(data)) }

  head_rows <- data[1:max_rows, ]
  tail_rows <- data[(nrow(data) - show_end + 1):nrow(data), ]

  if (method == "json") {
    json_head <- encoder(head_rows, strip_brackets = TRUE)
    json_tail <- encoder(tail_rows, strip_brackets = TRUE)

    return(
      paste0(
        "[\n",
        paste0("  ", json_head),
        ",\n  // ...",
        nrow(data) - max_rows,
        " rows omitted... //\n",
        paste0("  ", json_tail),
        "\n]\n"
      )
    )
  }

  if (method == "csv") {
    csv_head <- encoder(head_rows)
    csv_tail <- encoder(tail_rows, colnames = FALSE)

    return(
      paste(
        collapse = "\n",
        c(
          csv_head,
          sprintf("... %d rows omitted ...", nrow(data) - max_rows),
          csv_tail,
          ""
        )
      )
    )
  }
}

#' @rdname encode_data
#' @export
#' @importFrom readr write_csv
encode_data_csv <- function(data, colnames = TRUE) {
  check_tibble(data)
  temp_file <- tempfile(fileext = ".csv")
  on.exit(unlink(temp_file))
  readr::write_csv(data, file = temp_file, col_names = colnames)
  paste(readLines(temp_file), collapse = "\n")
}

#' @rdname encode_data
#' @export
#' @importFrom jsonlite toJSON
encode_data_json <- function(data, strip_brackets = FALSE) {
  check_tibble(data)
  hold <- jsonlite::toJSON(data, dataframe = "rows", na = "string", pretty = TRUE, auto_unbox = TRUE)
  if (strip_brackets) { return(strip_json_brackets(hold)) }
  hold
}

#' @rdname encode_data
#' @export
encode_data_text <- function(data) {
  check_tibble(data)
  hold <- paste(collapse = "\n", capture.output(print(data)))
  lines <- strsplit(hold, "\n")[[1]]
  lines <- lines[!grepl("print", lines)]
  return(paste(lines, collapse = "\n"))
}

#' @keywords internal
#' @importFrom stringr str_remove str_trim
strip_json_brackets <- function(json) {
  json |> stringr::str_remove("^\\[") |> stringr::str_remove("\\]$") |> stringr::str_trim()
}


# expressions -----------------------------------------------------------------------------------------------------

================
File: R/extract.R
================
#  ------------------------------------------------------------------------
#
# Title : Extraction Functions
#    By : Jimmy Briggs
#  Date : 2025-03-20
#
#  ------------------------------------------------------------------------


# extract code ----------------------------------------------------------------------------------------------------

#' Extract Code Blocks from Markdown
#'
#' This function extracts code blocks of a specified language from markdown text.
#' It handles both uppercase and lowercase language identifiers (e.g., 'R' and 'r').
#'
#' @param markdown_text The markdown text containing code blocks.
#' @param language The language identifier to extract (default: "R").
#'
#' @return A character vector with each element containing a code block.
#' @export
extract_code_blocks <- function(markdown_text, language = "R") {
  # Normalize language for comparison
  language <- tolower(language)

  # Split the text by code block markers
  parts <- strsplit(markdown_text, "```", fixed = TRUE)[[1]]

  # If we have fewer than 3 parts, there's no complete code block
  if (length(parts) < 3) {
    return(character(0))
  }

  blocks <- character(0)

  # Process every other part starting from the second part
  for (i in seq(2, length(parts), 2)) {
    if (i <= length(parts)) {
      part <- parts[i]
      # Get the first line to check the language
      first_line <- strsplit(part, "\n")[[1]][1]
      first_line <- trimws(first_line)

      # Check if this part starts with the language identifier (case insensitive)
      if (grepl(paste0("^", language, "$"), tolower(first_line))) {
        # Extract the code content after the language identifier (skip first line)
        code_lines <- strsplit(part, "\n")[[1]][-1]
        code_content <- paste(code_lines, collapse = "\n")
        blocks <- c(blocks, code_content)
      }
    }
  }

  return(blocks)
}

#' Merge Code Blocks into a Single String
#'
#' This function extracts code blocks of a specified language from markdown text
#' and merges them into a single string.
#'
#' @param markdown_text The markdown text containing code blocks.
#' @param language The language identifier to extract (default: "R").
#' @param separator String used to join blocks (default: "\n\n").
#'
#' @return A single string containing all merged code blocks.
#' @export
merge_code_blocks <- function(markdown_text, language = "R", separator = "\n\n") {
  blocks <- extract_code_blocks(markdown_text, language)

  if (length(blocks) == 0) {
    return("")
  }

  # Join all blocks with the specified separator
  merged_code <- paste(blocks, collapse = separator)
  return(merged_code)
}

#' Trim Code Block
#'
#' Removes leading/trailing whitespace and empty lines from a code block.
#'
#' @param code The code block to trim.
#'
#' @return A trimmed code block.
#' @export
trim_code <- function(code) {
  # Trim leading/trailing whitespace from each line
  lines <- strsplit(code, "\n", fixed = TRUE)[[1]]
  lines <- trimws(lines)

  # Remove empty lines at the beginning and end
  while (length(lines) > 0 && lines[1] == "") {
    lines <- lines[-1]
  }
  while (length(lines) > 0 && lines[length(lines)] == "") {
    lines <- lines[-length(lines)]
  }

  # Rejoin the lines
  return(paste(lines, collapse = "\n"))
}

#' Format Code Block
#'
#' Uses formatR to format a code block with consistent styling.
#'
#' @param code The code block to format.
#' @param keep_comments Whether to keep comments (default: TRUE).
#' @param style A list of formatting options to override defaults.
#'
#' @return A formatted code block.
#' @export
format_code <- function(code, keep_comments = TRUE, style = list()) {
  # Check if formatR is installed
  if (!requireNamespace("formatR", quietly = TRUE)) {
    warning("formatR package not installed. Returning unformatted code.")
    return(code)
  }

  # Default formatting options
  default_style <- list(
    comment = keep_comments,  # keep or remove comments
    pipe = TRUE,              # use native pipe |>
    arrow = TRUE,             # always use ->
    blank = FALSE,            # remove blank lines
    indent = 2L,              # indent with 2 spaces
    wrap = TRUE,              # wrap lines
    width.cutoff = 80L,       # wrap at 80 characters
    args.newline = TRUE       # place function args on new line
  )

  # Override defaults with any provided style options
  style_opts <- modifyList(default_style, style)

  # Apply formatting options
  formatted <- tryCatch({
    do.call(formatR::tidy_source,
            c(list(text = code, output = FALSE), style_opts))$text.tidy
  }, error = function(e) {
    warning("Error formatting code: ", e$message)
    return(code)  # Return original code if formatting fails
  })

  # Join lines if formatting was successful
  if (is.character(formatted) && length(formatted) > 0) {
    formatted <- paste(formatted, collapse = "\n")
  } else {
    formatted <- code  # Return original if something went wrong
  }

  return(formatted)
}

#' Extract and Format Code Blocks
#'
#' Extracts code blocks of a specified language from markdown text,
#' formats each block, and merges them.
#'
#' @param markdown_text The markdown text containing code blocks.
#' @param language The language identifier to extract (default: "R").
#' @param keep_comments Whether to keep comments when formatting (default: TRUE).
#' @param style A list of formatting options for format_code.
#' @param separator String used to join blocks (default: "\n\n").
#'
#' @return A single string containing all merged and formatted code blocks.
#' @export
extract_and_format_code <- function(markdown_text, language = "R",
                                    keep_comments = TRUE,
                                    style = list(),
                                    separator = "\n\n") {
  blocks <- extract_code_blocks(markdown_text, language)

  if (length(blocks) == 0) {
    return("")
  }

  # First trim each block
  blocks <- sapply(blocks, trim_code)

  # Then format each block
  if (requireNamespace("formatR", quietly = TRUE)) {
    blocks <- sapply(blocks, function(block) {
      format_code(block, keep_comments, style)
    })
  }

  # Join all blocks with the specified separator
  merged_code <- paste(blocks, collapse = separator)
  return(merged_code)
}

#' Write Extracted Code to a File
#'
#' Extracts code blocks, formats them, and writes to a file.
#'
#' @param markdown_text The markdown text containing code blocks.
#' @param file The output file path.
#' @param language The language identifier to extract (default: "R").
#' @param format Whether to format the code (default: TRUE).
#' @param style A list of formatting options.
#'
#' @return Invisibly returns TRUE if successful, FALSE otherwise.
#' @export
write_code_to_file <- function(markdown_text, file, language = "R",
                               format = TRUE, style = list()) {
  if (format && requireNamespace("formatR", quietly = TRUE)) {
    code <- extract_and_format_code(markdown_text, language, TRUE, style)
  } else {
    code <- merge_code_blocks(markdown_text, language)
  }

  if (code == "") {
    warning("No code blocks found for language: ", language)
    return(invisible(FALSE))
  }

  # Write to file
  status <- tryCatch({
    writeLines(code, file)
    TRUE
  }, error = function(e) {
    warning("Error writing to file: ", e$message)
    FALSE
  })

  return(invisible(status))
}


# extract dates ---------------------------------------------------------------------------------------------------

extract_date <- function(text) {
  # Regular expression to match dates in YYYY-MM-DD format
  pattern <- "\\b\\d{4}-\\d{2}-\\d{2}\\b"

  # Find all matches
  matches <- gregexpr(pattern, text)
  dates <- regmatches(text, matches)

  # Flatten the list and remove empty matches
  dates <- unlist(dates)
  dates <- dates[dates != ""]

  return(dates)
}


# extract numbers -------------------------------------------------------------------------------------------------

extract_numbers <- function(text) {
  # Regular expression to match numbers (integers and decimals)
  pattern <- "\\b\\d+(\\.\\d+)?\\b"

  # Find all matches
  matches <- gregexpr(pattern, text)
  numbers <- regmatches(text, matches)

  # Flatten the list and remove empty matches
  numbers <- unlist(numbers)
  numbers <- numbers[numbers != ""]

  return(numbers)
}

# extract email addresses ----------------------------------------------------------------------------------------

extract_email <- function(text) {
  # Regular expression to match email addresses
  pattern <- "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}"

  # Find all matches
  matches <- gregexpr(pattern, text)
  emails <- regmatches(text, matches)

  # Flatten the list and remove empty matches
  emails <- unlist(emails)
  emails <- emails[emails != ""]

  return(emails)
}

================
File: R/gmaps.R
================
#  ------------------------------------------------------------------------
#
# Title : Google Maps API Functions
#    By : Jimmy Briggs
#  Date : 2025-02-25
#
#  ------------------------------------------------------------------------

# geocode ---------------------------------------------------------------------------------------------------------

#' Geocode Address
#'
#' @description
#' Geocode an address using the Google Maps Geocoding API.
#'
#' @param address A character string representing the address to geocode.
#' @param api_key A character string representing the Google Maps API key.
#'   Will default to the result from [get_gmaps_api_key()].
#'
#' @returns
#' A list containing the following elements:
#'
#' - `status`: A character string indicating the status of the API request.
#' - `formatted_address`: A character string representing the formatted address.
#' - `place_id`: A character string representing the place ID.
#' - `place_types`: A character string representing the place types.
#' - `latitude`: A numeric value representing the latitude.
#' - `longitude`: A numeric value representing the longitude.
#'
#' @export
#'
#' @examples examples/ex_gmaps_geocode_address.R
#'
#' @importFrom googleway google_geocode
#' @importFrom purrr pluck
gmaps_geocode_address <- function(address, api_key = get_gmaps_api_key()) {

  cli::cli_alert_info("Geocoding address: {.field {address}}.")

  googleway::set_key(api_key)

  tryCatch({
    resp <- googleway::google_geocode(address = address)
    # gmaps_check_response(resp)
    results <- purrr::pluck(resp, "results")
    formatted_address <- purrr::pluck(results, "formatted_address")
    place_id <- purrr::pluck(results, "place_id")
    place_types <- purrr::pluck(results, "types", 1)
    location <- purrr::pluck(results, "geometry", "location")
    latitude <- purrr::pluck(location, "lat")
    longitude <- purrr::pluck(location, "lng")

    return(
      list(
        status = "OK",
        formatted_address = formatted_address,
        place_id = place_id,
        place_types = place_types,
        latitude = latitude,
        longitude = longitude
      )
    )
  }, error = function(e) {
    return(
      list(
        status = "ERROR",
        error = as.character(e$message),
        formatted_address = NA,
        place_id = NA,
        place_types = NA,
        latitude = NA,
        longitude = NA
      )
    )
  })

}


#' Google Maps Places Search
#'
#' @description
#' Search for a company using the Google Maps Places API.
#'
#' @param company_name Character string representing the name of the company.
#' @param company_address Character string representing the address of the company.
#' @param company_phone Character string representing the phone number of the company.
#' @param api_key A character string representing the Google Maps API key.
#'   Defaults to the result from [get_gmaps_api_key()].
#'
#' @returns
#' A list containing the following elements:
#'
#' - `website`: A character string representing the website URL.
#' - `domain`: A character string representing the domain extracted from the website URL.
#' - `display_name`: A character string representing the display name of the place.
#' - `formatted_address`: A character string representing the formatted address of the place.
#' - `phone`: A character string representing the phone number of the place.
#' - `business_status`: A character string representing the business status of the place.
#' - `business_type`: A character string representing the business type of the place.
#' - `latitude`: A numeric value representing the latitude of the place.
#' - `longitude`: A numeric value representing the longitude of the place.
#' - `maps_url`: A character string representing the Google Maps URL of the place.
#' - `place_id`: A character string representing the place ID of the place.
#'
#' @export
#'
#' @importFrom httr2 request req_method req_headers req_body_json req_perform resp_check_status resp_body_json
#' @importFrom purrr pluck
#' @importFrom snakecase to_title_case
#' @importFrom cli cli_alert_info cli_alert_danger
#'
#' @examples
#' \dontrun{
#'   gmaps_places_search("Google", "1600 Amphitheatre Parkway, Mountain View, CA")
#' }
gmaps_places_search <- function(
    company_name,
    company_address,
    company_phone = NULL,
    api_key = "AIzaSyA9iicnOPVX6NmifeCQNYtEhIciwdSgaOc"
) {

  cli::cli_alert_info("Searching for company: {.field {company_name}} at address: {.field {company_address}}.")

  base_url <- "https://places.googleapis.com/v1/places:searchText"
  req_query_txt <- paste(company_name, company_address, sep = " ")
  req_fields <- paste(
    "places.id",
    "places.displayName,",
    "places.formattedAddress,",
    "places.websiteUri,",
    "places.nationalPhoneNumber,",
    "places.internationalPhoneNumber,",
    "places.businessStatus,",
    "places.types,",
    "places.primaryTypeDisplayName,",
    "places.shortFormattedAddress,",
    "places.location",
    collapse = ","
  )

  req <- httr2::request(base_url) |>
    httr2::req_method("POST") |>
    httr2::req_headers(
      `Content-Type` = "application/json",
      `X-Goog-Api-Key` = api_key,
      `X-Goog-FieldMask` = req_fields #"*" #req_fields
    ) |>
    httr2::req_body_json(
      data = list(
        textQuery = req_query_txt
      )
    )

  tryCatch({
    resp <- httr2::req_perform(req)
    httr2::resp_check_status(resp)
    resp_json <- httr2::resp_body_json(resp)
    resp_places <- purrr::pluck(resp_json, "places")

    resp_len <- length(resp_places)
    cli::cli_alert_info(
      "Google Maps Places API returned {.field {resp_len}} results for the search query."
    )

    if (resp_len == 0L) {
      cli::cli_alert_danger(
        "No places found for the search query. Please check the company name and address."
      )
      return(
        list(
          website = NA_character_,
          domain = NA_character_,
          display_name = NA_character_,
          formatted_address = NA_character_,
          phone = NA_character_,
          business_status = NA_character_,
          business_type = NA_character_,
          latitude = NA_real_,
          longitude = NA_real_,
          maps_url = NA_character_,
          place_id = NA_character_
        )
      )
    }

    if (resp_len == 1L) {
      resp_place <- resp_places[[1]]
      return(gmaps_extract_place_info(resp_place))
    }

    # If multiple places are found, we need to determine the best match
    cli::cli_alert_info(
      "Multiple places found for the search query. Determining best match."
    )

    best_match <- gmaps_find_best_match(
      resp_places,
      company_name,
      company_address,
      company_phone
    )

    return(best_match)

  }, error = function(e) {
    cli::cli_alert_danger(
      c(
        "Failed to perform request to Google Maps Places API.\n",
        "Error: {e$message}"
      )
    )
    return(
      list(
        website = NA_character_,
        domain = NA_character_,
        display_name = NA_character_,
        formatted_address = NA_character_,
        phone = NA_character_,
        business_status = NA_character_,
        business_type = NA_character_,
        latitude = NA_real_,
        longitude = NA_real_,
        maps_url = NA_character_,
        place_id = NA_character_,
        error = as.character(e$message)
      )
    )
  })

}

#' Extract Place Information
#'
#' @description
#' This function extracts relevant information from a place object returned by the Google Maps Places API.
#'
#' @param place A list representing a place object returned by the Google Maps Places API.
#'
#' @returns
#' A list containing the following elements:
#'
#' - `display_name`: The display name of the place.
#' - `formatted_address`: The formatted address of the place.
#' - `phone`: The phone number of the place.
#' - `business_status`: The business status of the place.
#' - `business_primary_type`: The primary type of the business.
#' - `business_types`: A vector of business types associated with the place.
#' - `latitude`: The latitude of the place.
#' - `longitude`: The longitude of the place.
#' - `maps_url`: The Google Maps URL of the place.
#' - `place_id`: The unique identifier of the place.
#' - `website`: The website URL of the place.
#' - `domain`: The domain extracted from the website URL.
#'
#' @export
#'
#' @importFrom purrr pluck
#' @importFrom snakecase to_title_case
#' @importFrom cli cli_alert_warning cli_alert_success
gmaps_extract_place_info <- function(place) {

  hold <- list(
    display_name = purrr::pluck(place, "displayName", "text") %||% NA_character_,
    formatted_address = purrr::pluck(place, "formattedAddress") %||% NA_character_,
    phone = purrr::pluck(place, "nationalPhoneNumber") %||% NA_character_,
    business_status = purrr::pluck(place, "businessStatus") %||% NA_character_,
    business_primary_type = purrr::pluck(place, "primaryTypeDisplayName", "text") %||% NA_character_,
    business_types = purrr::pluck(place, "types") |> unlist() |> snakecase::to_title_case() %||% c(NA_character_),
    latitude = purrr::pluck(place, "location", "latitude") %||% NA_real_,
    longitude = purrr::pluck(place, "location", "longitude") %||% NA_real_,
    maps_url = purrr::pluck(place, "googleMapsUri") %||% NA_character_,
    place_id = purrr::pluck(place, "id") %||% NA_character_,
    website = purrr::pluck(place, "websiteUri") %||% NA_character_,
    domain = if (!is.null(purrr::pluck(place, "websiteUri"))) {
      get_domain_from_url(purrr::pluck(place, "websiteUri"))
    } else {
      NA_character_
    }
  )

  fields <- names(hold)
  missing_fields <- fields[is.na(hold)]
  if (length(missing_fields) > 0) {
    cli::cli_alert_warning(
      "The following fields are missing or not found: {.field {missing_fields}}."
    )
  } else {
    cli::cli_alert_success(
      "All fields successfully extracted from the place information."
    )
  }

  return(hold)

}

#' Determine the Best Match from Multiple Places
#'
#' @description
#' This function takes a list of places returned from the Google Maps Places API
#' and compares them to find the best match based on various criteria.
#'
#' @details
#' The function evaluates each place based on:
#'
#' - Type of place (e.g., real estate agency, property management company)
#' - String similarity of the company name
#' - String similarity of the address
#' - Phone number area code match
#' - Presence of a website
#' - Business status (operational or not)
#'
#' The function returns the place with the highest score, indicating the best match.
#'
#' @param places List of places returned from the Google Maps Places API.
#' @param company_name Character string representing the name of the company.
#' @param company_address Character string representing the address of the company.
#' @param company_phone Character string representing the phone number of the company.
#'
#' @returns
#' A list containing the following elements:
#'
#' - `display_name`: The display name of the place.
#' - `formatted_address`: The formatted address of the place.
#' - `phone`: The phone number of the place.
#' - `business_status`: The business status of the place.
#' - `business_primary_type`: The primary type of the business.
#' - `business_types`: A vector of business types associated with the place.
#' - `latitude`: The latitude of the place.
#' - `longitude`: The longitude of the place.
#' - `maps_url`: The Google Maps URL of the place.
#' - `place_id`: The unique identifier of the place.
#' - `website`: The website URL of the place.
#' - `domain`: The domain extracted from the website URL.
#'
#' @export
#'
#' @importFrom purrr pluck pluck_exists
#' @importFrom cli cli_alert_info cli_alert_danger
gmaps_find_best_match <- function(places, company_name, company_address, company_phone = NULL) {

  scores <- numeric(length(places))

  clean_company_name <- tolower(gsub("[[:punct:]]", "", company_name))
  clean_company_address <- tolower(gsub("[[:punct:]]", "", company_address))

  if (!is.null(company_phone)) {
    company_phone_area_code <- sub("^\\D*(\\d{3})\\D*.*$", "\\1", company_phone)
  } else {
    company_phone_area_code <- NULL
  }

  for (i in seq_along(places)) {

    browser()

    place <- places[[i]]
    score <- 0
    max_score <- 30

    real_estate_types <- c(
      "real_estate_agency",
      "property_management_company",
      "corporate_office",
      "real_estate_agent"
    )

    # check types
    if (purrr::pluck_exists(place, "types")) {
      types <- purrr::pluck(place, "types")
      for (type in types) {
        if (type %in% real_estate_types) {
          score <- score + 5
          break
        }
      }
    }

    # company name string similarity
    if (purrr::pluck_exists(place, "displayName", "text") && !is.null(purrr::pluck(place, "displayName", "text"))) {
      place_name <- tolower(gsub("[[:punct:]]", "", purrr::pluck(place, "displayName", "text")))
      name_similarity <- string_similarity(clean_company_name, place_name)
      score <- score + (name_similarity * 10)
    }

    # address string similarity
    if (purrr::pluck_exists(place, "formattedAddress") && !is.null(purrr::pluck(place, "formattedAddress"))) {
      place_address <- tolower(gsub("[[:punct:]]", "", purrr::pluck(place, "formattedAddress")))
      address_similarity <- string_similarity(clean_company_address, place_address)
      score <- score + (address_similarity * 8)
    }

    # phone number area code match
    if (!is.null(company_phone_area_code) && purrr::pluck_exists(place, "nationalPhoneNumber")) {
      place_phone_area_code <- sub("^\\D*(\\d{3})\\D*.*$", "\\1", purrr::pluck(place, "nationalPhoneNumber"))
      if (place_phone_area_code == company_phone_area_code) {
        score <- score + 3
      }
    }

    # website
    if (purrr::pluck_exists(place, "websiteUri") && !is.null(purrr::pluck(place, "websiteUri"))) {
      place_website <- purrr::pluck(place, "websiteUri")
      if (!is.na(place_website) && place_website != "") {
        score <- score + 2
      }
    }

    # business status
    if (purrr::pluck_exists(place, "businessStatus") && !is.null(purrr::pluck(place, "businessStatus"))) {
      place_business_status <- purrr::pluck(place, "businessStatus")
      if (place_business_status == "OPERATIONAL") {
        score <- score + 1
      }
    }

  }

  best_index <- which.max(scores)
  best_place <- places[[best_index]]

  match_quality <- scores[best_index] / max_score

  if (match_quality < 0.5) {
    cli::cli_alert_danger("Best match found, but match quality is low: {.field {match_quality}}.")
  } else {
    cli::cli_alert_info("Best match found with good quality: {.field {match_quality}}.")
  }

  # return extracted place info
  return(gmaps_extract_place_info(best_place))

}

================
File: R/langfuse.R
================
#  ------------------------------------------------------------------------
#
# Title : Langfuse Integrations
#    By : Jimmy Briggs
#  Date : 2025-03-12
#
#  ------------------------------------------------------------------------

#' Langfuse API Client
#'
#' @name langfuse
#'
#' @description
#' A collection of functions for tracking and evaluating LLM interactions
#' using Langfuse.
#'
#' Below are the functions grouped by category:
#'
#' ## Core Client Functions
#'
#' - `lf_client()`: Create a Langfuse API client configuration.
#' - `lf_ingestion()`: Send data to the Langfuse ingestion endpoint.
#'
#' ## Chat Tracing
#'
#' - `lf_trace_chat()`: Trace an individual ellmer chat interaction.
#' - `lf_trace_chat_session()`: Trace a chat interaction within a session.
#' - `lf_add_feedback()`: Add user feedback for a traced chat interaction.
#'
#' ## Session Management
#'
#' - `lf_create_session()`: Create a new session for grouped interactions.
#' - `lf_create_observation()`: Add an observation to a trace.
#' - `lf_create_evaluation()`: Add an evaluation score to a trace.
#'
#' ## Prompt Management
#'
#' - `lf_add_prompt()`: Add a prompt template to Langfuse.
#' - `lf_get_prompt()`: Retrieve a prompt template from Langfuse.
#'
#' ## Dataset & Experimentation
#'
#' - `lf_add_dataset()`: Create a new dataset for testing.
#' - `lf_add_dataset_item()`: Add an item to a dataset.
#' - `lf_run_experiment()`: Run an experiment using a dataset.
#'
#' @importFrom cli cli_alert_warning cli_alert_danger
#' @importFrom httr2 request req_url_path_append req_method req_headers req_auth_basic
#' @importFrom httr2 req_body_json req_perform resp_check_status resp_body_json
#' @importFrom uuid UUIDgenerate
NULL

#' Create a Langfuse API Client
#'
#' @description
#' This function creates a Langfuse API client configuration.
#'
#' @param secret_key Langfuse API Secret Key. Defaults to `LANGFUSE_SECRET_KEY` environment variable.
#' @param public_key Langfuse API Public Key. Defaults to `LANGFUSE_PUBLIC_KEY` environment variable.
#' @param host Langfuse API Host URL. Defaults to `LANGFUSE_HOST` environment variable.
#'   If not set, defaults to `https://us.cloud.langfuse.com` (US region).
#' @param enabled Whether tracing is enabled. Defaults to `TRUE`.
#'
#' @return A list containing the Langfuse client configuration.
#'
#' @export
#'
#' @examples
#' # Create client with environment variables
#' client <- lf_client()
#'
#' # Create client with explicit keys
#' client <- lf_client(
#'   secret_key = "your_secret_key",
#'   public_key = "your_public_key"
#' )
lf_client <- function(
    secret_key = Sys.getenv("LANGFUSE_SECRET_KEY"),
    public_key = Sys.getenv("LANGFUSE_PUBLIC_KEY"),
    host = Sys.getenv("LANGFUSE_HOST", "https://us.cloud.langfuse.com"),
    enabled = TRUE
) {

  if (nzchar(secret_key) && nzchar(public_key)) {
    enabled <- enabled
  } else {
    enabled <- FALSE
    cli::cli_alert_warning("Langfuse credentials missing. Tracing disabled.")
  }

  list(
    secret_key = secret_key,
    public_key = public_key,
    host = host,
    enabled = enabled
  )
}

#' Send Data to Langfuse Ingestion Endpoint
#'
#' @description
#' This function sends data to the Langfuse `/ingestion` endpoint.
#'
#' @param batch The batch data to send as a list
#' @param client A Langfuse client configuration created with `lf_client()`
#'
#' @return The response from Langfuse on success, FALSE on failure
#'
#' @export
#'
lf_ingestion <- function(batch, client) {
  if (is.null(client) || !isTRUE(client$enabled)) {
    return(FALSE)
  }

  req <- httr2::request(client$host) |>
    httr2::req_url_path_append("api", "public", "ingestion") |>
    httr2::req_method("POST") |>
    httr2::req_headers("Content-Type" = "application/json") |>
    httr2::req_auth_basic(username = client$public_key, password = client$secret_key) |>
    httr2::req_body_json(list(batch = batch))

  tryCatch({
    resp <- httr2::req_perform(req)
    httr2::resp_check_status(resp)
    httr2::resp_body_json(resp)
  }, error = function(e) {
    cli::cli_alert_danger("Failed to ingest data: {conditionMessage(e)}")
    return(FALSE)
  })
}

#' Create a Trace Event
#'
#' @description
#' Creates a trace event for Langfuse.
#'
#' @param name Name of the trace
#' @param user_id User ID
#' @param input Input text
#' @param output Output text
#' @param metadata Additional metadata as a list
#'
#' @return A list representing a trace event
#'
#' @keywords internal
lf_create_trace_event <- function(name, user_id = NULL, input = NULL, output = NULL, metadata = NULL) {
  id <- uuid::UUIDgenerate()
  timestamp <- format(Sys.time(), "%Y-%m-%dT%H:%M:%OS6Z")

  event <- list(
    id = id,
    timestamp = timestamp,
    type = "trace-create",
    body = list(
      id = id,
      timestamp = timestamp,
      name = name,
      environment = "production"
    )
  )

  if (!is.null(user_id)) event$body$userId <- user_id
  if (!is.null(input)) event$body$input <- input
  if (!is.null(output)) event$body$output <- output
  if (!is.null(metadata)) event$body$metadata <- metadata

  return(event)
}

#' Create a Generation Event
#'
#' @description
#' Creates a generation event for Langfuse.
#'
#' @param trace_id Parent trace ID
#' @param model Model name
#' @param prompt Prompt text
#' @param completion Completion text
#' @param metadata Additional metadata as a list
#'
#' @return A list representing a generation event
#'
#' @keywords internal
lf_create_generation_event <- function(trace_id, model, prompt, completion = NULL, metadata = NULL) {
  id <- uuid::UUIDgenerate()
  timestamp <- format(Sys.time(), "%Y-%m-%dT%H:%M:%OS6Z")

  event <- list(
    id = id,
    timestamp = timestamp,
    type = "generation-create",
    body = list(
      id = id,
      traceId = trace_id,
      startTime = timestamp,
      model = model,
      prompt = list(
        role = "user",
        content = prompt
      ),
      metadata = metadata %||% list()
    )
  )

  if (!is.null(completion)) {
    event$body$completion <- completion
    event$body$endTime <- timestamp
  }

  return(event)
}

#' Create a Score Event
#'
#' @description
#' Creates a score event for Langfuse.
#'
#' @param trace_id Parent trace ID
#' @param value Score value (0-1)
#' @param comment Optional comment
#'
#' @return A list representing a score event
#'
#' @keywords internal
lf_create_score_event <- function(trace_id, value, comment = NULL) {
  id <- uuid::UUIDgenerate()
  timestamp <- format(Sys.time(), "%Y-%m-%dT%H:%M:%OS6Z")

  event <- list(
    id = id,
    timestamp = timestamp,
    type = "score-create",
    body = list(
      id = id,
      traceId = trace_id,
      name = "user_feedback",
      value = value
    )
  )

  if (!is.null(comment)) event$body$comment <- comment

  return(event)
}

#' Trace an Ellmer Chat Interaction
#'
#' @description
#' Sends a message to an ellmer chat and tracks the interaction with Langfuse.
#'
#' @param chat An ellmer chat object
#' @param message User message
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#' @param user_id Optional user ID
#' @param metadata Optional metadata
#'
#' @return The chat response with trace_id attribute
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # Create a langfuse client
#' lf_client <- lf_client()
#'
#' # Create a chat
#' chat <- ellmer::chat_openai(model = "gpt-4")
#'
#' # Trace a chat interaction
#' response <- lf_trace_chat(
#'   chat = chat,
#'   message = "Tell me about R programming",
#'   langfuse_client = lf_client
#' )
#' }
lf_trace_chat <- function(chat, message, langfuse_client, user_id = NULL, metadata = NULL) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(chat$chat(message))
  }

  # Create trace
  trace_event <- lf_create_trace_event(
    name = "chat_interaction",
    user_id = user_id,
    input = message,
    metadata = metadata
  )

  # Get trace ID
  trace_id <- trace_event$body$id

  # Start timing
  start_time <- Sys.time()

  # Start generation
  gen_event <- lf_create_generation_event(
    trace_id = trace_id,
    model = chat$get_model(),
    prompt = message,
    metadata = list(
      provider = class(chat$provider)[1],
      start_time = format(start_time, "%Y-%m-%dT%H:%M:%OS6Z")
    )
  )

  # Send events to Langfuse
  lf_ingestion(list(trace_event, gen_event), langfuse_client)

  # Call the chat function
  result <- tryCatch({
    chat$chat(message)
  }, error = function(e) {
    # Log error
    error_gen_event <- lf_create_generation_event(
      trace_id = trace_id,
      model = chat$get_model(),
      prompt = message,
      metadata = list(
        error = conditionMessage(e),
        duration_ms = as.numeric(difftime(Sys.time(), start_time, units = "secs")) * 1000
      )
    )
    lf_ingestion(list(error_gen_event), langfuse_client)
    stop(e)
  })

  # End timing
  end_time <- Sys.time()
  duration_ms <- as.numeric(difftime(end_time, start_time, units = "secs")) * 1000

  # Get the completion text
  completion <- chat$last_turn()@text

  # Send completion
  completion_gen_event <- lf_create_generation_event(
    trace_id = trace_id,
    model = chat$get_model(),
    prompt = message,
    completion = completion,
    metadata = list(
      duration_ms = duration_ms
    )
  )

  # Update trace with output
  update_trace_event <- list(
    id = uuid::UUIDgenerate(),
    timestamp = format(end_time, "%Y-%m-%dT%H:%M:%OS6Z"),
    type = "trace-update",
    body = list(
      id = trace_id,
      output = completion
    )
  )

  # Send events to Langfuse
  lf_ingestion(list(completion_gen_event, update_trace_event), langfuse_client)

  # Store trace ID as an attribute
  attr(result, "trace_id") <- trace_id

  return(result)
}

#' Add Feedback for a Chat Interaction
#'
#' @description
#' Adds user feedback for a traced chat interaction.
#'
#' @param result The result returned from `lf_trace_chat()`
#' @param score Score value (0-1)
#' @param comment Optional comment
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#'
#' @return Invisibly returns whether the feedback was sent
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # First trace a chat interaction
#' response <- lf_trace_chat(chat, "Tell me about R", lf_client)
#'
#' # Then add feedback
#' lf_add_feedback(
#'   result = response,
#'   score = 0.95,
#'   comment = "Very helpful response",
#'   langfuse_client = lf_client
#' )
#' }
lf_add_feedback <- function(result, score, comment = NULL, langfuse_client) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(invisible(FALSE))
  }

  trace_id <- attr(result, "trace_id")
  if (is.null(trace_id)) {
    cli::cli_alert_warning("No trace ID found. Was this result created with lf_trace_chat()?")
    return(invisible(FALSE))
  }

  # Validate score
  if (!is.numeric(score) || score < 0 || score > 1) {
    cli::cli_alert_error("Score must be a numeric value between 0 and 1")
    return(invisible(FALSE))
  }

  # Create score event
  score_event <- lf_create_score_event(
    trace_id = trace_id,
    value = score,
    comment = comment
  )

  # Send to Langfuse
  result <- lf_ingestion(list(score_event), langfuse_client)

  return(invisible(!isFALSE(result)))
}

#' Create a Session in Langfuse
#'
#' @description
#' Creates a new session for grouping related traces together.
#'
#' @param name Session name
#' @param user_id Optional user ID
#' @param metadata Optional metadata
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#'
#' @return Session ID if successful, NULL otherwise
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # Create a session
#' session_id <- lf_create_session(
#'   name = "User Learning Session",
#'   user_id = "user-123",
#'   metadata = list(app_version = "1.0.0"),
#'   langfuse_client = lf_client
#' )
#' }
lf_create_session <- function(name, user_id = NULL, metadata = NULL, langfuse_client) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(NULL)
  }

  session_id <- uuid::UUIDgenerate()
  timestamp <- format(Sys.time(), "%Y-%m-%dT%H:%M:%OS6Z")

  event <- list(
    id = uuid::UUIDgenerate(),
    timestamp = timestamp,
    type = "session-create",
    body = list(
      id = session_id,
      name = name,
      timestamp = timestamp
    )
  )

  if (!is.null(user_id)) event$body$userId <- user_id
  if (!is.null(metadata)) event$body$metadata <- metadata

  result <- lf_ingestion(list(event), langfuse_client)

  if (!isFALSE(result)) {
    return(session_id)
  } else {
    return(NULL)
  }
}

#' Create an Observation in Langfuse
#'
#' @description
#' Adds an observation to a trace, such as retrieval results or intermediate calculations.
#'
#' @param trace_id Parent trace ID
#' @param type Observation type (e.g., "completion", "prompt", "retrieval")
#' @param input Input text or data
#' @param output Output text or data
#' @param metadata Optional metadata
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#'
#' @return Observation ID if successful, NULL otherwise
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # First trace a chat interaction
#' response <- lf_trace_chat(chat, "Tell me about R", lf_client)
#' trace_id <- attr(response, "trace_id")
#'
#' # Add an observation
#' lf_create_observation(
#'   trace_id = trace_id,
#'   type = "analysis",
#'   input = "User is asking about R",
#'   output = "User seems to be a beginner",
#'   langfuse_client = lf_client
#' )
#' }
lf_create_observation <- function(trace_id, type, input = NULL, output = NULL, metadata = NULL, langfuse_client) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(NULL)
  }

  observation_id <- uuid::UUIDgenerate()
  timestamp <- format(Sys.time(), "%Y-%m-%dT%H:%M:%OS6Z")

  event <- list(
    id = uuid::UUIDgenerate(),
    timestamp = timestamp,
    type = "observation-create",
    body = list(
      id = observation_id,
      traceId = trace_id,
      type = type,
      timestamp = timestamp
    )
  )

  if (!is.null(input)) event$body$input <- input
  if (!is.null(output)) event$body$output <- output
  if (!is.null(metadata)) event$body$metadata <- metadata

  result <- lf_ingestion(list(event), langfuse_client)

  if (!isFALSE(result)) {
    return(observation_id)
  } else {
    return(NULL)
  }
}

#' Create an Evaluation in Langfuse
#'
#' @description
#' Adds a quality evaluation score to a trace.
#'
#' @param trace_id Parent trace ID
#' @param name Evaluation name
#' @param value Numeric score value (0-1)
#' @param comment Optional comment
#' @param metadata Optional metadata
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#'
#' @return Evaluation ID if successful, NULL otherwise
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # First trace a chat interaction
#' response <- lf_trace_chat(chat, "Tell me about R", lf_client)
#' trace_id <- attr(response, "trace_id")
#'
#' # Add an evaluation
#' lf_create_evaluation(
#'   trace_id = trace_id,
#'   name = "response_quality",
#'   value = 0.95,
#'   comment = "Excellent explanation",
#'   langfuse_client = lf_client
#' )
#' }
lf_create_evaluation <- function(trace_id, name, value, comment = NULL, metadata = NULL, langfuse_client) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(NULL)
  }

  eval_id <- uuid::UUIDgenerate()
  timestamp <- format(Sys.time(), "%Y-%m-%dT%H:%M:%OS6Z")

  event <- list(
    id = uuid::UUIDgenerate(),
    timestamp = timestamp,
    type = "score-create",
    body = list(
      id = eval_id,
      traceId = trace_id,
      name = name,
      value = value,
      timestamp = timestamp
    )
  )

  if (!is.null(comment)) event$body$comment <- comment
  if (!is.null(metadata)) event$body$metadata <- metadata

  result <- lf_ingestion(list(event), langfuse_client)

  if (!isFALSE(result)) {
    return(eval_id)
  } else {
    return(NULL)
  }
}

#' Add a Prompt to Langfuse
#'
#' @description
#' Adds a prompt template to Langfuse for version control and reuse.
#'
#' @param name Prompt name
#' @param prompt Prompt text or array of message objects (depends on type)
#' @param type Prompt type, either "text" or "chat"
#' @param config Optional configuration parameters (model, temperature, etc.)
#' @param labels Optional list of labels for organizing prompts
#' @param tags Optional list of tags for categorizing prompts
#' @param commit_message Optional message describing changes (for versioning)
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#'
#' @return Prompt ID if successful, NULL otherwise
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # Add a text prompt template
#' prompt_id <- lf_add_prompt(
#'   name = "r_tutorial_text",
#'   prompt = "You are a helpful R programming tutor. Explain {{topic}} with examples.",
#'   type = "text",
#'   langfuse_client = lf_client
#' )
#'
#' # Add a chat prompt template
#' prompt_id <- lf_add_prompt(
#'   name = "r_tutorial_chat",
#'   prompt = list(
#'     list(role = "system", content = "You are a helpful R programming tutor."),
#'     list(role = "user", content = "Explain {{topic}} in simple terms with examples.")
#'   ),
#'   type = "chat",
#'   config = list(model = "gpt-4", temperature = 0.7),
#'   labels = c("tutorial", "r-programming"),
#'   langfuse_client = lf_client
#' )
#' }
lf_add_prompt <- function(name, prompt, type = c("chat", "text"), config = NULL,
                          labels = NULL, tags = NULL, commit_message = NULL,
                          langfuse_client) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(NULL)
  }

  type <- match.arg(type)

  # Prepare the request body
  body <- list(
    name = name,
    type = type
  )

  # Handle the prompt format based on type
  if (type == "text") {
    # For text prompts, ensure it's a simple string
    if (!is.character(prompt) || length(prompt) != 1) {
      cli::cli_alert_danger("For text prompts, 'prompt' must be a single character string")
      return(NULL)
    }
    body$prompt = prompt
  } else if (type == "chat") {
    # For chat prompts, ensure it's an array of messages with role/content
    if (is.character(prompt) && length(prompt) == 1) {
      # Convert simple string to a chat format with user role
      body$prompt = list(list(role = "user", content = prompt))
    } else if (is.list(prompt)) {
      # Validate the list structure
      valid <- all(sapply(prompt, function(msg) {
        is.list(msg) && !is.null(msg$role) && !is.null(msg$content)
      }))

      if (!valid) {
        cli::cli_alert_danger("Chat prompts must be a list of objects with 'role' and 'content' fields")
        return(NULL)
      }
      body$prompt = prompt
    } else {
      cli::cli_alert_danger("Invalid prompt format for chat type")
      return(NULL)
    }
  }

  # Add optional parameters if provided
  if (!is.null(config)) body$config <- config
  if (!is.null(labels)) body$labels <- as.list(labels)
  if (!is.null(tags)) body$tags <- as.list(tags)
  if (!is.null(commit_message)) body$commitMessage <- commit_message

  # Create the API request
  req <- httr2::request(langfuse_client$host) |>
    httr2::req_url_path_append("api", "public", "v2", "prompts") |>
    httr2::req_method("POST") |>
    httr2::req_headers("Content-Type" = "application/json") |>
    httr2::req_auth_basic(username = langfuse_client$public_key, password = langfuse_client$secret_key) |>
    httr2::req_body_json(body)

  tryCatch({
    resp <- httr2::req_perform(req)
    httr2::resp_check_status(resp)
    result <- httr2::resp_body_json(resp)
    return(result$id)
  }, error = function(e) {
    cli::cli_alert_danger("Failed to create prompt: {conditionMessage(e)}")
    return(NULL)
  })
}

#' Get a Prompt from Langfuse
#'
#' @description
#' Retrieves a prompt template from Langfuse.
#'
#' @param prompt_name Name of the prompt to retrieve
#' @param version Specific version number to retrieve (if NULL, latest version will be fetched)
#' @param label Label of the prompt to retrieve (optional)
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#'
#' @return Prompt object if successful, NULL otherwise
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # Get the latest version of a prompt
#' prompt <- lf_get_prompt(
#'   prompt_name = "r_tutorial_chat",
#'   langfuse_client = lf_client
#' )
#'
#' # Get a specific version of a prompt
#' prompt <- lf_get_prompt(
#'   prompt_name = "r_tutorial_chat",
#'   version = 2,
#'   langfuse_client = lf_client
#' )
#'
#' # Get a prompt with a specific label
#' prompt <- lf_get_prompt(
#'   prompt_name = "r_tutorial_chat",
#'   label = "development",
#'   langfuse_client = lf_client
#' )
#' }
lf_get_prompt <- function(prompt_name, version = NULL, label = NULL, langfuse_client) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(NULL)
  }

  # Validate prompt name
  if (is.null(prompt_name) || !is.character(prompt_name) || nchar(prompt_name) == 0) {
    cli::cli_alert_danger("'prompt_name' must be a non-empty string")
    return(NULL)
  }

  # If version is not provided, try to get a list of versions first
  if (is.null(version) && is.null(label)) {
    # Get all prompt versions
    versions_req <- httr2::request(langfuse_client$host) |>
      httr2::req_url_path_append("api", "public", "v2", "prompts", prompt_name, "versions") |>
      httr2::req_method("GET") |>
      httr2::req_auth_basic(username = langfuse_client$public_key, password = langfuse_client$secret_key)

    versions_result <- tryCatch({
      resp <- httr2::req_perform(versions_req)
      httr2::resp_check_status(resp)
      httr2::resp_body_json(resp)
    }, error = function(e) {
      cli::cli_alert_warning("Failed to get prompt versions: {conditionMessage(e)}")
      return(NULL)
    })

    # If we got versions, use the latest one
    if (!is.null(versions_result) && length(versions_result) > 0) {
      # Sort by version number (descending)
      version_numbers <- sapply(versions_result, function(v) as.integer(v$version))
      latest_version <- max(version_numbers)
      cli::cli_alert_info("Using latest version: {latest_version}")
      version <- latest_version
    } else {
      # Default to version 1 if we couldn't get a list of versions
      cli::cli_alert_info("Could not determine latest version, defaulting to version 1")
      version <- 1
    }
  }

  # Build the request for a specific version or label
  req <- httr2::request(langfuse_client$host) |>
    httr2::req_url_path_append("api", "public", "v2", "prompts", prompt_name) |>
    httr2::req_method("GET") |>
    httr2::req_auth_basic(username = langfuse_client$public_key, password = langfuse_client$secret_key)

  # Add optional query parameters
  if (!is.null(version)) {
    req <- httr2::req_url_query(req, version = as.integer(version))
  }

  if (!is.null(label)) {
    req <- httr2::req_url_query(req, label = label)
  }

  tryCatch({
    resp <- httr2::req_perform(req)
    httr2::resp_check_status(resp)
    result <- httr2::resp_body_json(resp)
    return(result)
  }, error = function(e) {
    cli::cli_alert_danger("Failed to get prompt: {conditionMessage(e)}")
    return(NULL)
  })
}

#' Add a Dataset to Langfuse
#'
#' @description
#' Creates a new dataset for testing and evaluation.
#'
#' @param name Dataset name
#' @param description Dataset description (optional)
#' @param metadata Additional metadata as a list (optional)
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#'
#' @return Dataset ID if successful, NULL otherwise
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # Create a dataset
#' dataset_id <- lf_add_dataset(
#'   name = "R Programming Questions",
#'   description = "Common questions about R programming for testing",
#'   langfuse_client = lf_client
#' )
#' }
lf_add_dataset <- function(name, description = NULL, metadata = NULL, langfuse_client) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(NULL)
  }

  # Build request body
  body <- list(name = name)
  if (!is.null(description)) body$description <- description
  if (!is.null(metadata)) body$metadata <- metadata

  req <- httr2::request(langfuse_client$host) |>
    httr2::req_url_path_append("api", "public", "v2", "datasets") |>
    httr2::req_method("POST") |>
    httr2::req_headers("Content-Type" = "application/json") |>
    httr2::req_auth_basic(username = langfuse_client$public_key, password = langfuse_client$secret_key) |>
    httr2::req_body_json(body)

  tryCatch({
    resp <- httr2::req_perform(req)
    httr2::resp_check_status(resp)
    result <- httr2::resp_body_json(resp)
    return(result$id)
  }, error = function(e) {
    cli::cli_alert_danger("Failed to create dataset: {conditionMessage(e)}")
    return(NULL)
  })
}

#' Add an Item to a Dataset
#'
#' @description
#' Adds a test item to a Langfuse dataset.
#'
#' @param dataset_name Name of the dataset
#' @param input Input text or data
#' @param expected_output Expected output (optional)
#' @param metadata Optional metadata as a list
#' @param source_trace_id Optional trace ID that this item is based on
#' @param source_observation_id Optional observation ID that this item is based on
#' @param id Optional custom ID for the dataset item (must be unique)
#' @param status Item status ("ACTIVE" or "ARCHIVED", defaults to "ACTIVE")
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#'
#' @return Item ID if successful, NULL otherwise
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # Add an item to a dataset
#' lf_add_dataset_item(
#'   dataset_name = "R Programming Questions",
#'   input = "What are the differences between a list and a data frame in R?",
#'   expected_output = "A detailed comparison of lists and data frames",
#'   metadata = list(category = "data_structures"),
#'   langfuse_client = lf_client
#' )
#'
#' # Add an item with a custom ID
#' lf_add_dataset_item(
#'   dataset_name = "R Programming Questions",
#'   input = "How do you create a ggplot2 visualization?",
#'   id = "ggplot2-question",
#'   langfuse_client = lf_client
#' )
#' }
lf_add_dataset_item <- function(dataset_name, input, expected_output = NULL,
                                metadata = NULL, source_trace_id = NULL,
                                source_observation_id = NULL, id = NULL,
                                status = "ACTIVE", langfuse_client) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(NULL)
  }

  # Validate required parameters
  if (is.null(dataset_name) || !is.character(dataset_name) || nchar(dataset_name) == 0) {
    cli::cli_alert_danger("'dataset_name' must be a non-empty string")
    return(NULL)
  }

  # Build the request body
  body <- list(
    datasetName = dataset_name,
    input = input,
    status = status
  )

  # Add optional fields
  if (!is.null(expected_output)) body$expectedOutput <- expected_output
  if (!is.null(metadata)) body$metadata <- metadata
  if (!is.null(source_trace_id)) body$sourceTraceId <- source_trace_id
  if (!is.null(source_observation_id)) body$sourceObservationId <- source_observation_id
  if (!is.null(id)) body$id <- id

  req <- httr2::request(langfuse_client$host) |>
    httr2::req_url_path_append("api", "public", "dataset-items") |>
    httr2::req_method("POST") |>
    httr2::req_headers("Content-Type" = "application/json") |>
    httr2::req_auth_basic(username = langfuse_client$public_key, password = langfuse_client$secret_key) |>
    httr2::req_body_json(body)

  tryCatch({
    resp <- httr2::req_perform(req)
    httr2::resp_check_status(resp)
    result <- httr2::resp_body_json(resp)
    return(result$id)
  }, error = function(e) {
    cli::cli_alert_danger("Failed to add dataset item: {conditionMessage(e)}")
    return(NULL)
  })
}

#' Run an Experiment on a Dataset
#'
#' @description
#' Runs an experiment by processing items from a dataset and recording the results.
#'
#' @param name Experiment name
#' @param dataset_name Name of the dataset to use
#' @param chat_function Function to process each item (should accept input and return output)
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#' @param max_items Maximum number of items to process (0 = all)
#' @param filter_status Filter items by status ("ACTIVE" or "ARCHIVED")
#'
#' @return Experiment results as a list
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # Run an experiment with a fresh chat instance for each item
#' experiment_results <- lf_run_experiment(
#'   name = "R Tutor Test",
#'   dataset_name = "R Programming Questions",
#'   chat_function = function(input) {
#'     # Create a fresh chat for each item
#'     item_chat <- ellmer::chat_openai(model = "gpt-4o")
#'     # The chat() method returns the text response directly
#'     return(item_chat$chat(input))
#'   },
#'   langfuse_client = lf_client,
#'   max_items = 10
#' )
#' }
lf_run_experiment <- function(name, dataset_name, chat_function, langfuse_client,
                              max_items = 0, filter_status = "ACTIVE") {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    cli::cli_alert_warning("Langfuse client not configured or disabled")
    return(NULL)
  }

  # Get dataset items
  req <- httr2::request(langfuse_client$host) |>
    httr2::req_url_path_append("api", "public", "dataset-items") |>
    httr2::req_method("GET") |>
    httr2::req_auth_basic(username = langfuse_client$public_key, password = langfuse_client$secret_key) |>
    httr2::req_url_query(datasetName = dataset_name)

  # Add status filter if provided
  if (!is.null(filter_status)) {
    req <- httr2::req_url_query(req, status = filter_status)
  }

  items_response <- tryCatch({
    resp <- httr2::req_perform(req)
    httr2::resp_check_status(resp)
    httr2::resp_body_json(resp)
  }, error = function(e) {
    cli::cli_alert_danger("Failed to get dataset items: {conditionMessage(e)}")
    return(NULL)
  })

  # Handle different possible response formats from the API
  items <- NULL
  if (is.null(items_response)) {
    items <- NULL
  } else if (is.list(items_response) && length(items_response) > 0) {
    if ("items" %in% names(items_response) && is.list(items_response$items)) {
      # If response has an "items" field that's a list, use that
      items <- items_response$items
    } else {
      # Otherwise assume the response itself is the list of items
      items <- items_response
    }
  }

  if (is.null(items) || length(items) == 0) {
    cli::cli_alert_warning("No items found in dataset")
    return(NULL)
  }

  # Limit items if requested
  if (max_items > 0 && max_items < length(items)) {
    items <- items[1:max_items]
  }

  # Create experiment session
  session_id <- lf_create_session(
    name = paste0("Experiment: ", name),
    metadata = list(
      dataset_name = dataset_name,
      item_count = length(items)
    ),
    langfuse_client = langfuse_client
  )

  # Process each item
  results <- lapply(items, function(item) {
    # Extract and validate item ID
    item_id <- "unknown"
    if (!is.null(item$id) && is.character(item$id) && nchar(item$id) > 0) {
      item_id <- item$id
    }

    # Make sure we have a valid input
    if (is.null(item$input) || !is.character(item$input) || nchar(item$input) == 0) {
      cli::cli_alert_warning("Item {item_id} has no valid input, skipping")
      return(list(
        item_id = item_id,
        error = "No valid input found",
        skipped = TRUE
      ))
    }

    cli::cli_alert_info("Processing item {item_id}")

    # Create a trace for this item
    trace_event <- lf_create_trace_event(
      name = paste0("experiment_item_", item_id),
      metadata = list(
        dataset_name = dataset_name,
        item_id = item_id,
        session_id = session_id,
        experiment_name = name
      )
    )
    trace_id <- trace_event$body$id

    # Send the trace event
    lf_ingestion(list(trace_event), langfuse_client)

    # Process the item using the provided function
    start_time <- Sys.time()
    output <- NULL
    error <- NULL

    # Use tryCatch to properly capture any errors
    tryCatch({
      output <- chat_function(item$input)

      # Ensure output is a character string
      if (!is.character(output)) {
        output <- as.character(output)
      }
    }, error = function(e) {
      error <- conditionMessage(e)
      cli::cli_alert_danger("Error processing item {item_id}: {error}")
    })

    end_time <- Sys.time()
    duration_ms <- as.numeric(difftime(end_time, start_time, units = "secs")) * 1000

    # Create appropriate events based on success or failure
    if (is.null(error)) {
      # Create a generation event with the successful output
      gen_event <- lf_create_generation_event(
        trace_id = trace_id,
        model = "experiment",
        prompt = item$input,
        completion = output,
        metadata = list(
          duration_ms = duration_ms
        )
      )

      # Update trace with output
      update_trace_event <- list(
        id = uuid::UUIDgenerate(),
        timestamp = format(end_time, "%Y-%m-%dT%H:%M:%OS6Z"),
        type = "trace-update",
        body = list(
          id = trace_id,
          output = output
        )
      )

      # Send events to Langfuse
      lf_ingestion(list(gen_event, update_trace_event), langfuse_client)

      # If expected output exists, create an evaluation
      if (!is.null(item$expectedOutput)) {
        # Here you could add an automated evaluation
      }
    } else {
      # Log the error to Langfuse
      error_gen_event <- lf_create_generation_event(
        trace_id = trace_id,
        model = "experiment",
        prompt = item$input,
        metadata = list(
          error = error,
          duration_ms = duration_ms
        )
      )

      # Update trace with error info
      error_trace_event <- list(
        id = uuid::UUIDgenerate(),
        timestamp = format(end_time, "%Y-%m-%dT%H:%M:%OS6Z"),
        type = "trace-update",
        body = list(
          id = trace_id,
          output = paste("Error:", error),
          status = "error"
        )
      )

      lf_ingestion(list(error_gen_event, error_trace_event), langfuse_client)
    }

    return(list(
      item_id = item_id,
      input = item$input,
      output = output,
      error = error,
      trace_id = trace_id,
      duration_ms = duration_ms
    ))
  })

  return(list(
    experiment_name = name,
    dataset_name = dataset_name,
    session_id = session_id,
    results = results
  ))
}

#' Trace a Chat Interaction within a Session
#'
#' @description
#' Sends a message to an ellmer chat and tracks the interaction with Langfuse
#' within a defined session.
#'
#' @param chat An ellmer chat object
#' @param message User message
#' @param session_id Session ID for grouped traces from `lf_create_session()`
#' @param langfuse_client Langfuse client configuration from `lf_client()`
#' @param user_id Optional user ID
#' @param metadata Optional metadata
#'
#' @return The chat response with trace_id and session_id attributes
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # Create a langfuse client and session
#' lf_client <- lf_client()
#' session_id <- lf_create_session(name = "Learning Session", langfuse_client = lf_client)
#'
#' # Create a chat
#' chat <- ellmer::chat_openai(model = "gpt-4")
#'
#' # Trace chat interactions in the session
#' response1 <- lf_trace_chat_session(
#'   chat = chat,
#'   message = "What are the main features of R?",
#'   session_id = session_id,
#'   langfuse_client = lf_client
#' )
#'
#' response2 <- lf_trace_chat_session(
#'   chat = chat,
#'   message = "Tell me more about data visualization in R",
#'   session_id = session_id,
#'   langfuse_client = lf_client
#' )
#' }
lf_trace_chat_session <- function(chat, message, session_id, langfuse_client, user_id = NULL, metadata = NULL) {
  if (is.null(langfuse_client) || !isTRUE(langfuse_client$enabled)) {
    return(chat$chat(message))
  }

  # Create trace with session ID
  trace_event <- lf_create_trace_event(
    name = "chat_interaction",
    user_id = user_id,
    input = message,
    metadata = metadata
  )

  # Add session ID to trace
  trace_event$body$sessionId <- session_id

  # Get trace ID
  trace_id <- trace_event$body$id

  # Start timing
  start_time <- Sys.time()

  # Start generation
  gen_event <- lf_create_generation_event(
    trace_id = trace_id,
    model = chat$get_model(),
    prompt = message,
    metadata = list(
      provider = class(chat$provider)[1],
      start_time = format(start_time, "%Y-%m-%dT%H:%M:%OS6Z")
    )
  )

  # Send events to Langfuse
  lf_ingestion(list(trace_event, gen_event), langfuse_client)

  # Call the chat function
  result <- tryCatch({
    chat$chat(message)
  }, error = function(e) {
    # Log error
    error_gen_event <- lf_create_generation_event(
      trace_id = trace_id,
      model = chat$get_model(),
      prompt = message,
      metadata = list(
        error = conditionMessage(e),
        duration_ms = as.numeric(difftime(Sys.time(), start_time, units = "secs")) * 1000
      )
    )
    lf_ingestion(list(error_gen_event), langfuse_client)
    stop(e)
  })

  # End timing
  end_time <- Sys.time()
  duration_ms <- as.numeric(difftime(end_time, start_time, units = "secs")) * 1000

  # Get the completion text
  completion <- chat$last_turn()@text

  # Send completion
  completion_gen_event <- lf_create_generation_event(
    trace_id = trace_id,
    model = chat$get_model(),
    prompt = message,
    completion = completion,
    metadata = list(
      duration_ms = duration_ms
    )
  )

  # Update trace with output
  update_trace_event <- list(
    id = uuid::UUIDgenerate(),
    timestamp = format(end_time, "%Y-%m-%dT%H:%M:%OS6Z"),
    type = "trace-update",
    body = list(
      id = trace_id,
      output = completion
    )
  )

  # Send events to Langfuse
  lf_ingestion(list(completion_gen_event, update_trace_event), langfuse_client)

  # Store trace ID and session ID as attributes
  attr(result, "trace_id") <- trace_id
  attr(result, "session_id") <- session_id

  return(result)
}

================
File: R/logger.R
================
#  ------------------------------------------------------------------------
#
# Title : Logger
#    By : Jimmy Briggs
#  Date : 2025-03-14
#
#  ------------------------------------------------------------------------

# logger ----------------------------------------------------------------------------------------------------------

#' Initialize Logger
#'
#' @description
#' Initializes the logger with the specified parameters.
#'
#' @param level The logging level. Default is `logger::INFO`.
#' @param formatter The formatter function. Default is `logger::formatter_json`.
#' @param layout The layout function. Default is `logger::layout_json`.
#' @param log_file The log file path. Default is `NULL`, which uses the default log path.
#' @param console Whether to log to the console. Default is `TRUE`.
#' @param async Whether to use asynchronous logging. Default is `FALSE`.
#' @param namespace The namespace for the logger. Default is `NULL`, which uses the package name.
#' @param frame The parent frame for the logger. Default is `parent.frame()`.
#' @param ... Additional arguments to pass to the logger.
#'
#' @returns
#' Invisibly returns a list of logger metadata variables.
#'
#' @export
#'
#' @importFrom logger log_threshold log_appender log_info log_error log_warn log_debug log_trace
#' @importFrom glue glue
logger_init <- function(
    level = logger::INFO,
    formatter = NULL,
    layout = NULL,
    log_file = NULL,
    console = TRUE,
    async = FALSE,
    namespace = NULL,
    frame = parent.frame(),
    ...
) {

  # namespace
  logger_ns <- if (is.null(namespace)) {
    if (is.null(.logger_env$logger_ns)) {
      .logger_env$logger_ns <- "noclocksai"
    } else {
      .logger_env$logger_ns
    }
  } else {
    namespace
  }
  assign("logger_ns", logger_ns, envir = .logger_env)

  # log file
  logger_file <- if (is.null(log_file)) {
    .default_log_path()
  } else if (is.logical(log_file) && log_file) {
    .default_log_path()
  } else if (is.logical(log_file) && !log_file) {
    NULL
  } else if (is.character(log_file)) {
    normalizePath(log_file, mustWork = FALSE)
  } else {
    NULL
  }
  assign("log_file", logger_file, envir = .logger_env)

  # threshold
  logger::log_threshold(level, namespace = logger_ns)
  assign("log_level", level, envir = .logger_env)

  # formatter
  if (is.null(formatter)) {
    formatter <- logger::formatter_json
  }
  assign("formatter", formatter, envir = .logger_env)

  # layout
  if (is.null(layout)) {
    layout <- logger::layout_json
  }
  assign("layout", layout, envir = .logger_env)

  # console
  if (console) {
    log_appender <- logger::appender_tee(file = logger_file, append = TRUE)
  } else {
    log_appender <- logger::appender_file(logger_file, append = TRUE)
  }

  # async
  if (async) {
    log_appender <- logger::appender_async(log_appender, namespace = logger_ns, init = function() logger::log_info("Async logger initialized"))
  }

  # appender
  logger::log_appender(log_appender, namespace = logger_ns)

  msg <- glue::glue(
    "Logger initialized with level: {level}, ",
    "formatter: {formatter}, ",
    "layout: {layout}, ",
    "log_file: {log_file}, ",
    "console: {console}, ",
    "async: {async}"
  )

  logger::log_info(msg, namespace = logger_ns)

  meta <- logger::get_logger_meta_variables(namespace = logger_ns)
  invisible(meta)
}

#' Reset Logger Configuration
#'
#' @description
#' Resets the logger configuration to the default settings and removes all hooks.
#'
#' @param namespace The namespace for the logger. Default is `NULL`, which uses the package name.
#'
#' @export
logger_reset <- function(namespace = NULL) {

  logger_hooks_reset()

  logger::log_threshold(logger::INFO, namespace = namespace)
  logger::log_formatter(logger::formatter_glue, namespace = namespace)
  logger::log_layout(logger::layout_glue, namespace = namespace)
  logger::log_appender(logger::appender_console(), namespace = namespace)

  logger::log_info("Logger reset to default configuration", namespace = namespace)

  invisible(TRUE)

}


# log functions ---------------------------------------------------------------------------------------------------

#' Log a Function Call with Arguments
#'
#' @param fn_name Name of the function being called
#' @param args List of arguments
#' @param level Logging level (default: "INFO")
#' @param namespace Logger namespace
#'
#' @export
log_function_call <- function(fn_name, args = list(), level = "INFO",
                              namespace = .logger_env$logger_ns) {
  # Format arguments
  args_str <- paste(
    names(args),
    "=",
    vapply(args, function(x) {
      if (is.character(x)) {
        paste0("\"", substr(x, 1, 50), if(nchar(x) > 50) "..." else "", "\"")
      } else if (is.null(x)) {
        "NULL"
      } else if (length(x) > 5) {
        paste0("[", class(x)[1], "(", length(x), ")]")
      } else {
        paste(as.character(x), collapse = ", ")
      }
    }, character(1)),
    collapse = ", "
  )

  # Log the function call
  log_fn <- switch(toupper(level),
                   "TRACE" = logger::log_trace,
                   "DEBUG" = logger::log_debug,
                   "INFO" = logger::log_info,
                   "WARN" = logger::log_warn,
                   "ERROR" = logger::log_error,
                   "FATAL" = logger::log_fatal,
                   logger::log_info)

  log_fn(paste0("Call: ", fn_name, "(", args_str, ")"), namespace = namespace)
}

# hooks -----------------------------------------------------------------------------------------------------------

#' Logger Hooks
#'
#' @name logger_hooks
#'
#' @description
#' Setup or reset logging hooks for various types of messages in R.
#'
#' - `logger_hooks_init()`: Initializes the logging hooks.
#' - `logger_hooks_reset()`: Resets the logging hooks to their original state.
#'
#' @param log_errors Whether to log error messages
#' @param log_warnings Whether to log warning messages
#' @param log_messages Whether to log regular messages
#' @param log_cli Whether to log CLI alerts
#' @param log_ellmer Whether to log ellmer chat interactions
#' @param error_traceback Whether to include traceback in error logs
#' @param error_quiet Whether to suppress errors after logging
#'
#' @export
logger_hooks_init <- function(
    log_errors = TRUE,
    log_warnings = TRUE,
    log_messages = TRUE,
    log_cli = TRUE,
    error_traceback = FALSE,
    error_quiet = FALSE
) {

  logger_hooks_reset()

  if (log_messages) { globalCallingHandlers(message = .log_hook_messages()) }
  if (log_warnings) { globalCallingHandlers(warning = .log_hook_warnings()) }
  if (log_errors) { globalCallingHandlers(error = .log_hook_errors(error_quiet, error_traceback)) }
  if (log_cli && requireNamespace("cli", quietly = TRUE)) { .log_cli_alerts() }

  invisible()
}

#' @rdname logger_hooks
#' @export
logger_hooks_reset <- function() {

  existing_handlers <- names(globalCallingHandlers())

  for (handler in existing_handlers) {
    globalCallingHandlers(handler = NULL)
  }

  if (requireNamespace("cli", quietly = TRUE)) {
    cli_fns <- c(
      "cli_alert_success",
      "cli_alert_danger",
      "cli_alert_warning",
      "cli_alert_info"
    )
    for (fn in cli_fns) {
      if (exists(fn, where = asNamespace("cli"), mode = "function")) {
        try(untrace(what = fn, where = asNamespace("cli")), silent = TRUE)
      }
    }
  }

  invisible()
}

# environment -----------------------------------------------------------------------------------------------------

.logger_env <- new.env()

.logger_env$logger_ns <- "noclocksai"
.logger_env$log_file <- NULL
.logger_env$log_level <- logger::INFO
.logger_env$formatter <- logger::formatter_json
.logger_env$layout <- logger::layout_json
.logger_env$console <- TRUE
.logger_env$async <- FALSE
.logger_env$log_errors <- TRUE
.logger_env$log_warnings <- TRUE
.logger_env$log_messages <- TRUE
.logger_env$log_cli_alerts <- TRUE

.logger_env$base <- list()

.logger_env$cli <- list()
.logger_env$cli$alert_info <- cli::cli_alert_info
.logger_env$cli$alert_warning <- cli::cli_alert_warning
.logger_env$cli$alert_error <- cli::cli_alert_danger
.logger_env$cli$alert_success <- cli::cli_alert_success


# internals -------------------------------------------------------------------------------------------------------

.default_log_path <- function(extension = c("log", "json")) {
  extension <- match.arg(extension)
  pkg_name <- "noclocksai"
  log_dir <- file.path(rappdirs::user_log_dir(pkg_name))

  dir_created <- dir.create(log_dir, recursive = TRUE, showWarnings = FALSE)
  if (!dir_created) { warning("Could not create log directory: ", log_dir) }
  log_file <- paste0(pkg_name, ".", extension)
  file.path(log_dir, log_file)
}

.log_hook_errors <- function(quiet = FALSE, traceback = FALSE, namespace = NULL) {
  structure(
    function(msg) {
      call_info <- if (!is.null(msg$call)) {
        tryCatch(
          {
            deparse(msg$call)[1]
          },
          error = function(e) { "Unknown" }
        )
      } else {
        "Unknown"
      }

      logger::log_error(
        paste0("[", call_info, "]", msg$message),
        .topcall = msg$call
      )

      if (traceback) {
        bt <- .traceback(3L)
        logger::log_level(logger::ERROR, "Traceback:", .topcall = msg$call)
        for (i in seq_along(bt)) {
          message <- paste0(length(bt) - i + 1L, ": ", bt[[i]])
          ref <- attr(bt[[i]], "srcref")
          file <- attr(ref, "srcfile")
          if (inherits(file, "srcfile")) {
            file <- basename(file$filename)
            line <- paste(unique(c(ref[1L], ref[3L])), collapse = "-")
            message <- paste0(message, " at ", file, " #", line)
          }
          logger::log_level(
            logger::ERROR,
            logger::skip_formatter(message),
            .topcall = msg$call
          )
        }
      }
      if (quiet) { invokeRestart("abort") }
    },
    implements = "log_errors"
  )
}

.log_hook_messages <- function() {
  structure(
    function(msg) {
      logger::log_info(msg$message, .topcall = msg$call)
    },
    implements = "log_messages"
  )
}

.log_hook_warnings <- function() {
  structure(
    function(msg) {
      logger::log_warn(msg$message, .topcall = msg$call)
    },
    implements = "log_warnings"
  )
}

.log_cli_alerts <- function() {

  if (any(sapply(
    globalCallingHandlers()[names(globalCallingHandlers()) == "cli_alert"],
    attr, which = "implements") == "log_cli_alerts"
  )) {
    warning("CLI alert logging already registered")
    return(invisible())
  }

  cli_handlers <- list(
    cli_alert_success = function(msg) {
      logger::log_info(paste("[SUCCESS]", msg$message), .topcall = msg$call)
    },
    cli_alert_danger = function(msg) {
      logger::log_warn(paste("[DANGER]", msg$message), .topcall = msg$call)
    },
    cli_alert_warning = function(msg) {
      logger::log_warn(paste("[WARNING]", msg$message), .topcall = msg$call)
    },
    cli_alert_info = function(msg) {
      logger::log_info(paste("[INFO]", msg$message), .topcall = msg$call)
    }
  )

  for (fn_name in names(cli_handlers)) {
    if (exists(fn_name, where = asNamespace("cli"), mode = "function")) {
      trace(
        what = fn_name,
        where = asNamespace("cli"),
        tracer = cli_handlers[[fn_name]],
        print = FALSE
      )
    }
  }

  invisible()
}

.log_ellmer_chats <- function(namespace = .logger_env$logger_ns) {

  if (!requireNamespace("ellmer", quietly = TRUE)) {
    warning("ellmer package not available")
    return(invisible(FALSE))
  }

  if (!exists("ellmer_original_methods", envir = .logger_env)) {
    .logger_env$ellmer_original_methods <- list()

    Chat <- ellmer:::Chat

    if (exists("chat", where = Chat$public_methods)) {
      .logger_env$ellmer_original_methods$chat <- Chat$public_methods$chat

      Chat$set("public", "chat", function(prompt, ...) {
        logger::log_info(paste0("> ", prompt), namespace = namespace)

        current_turns <- length(self$get_turns(detailed = TRUE))

        result <- .logger_env$ellmer_original_methods$chat(self, prompt, ...)

        all_turns <- self$get_turns(detailed = TRUE)
        new_turns <- all_turns[(current_turns + 1):length(all_turns)]

        for (turn in new_turns) {
          if (turn@role == "assistant") {
            response_text <- gsub("\n", "\n< ", turn@text)
            logger::log_info(paste0("< ", response_text), namespace = namespace)

            if (length(turn@tokens) == 2) {
              logger::log_debug(
                paste0("< [Tokens: prompt=", turn@tokens[1],
                       ", completion=", turn@tokens[2], "]"),
                namespace = namespace
              )
            }

            logger::log_info("<", namespace = namespace)
          }
        }

        return(result)
      }, overwrite = TRUE)

      logger::log_debug("Registered ellmer chat logging", namespace = namespace)
    }
  } else {
    warning("ellmer chat logging already registered")
  }

  invisible(TRUE)
}

# onLoad ----------------------------------------------------------------------------------------------------------

rlang::on_load(
  expr = {
    .logger_hooks_init()
  }
)

================
File: R/mermaid.R
================
#  ------------------------------------------------------------------------
#
# Title : Mermaid Diagrams
#    By : Jimmy Briggs
#  Date : 2025-03-14
#
#  ------------------------------------------------------------------------

#' Generate Mermaid Diagrams
#'
#' @description
#' Generate a mermaid diagram using the dedicated [mermaid_agent()] based on a prompt or code.
#'
#' @param chat_agent An optional chat agent object. If not provided, a default agent will be created.
#' @param prompt A prompt to generate the diagram. If not provided, a default prompt will be used.
#' @param ... Additional arguments passed to [prompt_mermaid_user()]. (e.g. `context`, `code`, `chart_type`, `chart_styles`).
#'
#' @returns
#' A character string containing the mermaid code block.
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # generate a diagram based off of code
#' example <- "
#'   starwars |>
#'     group_by(species) |>
#'     summarise(
#'       n = n(),
#'       mass = mean(mass, na.rm = TRUE)
#'     ) |>
#'     filter(
#'       n > 1,
#'       mass > 50
#'     )
#' "
#' create_mermaid_diagram(code = example)
#'
#' # generate a diagram based off of a prompt
#' prompt <- prompt_mermaid_user("Create a flowchart representing the process of photosynthesis.")
#' create_mermaid_diagram(prompt = prompt)
#'
#' # specify chart type and styles
#' create_mermaid_diagram(prompt = prompt, chart_type = "flowchart", chart_styles = "Make the chart colorful.")
#' }
create_mermaid_diagram <- function(
  chat_agent = NULL,
  prompt = NULL,
  ...
) {

  # chat_agent
  if (is.null(chat_agent)) chat_agent <- mermaid_agent()
  check_chat(chat_agent)

  # prompt
  if (is.null(prompt)) prompt <- prompt_mermaid_user(...)

  # response
  resp <- chat_agent$chat(prompt)

  # code
  mermaid_code <- extract_code(resp, lang = "mermaid")

  # print
  cat(mermaid_code)

  # return
  return(mermaid_code)

}

================
File: R/models.R
================
#  ------------------------------------------------------------------------
#
# Title : Models
#    By : Jimmy Briggs
#  Date : 2025-03-06
#
#  ------------------------------------------------------------------------

#' AI Models
#'
#' @name models
#'
#' @description
#' Functions for listing and working with AI models across providers.
#'
#' Functions:
#'
#' - `get_openai_models()`: Get OpenAI models by calling the `/models` endpoint.
#'
#' - `get_anthropic_models()`: Get Anthropic models by calling the `/models` endpoint.
#'
#' @param api_key The API key to use for authentication. Will default to the respective platform's API key.
#'
#' @returns
#' Each function returns a character vector of model IDs.
NULL

# openai ----------------------------------------------------------------------------------------------------------

#' @rdname models
#' @export
#' @importFrom httr2 request req_auth_bearer_token req_perform resp_check_status resp_body_json
#' @importFrom dplyr bind_rows arrange desc select
#' @importFrom purrr pluck
get_openai_models <- function(api_key = get_openai_api_key()) {

  base_url <- get_api_url("openai", "models")

  req <- httr2::request(base_url) |>
    httr2::req_auth_bearer_token(api_key)

  resp <- httr2::req_perform(req)

  httr2::resp_check_status(resp)

  resp_json <- httr2::resp_body_json(resp)

  resp_data <- resp_json |>
    purrr::pluck("data") |>
    dplyr::bind_rows() |>
    dplyr::arrange(dplyr::desc(.data$created))

  resp_data |> purrr::pluck("id")

}

#' @rdname models
#' @export
#' @importFrom httr2 request req_headers req_perform resp_check_status resp_body_json
#' @importFrom dplyr bind_rows arrange desc select mutate arrange
#' @importFrom lubridate as_date
#' @importFrom tibble deframe
get_anthropic_models <- function(api_key = get_anthropic_api_key()) {

  base_url <- get_api_url("anthropic", "models")

  req <- httr2::request(base_url) |>
    httr2::req_headers(
      `X-API-KEY` = api_key,
      `Anthropic-Version` = "2023-06-01"
    )

  resp <- httr2::req_perform(req)
  httr2::resp_check_status(resp)

  resp_json <- httr2::resp_body_json(resp)

  resp_data <- resp_json |>
    purrr::pluck("data") |>
    dplyr::bind_rows() |>
    dplyr::mutate(created_at = lubridate::as_date(.data$created_at)) |>
    dplyr::arrange(dplyr::desc(.data$created_at))

  resp_data |>
    dplyr::select("id", "display_name") |>
    tibble::deframe()

}

================
File: R/noclocksai-package.R
================
#  ------------------------------------------------------------------------
#
# Title : Pacakge
#    By : Jimmy Briggs
#  Date : 2025-03-14
#
#  ------------------------------------------------------------------------

# docs --------------------------------------------------------------------

#' @keywords internal
"_PACKAGE"

## usethis namespace: start
#' @import rlang
## usethis namespace: end
NULL


# globals ---------------------------------------------------------------------------------------------------------

utils::globalVariables(
  c(

  )
)

# env ---------------------------------------------------------------------

.pkg_env <- rlang::new_environment()
.pkg_env$pkg_name <- "noclocksai"
.pkg_env$pkg_version <- utils::packageVersion("noclocksai")
# .pkg_env$pkg_config_file <- noclocksai:::cfg

================
File: R/openai.R
================
#
# #  ------------------------------------------------------------------------
# #
# # Title : OpenAI
# #    By : Jimmy Briggs
# #  Date : 2025-03-17
# #
# #  ------------------------------------------------------------------------
#
#
# # responses -------------------------------------------------------------------------------------------------------
#
#
# # Load necessary library
# library(httr2)
#
# # example with custom instructions
# req <- httr2::request("https://api.openai.com/v1/responses") |>
#   httr2::req_method("POST") |>
#   httr2::req_headers(
#     "Content-Type" = "application/json"
#   ) |>
#   httr2::req_auth_bearer_token(Sys.getenv("OPENAI_API_KEY")) |>
#   httr2::req_body_json(
#     list(
#       model = "gpt-4o",
#       instructions = "Talk like a pirate.",
#       input = "Are semicolons optional in JavaScript?"
#     )
#   )
#
# resp <- req |> httr2::req_perform()
# resp_json <- resp |> httr2::resp_body_json()
#
# # example with web search tool call
# req <- httr2::request("https://api.openai.com/v1/responses") |>
#   httr2::req_method("POST") |>
#   httr2::req_headers(
#     "Content-Type" = "application/json"
#   ) |>
#   httr2::req_auth_bearer_token(Sys.getenv("OPENAI_API_KEY")) |>
#   httr2::req_body_json(
#     list(
#       model = "gpt-4o",
#       tools = list(
#         list(
#           type = "web_search_preview"
#         )
#       ),
#       input = "what was a positive news story from today?"
#     )
#   )
#
# resp <- httr2::req_perform(req)
# resp_json <- resp |> httr2::resp_body_json()
#
# # example with function call
# httr2::request("https://api.openai.com/v1/responses") |>
#   httr2::req_method("POST") |>
#   httr2::req_headers(
#     "Content-Type" = "application/json"
#   ) |>
#   httr2::req_auth_bearer_token(Sys.getenv("OPENAI_API_KEY")) |>
#   httr2::req_body_json(
#     list(
#       model = "gpt-4o",
#       input = "What is the weather like in Paris today?",
#       tools = list(
#         list(
#           type = "function",
#           name = "get_weather",
#           description = "Get current temperature for a given location.",
#           parameters = list(
#             type = "object",
#             properties = list(
#               location = list(
#                 type = "string",
#                 description = "City and country e.g. Bogotá, Colombia"
#               )
#             ),
#             required = c("location"),
#             additionalProperties = FALSE
#           )
#         )
#       )
#     )
#   ) |>
#   httr2::req_perform() |>
#   httr2::resp_body_json()
#
#
#
# # Define the function
# openai_create_response <- function(
#     input,
#     model = "o1",
#     include = NULL,
#     instructions = NULL,
#     max_tokens = NULL,
#     metadata = NULL,
#     parallel_tool_calls = NULL,
#     reasoning = NULL,
#     store = NULL,
#     stream = NULL,
#     temperature = NULL,
#     text = list(type = "text"),
#     tool_choice = NULL,
#     tools = NULL,
#     top_p = NULL,
#     truncation = NULL,
#     user = NULL,
#     api_key = Sys.getenv("OPENAI_API_KEY")
# ) {
#
#   # Base URL for the API endpoint
#   base_url <- "https://api.openai.com/v1/responses"
#
#   # Validate API key
#   if (is.null(api_key) || api_key == "") {
#     stop("API key is missing. Set it as an environment variable 'OPENAI_API_KEY'.")
#   }
#
#   # Construct the request body
#   body <- list(
#     input = input,
#     model = model,
#     include = include,
#     instructions = instructions,
#     max_tokens = max_tokens,
#     metadata = metadata,
#     parallel_tool_calls = parallel_tool_calls,
#     reasoning = reasoning,
#     store = store,
#     stream = stream,
#     temperature = temperature,
#     text = text,
#     tool_choice = tool_choice,
#     tools = tools,
#     top_p = top_p,
#     truncation = truncation,
#     user = user
#   )
#
#   # Remove any NULL values from the body
#   body <- body[!sapply(body, is.null)]
#
#   # Create and send the request
#   req <- request(base_url) |>
#     req_headers(
#       "Content-Type"  = "application/json"
#     ) |>
#     req_auth_bearer_token(api_key) |>
#     req_body_json(list(
#       model = model,
#       input = input
#     ))
#
#   response <- req |> req_perform()
#
#   # Parse and return the response
#   resp_body_json(response)
# }
#
# # Example usage:
# # Ensure you have set your API key: Sys.setenv(OPENAI_API_KEY="your_api_key_here")
# result <- openai_create_response(input="Hello!", model="gpt-4o", max_tokens=100)
# # print(result)

================
File: R/options.R
================
#  ------------------------------------------------------------------------
#
# Title : Options
#    By : Jimmy Briggs
#  Date : 2025-03-20
#
#  ------------------------------------------------------------------------

#' Options used by `noclocksai`
#'
#' @description
#' The `noclocksai` package makes use of several options to control its behavior.
#'
#' @section Models:
#'
#' `noclocksai` uses the option `noclocksai.chat` to configure which model powers the

================
File: R/parallel.R
================
#  ------------------------------------------------------------------------
#
# Title : Parallel Processing
#    By : Jimmy Briggs
#  Date : 2025-03-12
#
#  ------------------------------------------------------------------------

setup_parallel_processing <- function(workers = NULL, strategy = future::multisession) {

  if (is.null(workers)) workers <- max(1, parallel::detectCores() - 1)

  plan <- future::plan(strategy, workers = workers)

  cli::cli_alert_success(
    "Parallel processing initialized with {.field {workers}} workers."
  )

  invisible(plan)

}

================
File: R/pkgdown.R
================
generate_pkgdown_reference <- function(
    pkg_path = ".",
    output_file = "_pkgdown.yml",
    model = "gpt-4o",
    update_existing = TRUE,
    api_key = get_openai_api_key()
) {

  pkg_name <- basename(normalizePath(pkg_path))
  pkg_namespace <- tryCatch({
    pkgload::load_all(pkg_path, quiet = TRUE)
    getNamespace(pkg_name)
  }, error = function(e) {
    cli::cli_abort("Unable to load the package namespace: {e$message}")
  })

  # get exported functions
  exported_functions <- getNamespaceExports(pkg_namespace)

  # get function docs
  function_docs <- purrr::map(
    exported_functions,
    function(func) {
      tryCatch({
        help_text <- utils::capture.output(utils::help(func, package = as.character(pkg_name)))
        paste(help_text, collapse = "\n")
      }, error = function(e) {
        cli::cli_alert_warning("Unable to get help for function: {func}")
        paste(func, ": No documentation available")
      })
    }
  ) |>
    rlang::set_names(exported_functions)

  pkgdown_path <- file.path(pkg_path, "_pkgdown.yml")
  existing_yaml <- NULL
  if (file.exists(pkgdown_path) && update_existing) {
    existing_yaml <- yaml::read_yaml(pkgdown_path)
  }

  pkg_funcs_txt <- paste(
    "- ",
    exported_functions,
    ": ",
    function_docs,
    sep = ""
  ) |>
    paste(collapse = "\n")

  existing_yaml_txt <- yaml::as.yaml(existing_yaml)

  sys_prompt <- prompt_pkgdown_sys()
  user_prompt <- prompt_pkgdown_user(pkg_name, pkg_funcs_txt, existing_yaml_txt)

  chat <- ellmer::chat_openai(
    model = model,
    system_prompt = sys_prompt
  )

  resp <- chat$chat(user_prompt)
  resp_yaml <- extract_code(resp, "yaml")

  if (is.null(resp_yaml)) { return(NULL) }

  # get existing yaml, remove reference section if it exists, and add new yaml reference section
  new_yaml <- yaml::as.yaml(
    yaml::yaml.load(existing_yaml_txt)[!names(yaml::yaml.load(existing_yaml_txt)) %in% "reference"]
  ) |>
    paste(collapse = "\n") |>
    paste(resp_yaml, collapse = "\n")

  # write new yaml to file
  fileConn <- file(pkgdown_path)
  writeLines(new_yaml, fileConn)
  close(fileConn)

  cli::cli_alert_success("Successfully updated {.path {pkgdown_path}} with new reference section.")

}

================
File: R/prompts.R
================
#  ------------------------------------------------------------------------
#
# Title : Prompts
#    By : Jimmy Briggs
#  Date : 2025-02-28
#
#  ------------------------------------------------------------------------

#' Prompts
#'
#' @name prompts
#'
#' @description
#' A collection of functions for generating prompts.
#'
#' There are functions for generating system prompts and user prompts.
#'
#' `noclocksai` comes with various prompt templates included that can be
#' found under the package's installed `/prompts/` directory or retrieved
#' directly via [pkg_sys_prompt()].
#'
#' @section Prompts:
#'
#' Default Prompt:
#'
#' - `prompt_default_sys()`: Generate the default system prompt for the chat session.
#'
#' Execute R Code Prompts:
#'
#' - `prompt_r_sys()`: Generate the system prompt for executing R code.
#' - `prompt_r_user()`: Generate the user prompt for executing R code.
#'
#' Roxygen Prompts:
#'
#' - `prompt_roxygen_sys()`: Generate the system prompt for Roxygen documentation.
#' - `prompt_roxygen_user()`: Generate the user prompt for Roxygen documentation.
#'
#' Exploratory Data Analysis (EDA) Prompts:
#'
#' - `prompt_eda_sys()`: Generate the system prompt for exploratory data analysis.
#' - `prompt_eda_user()`: Generate the user prompt for exploratory data analysis.
#'
#' Regular Expression (regex) Prompts:
#'
#' - `prompt_regex_sys()`: Generate the system prompt for regular expressions.
#' - `prompt_regex_user()`: Generate the user prompt for regular expressions.
#'
#' Google Maps Prompts:
#'
#' - `prompt_gmaps_sys()`: Generate the system prompt for Google Maps.
#' - `prompt_gmaps_user()`: Generate the user prompt for Google Maps.
#'
#' Database Prompts:
#'
#' - `prompt_db_sys()`: Generate the system prompt for database interaction.
#' - `prompt_db_user()`: Generate the user prompt for database interaction.
#'
#' Synthetic Data Prompts:
#'
#' - `prompt_synthetic_sys()`: Generate the system prompt for synthetic data generation.
#' - `prompt_synthetic_user()`: Generate the user prompt for synthetic data generation.
#'
#' `pkgdown` Prompts:
#'
#' - `prompt_pkgdown_sys()`: Generate the system prompt for the package documentation.
#' - `prompt_pkgdown_user()`: Generate the user prompt for the package documentation.
#'
#' Mermaid Prompts:
#'
#' - `prompt_mermaid_sys()`: Generate the system prompt for a Mermaid diagram.
#' - `prompt_mermaid_user()`: Generate the user prompt for a Mermaid diagram.
#'
#' @param ... Additional arguments passed to the template as data.
#' @param pkg_name,pkg_funcs,existing_yaml Variables passed to the `prompt_pkgdown_user()` function.
#' @param code The R code to be executed for `prompt_r_user()`.
#' @param context The context for the Mermaid diagram for `prompt_mermaid_user()`.
#'
#' @returns
#' All prompt functions return a character string representing the (interpolated) prompt.
#'
#' @seealso [ellmer::interpolate_file()], [pkg_sys_prompt()]
NULL

#' @rdname prompts
#' @export
#' @importFrom ellmer interpolate_file
prompt_default_sys <- function(...) {
  ellmer::interpolate_file(path = pkg_sys("prompts/default/system.prompt.md"))
}

#' @rdname prompts
#' @export
#' @importFrom ellmer interpolate_file
prompt_r_sys <- function() {
  ellmer::interpolate_file(path = pkg_sys("prompts/execute_r_code/system.prompt.md"))
}

#' @rdname prompts
#' @export
#' @importFrom ellmer interpolate_file
prompt_r_user <- function(code) {
  ellmer::interpolate_file(path = pkg_sys("prompts/execute_r_code/user.prompt.md"), code = code)
}

#' @rdname prompts
#' @export
#' @importFrom ellmer interpolate_file
prompt_mermaid_sys <- function() {
  ellmer::interpolate_file(path = pkg_sys("prompts/mermaid/system.prompt.md"))
}

#' @rdname prompts
#' @export
#' @importFrom ellmer interpolate_file
#' @importFrom purrr flatten_chr
prompt_mermaid_user <- function(context = NULL, code = NULL, chart_type = NULL, chart_styles = NULL, ...) {

  if (is.null(context) && is.null(code)) {
    cli::cli_abort("One of {.arg context} or {.arg code} must be provided.")
  }

  if (!is.null(context)) {
    context <- paste(context, collapse = "\n")
  }

  if (!is.null(code)) {
    code <- paste(code, collapse = "\n")
  }

  dots <- list(...)

  if (length(dots) > 0) {
    additional_context <- dots |> purrr::flatten_chr() |> paste(collapse = ", ")
  } else {
    additional_context <- NULL
  }

  # convert NULLs to NAs
  context <- ifelse(is.null(context), NA_character_, context)
  code <- ifelse(is.null(code), NA_character_, code)
  chart_type <- ifelse(is.null(chart_type), NA_character_, chart_type)
  chart_styles <- ifelse(is.null(chart_styles), NA_character_, chart_styles)
  additional_context <- ifelse(is.null(additional_context), NA_character_, additional_context)

  ellmer::interpolate_file(
    path = pkg_sys("prompts/mermaid/user.prompt.md"),
    context = context,
    code = code,
    chart_type = chart_type,
    chart_styles = chart_styles,
    additional_context = additional_context
  )

}

prompt_enhance_markdown_user <- function(markdown) {

  ellmer::interpolate_file(
    path = pkg_sys("prompts/enhance_markdown/user.prompt.md"),
    markdown = markdown
  )

}

#' @rdname prompts
#' @export
#' @importFrom ellmer interpolate_file
prompt_pkgdown_sys <- function() {
  ellmer::interpolate_file(path = pkg_sys("prompts/pkgdown.system.prompt.md"))
}

#' @rdname prompts
#' @export
#' @importFrom ellmer interpolate_file
prompt_pkgdown_user <- function(pkg_name, pkg_funcs, existing_yaml) {
  ellmer::interpolate_file(
    path = pkg_sys("prompts/pkgdown.user.prompt.md"),
    pkg_name = pkg_name,
    pkg_funcs = pkg_funcs,
    existing_yaml = existing_yaml
  )
}

prompt_document_dataset_sys <- function() {
  ellmer::interpolate_file(path = pkg_sys("prompts/document_dataset/system.prompt.md"))
}

prompt_document_dataset_user <- function(data) {
  check_data_frame(data)
  ellmer::interpolate_file(path = pkg_sys("prompts/document_dataset/user.prompt.md"), data = data)
}

prompt_eda_sys <- function() {
  ellmer::interpolate_file(path = pkg_sys("prompts/eda/system.prompt.md"))
}

prompt_eda_user <- function(data) {
  check_data_frame(data)
  ellmer::interpolate_file(path = pkg_sys("prompts/eda/user.prompt.md"), data = data)
}

================
File: R/store.R
================
#'
#' #  ------------------------------------------------------------------------
#' #
#' # Title : Vector Store
#' #    By : Jimmy Briggs
#' #  Date : 2025-03-15
#' #
#' #  ------------------------------------------------------------------------
#'
#'
#' # class -----------------------------------------------------------------------------------------------------------
#'
#' #' @export
#' #' @importFrom S7 new_class class_function class_data.frame
#' VectorStore <- S7::new_class(
#'   name = "VectorStore",
#'   properties = list(
#'     embed = S7::class_function,
#'     schema = S7::class_data.frame
#'   ),
#'   abstract = TRUE
#' )
#'
#' #' @export
#' #' @importFrom S7 new_class
#' PgVectorStore <- S7::new_class(
#'   name = "PgVectorStore",
#'   parent = "VectorStore",
#'   properties = list(
#'     .conn = method::getClass("DBIConnection"),
#'     .pool = S7::class_environment
#'   )
#' )

================
File: R/templates.R
================
#  ------------------------------------------------------------------------
#
# Title : Templates
#    By : Jimmy Briggs
#  Date : 2025-02-28
#
#  ------------------------------------------------------------------------

render_template <- function(template_name, data) {

  template_path <- system.file(
    paste0("prompts/", template_name, "user.prompt.md"),
    package = "noclocksai"
  )

  template <- paste(
    readLines(
      template_path,
      encoding = "UTF-8",
      warn = FALSE
    ),
    collapse = "\n"
  )

  # determine if the template has any variables
  template_variables <- extract_template_variables(template)

  if (length(template_variables$variables) > 0) {
    for (variable in template_variables$variables) {
      if (!exists(variable, where = data)) {
        if (!exists(paste0("has_", variable), where = data)) {
          data[[paste0("has_", variable)]] <- FALSE
        }
      }
    }
  }

  whisker::whisker.render(
    template,
    data
  )

}

extract_template_variables <- function(template) {

  variables <- stringr::str_extract_all(template, "\\{\\{([a-z_]+)\\}\\}") |>
    purrr::map(stringr::str_replace_all, pattern = "\\{\\{", replacement = "") |>
    purrr::map(stringr::str_replace_all, pattern = "\\}\\}", replacement = "") |>
    unlist() |>
    unique()

  has_variables <- stringr::str_extract_all(template, "\\{\\{#([a-z_]+)\\}\\}") |>
    purrr::map(stringr::str_replace_all, pattern = "\\{\\{#", replacement = "") |>
    purrr::map(stringr::str_replace_all, pattern = "\\}\\}", replacement = "") |>
    unlist() |>
    unique()

  list(
    variables = variables,
    has_variables = has_variables
  )

}

================
File: R/tools.R
================
#  ------------------------------------------------------------------------
#
# Title : Custom Tools
#    By : Jimmy Briggs
#  Date : 2025-03-09
#
#  ------------------------------------------------------------------------


# registration ----------------------------------------------------------------------------------------------------

#' Tool Registration
#'
#' @description
#' Register custom, function calling tools to the chat session.
#'
#' - `register_tool()`: Register a single tool.
#' - `register_tools()`: Register multiple tools.
#'
#' @param chat An [ellmer::chat_openai()] object.
#' @param tool An [ellmer::tool()] object.
#' @param tools A list of [ellmer::tool()] objects.
#'
#' @returns
#' While these functions are used for there side-effects (registering tools to the chat session), they do
#' invisibly return the chat object.
#'
#' @export
#'
#' @importFrom cli cli_alert_success
#'
#' @examples
#' \dontrun{
#' chat <- initialize_chat()
#' register_tool(chat, tool_gmaps_places_search())
#' register_tools(chat, list(tool_gmaps_geocode_address(), tool_hunter_get_email_address()))
#' }
register_tool <- function(chat, tool, use_cache = TRUE, cache = NULL) {
  check_chat(chat)
  check_tool(tool)
  chat$register_tool(tool)
  cli::cli_alert_success("Successfully registered tool: {.field {tool@name}}")
  invisible(chat)
}

#' @rdname register_tool
#' @export
#' @importFrom cli cli_alert_success
register_tools <- function(chat, tools) {
  check_chat(chat)
  for (tool in tools) {
    check_tool(tool)
    register_tool(chat, tool)
  }
  cli::cli_alert_success("Successfully registered {.field {length(tools)}} tools.")
  invisible(chat)
}

# tools -----------------------------------------------------------------------------------------------------------

#' Custom Tools
#'
#' @name tools
#'
#' @description
#' Functions that create custom [ellmer::tool()] definitions.
#'
#' Tool Functions:
#'
#' - `tool_extract_code()`: Tool that extracts code blocks from text. Wraps the [extract_code()] function.
#'
#' @param cache Logical. If `TRUE`, the function will cache the results of the tool call using [memoise::memoise()].
#'   Default is `FALSE`.
#'
#' @returns
#' Each function returns an [ellmer::tool()] definition.
NULL

tool_current_time <- function(tz = NULL) {

  func <- function(tz = tz) {
    if (is.null(tz)) tz <- Sys.timezone()
    format(Sys.time(), tz = tz, usetz = TRUE)
  }

  ellmer::tool(
    .name = "get_current_time",
    .description = "Get the current time. If no timezone is provided, the system timezone should be used.",
    .fun = func,
    tz = ellmer::type_string("Timezone to use for the current time.", required = FALSE)
  )

}

tool_query_db <- function() {


}

#' @rdname tools
#' @export
#' @importFrom ellmer tool
#' @importFrom purrr partial
#' @importFrom memoise memoise
#' @importFrom rlang inject
tool_extract_code <- function(cache = FALSE) {

  func <- purrr::partial(extract_code, print = FALSE)
  if (cache) func <- memoise::memoise(func)

  rlang::inject(
    ellmer::tool(
      .fun = func,
      .description = "Extracts code blocks from text",
      .name = "extract_code",
      !!!.extract_code_types
    )
  )

}

execute_r_code <- function(code) {

  tryCatch({
    expr = {
      eval(parse(text = code))
      cli::cli_alert_success("R Code executed successfully.")
    }
  }, error = function(e) {
    cli::cli_alert_danger("Error executing R code: {e$message}")
    return(character(0))
  })

}

#' @rdname tools
#' @export
tool_execute_r_code <- function() {

  func <- execute_r_code

  ellmer::tool(
    .name = "execute_r_code",
    .description = "Executes R code and returns the result.",
    .fun = func,
    code = ellmer::type_string("R code to execute.", required = TRUE)
  )

}


# database --------------------------------------------------------------------------------------------------------

query_db <- function(conn, query) {

  check_db_conn(conn)
  if (inherits(conn, "Pool")) {
    pool <- conn
    conn <- pool::poolCheckout(conn)
    withr::defer(pool::poolReturn(conn))
  }

  tryCatch({
    result <- DBI::dbGetQuery(conn, query)
    return(as.data.frame(result))
  }, error = function(e) {
    cli::cli_alert_danger("Error executing query: {e$message}")
    return(character(0))
  })

}

#' @rdname tools
#' @export
tool_query_db <- function(conn) {

  check_db_conn(conn)
  func <- purrr::partial(query_db, conn = conn)

  ellmer::tool(
    .name = "query_db",
    .description = "Executes a SQL query on the database and returns the result.",
    .fun = func,
    query = ellmer::type_string("SQL query to execute.", required = TRUE)
  )

}

# EDA -------------------------------------------------------------------------------------------------------------

detect_anomalies <- function(data, column_name = NULL) {

  check_tibble(data)

  # Check if column_name is provided
  if (is.null(column_name)) {
    # Run anomaly detection on all numeric columns
    results <- data |>
      dplyr::select(tidyselect::where(is.numeric)) |>
      purrr::map(~ {
        iqr <- stats::IQR(.x, na.rm = TRUE)
        q3 <- stats::quantile(.x, 0.75, na.rm = TRUE)
        outliers <- which(.x > q3 + (iqr * 1.5))
        list(
          outliers = outliers,
          values = .x[outliers],
          severity = length(outliers) / length(.x)
        )
      }) |>
      purrr::keep(~ length(.x$outliers) > 0)
    return(results)
  } else {

    check_col_names(data, column_name)
    values <- data[[column_name]]
    if (!is.numeric(values)) {
      return(paste("Column", column_name, "is not numeric"))
    }
    # Simple IQR-based outlier detection
    iqr <- stats::IQR(values, na.rm = TRUE)
    q3 <- stats::quantile(values, 0.75, na.rm = TRUE)
    outliers <- which(values > q3 + (iqr * 1.5))
    return(
      list(
        outliers = outliers,
        values = values[outliers],
        severity = length(outliers) / length(values)
      )
    )
  }
}

tool_anomaly_detection <- function(data) {

  check_tibble(data)

  func <- purrr::partial(detect_anomalies, data = data)

  ellmer::tool(
    .name = "detect_anomalies",
    .description = "Detects anomalies in the dataset using IQR method",
    .fun = func,
    column_name = type_string("Optional column name to analyze", required = FALSE)
  )
}

correlate_with_anomalies <- function(data, column_name, anomaly_indices) {

  check_tibble(data)
  check_col_names(data, column_name)

  # Check correlations with other variables
  correlations <- data |>
    dplyr::select(tidyselect::where(is.numeric)) |>
    purrr::map_dbl(~ stats::cor(.x, data[[column_name]], use = "complete.obs"))

  # Compare distributions
  normal_indices <- setdiff(1:nrow(data), anomaly_indices)

  comparison <- data |>
    dplyr::select(tidyselect::where(is.numeric)) |>
    purrr::map(~ {
      if (length(anomaly_indices) > 0) {
        list(
          anomaly_mean = mean(.x[anomaly_indices], na.rm = TRUE),
          normal_mean = mean(.x[normal_indices], na.rm = TRUE),
          diff_percent = (mean(.x[anomaly_indices], na.rm = TRUE) /
                            mean(.x[normal_indices], na.rm = TRUE) - 1) * 100
        )
      } else {
        list(
          anomaly_mean = NA,
          normal_mean = mean(.x, na.rm = TRUE),
          diff_percent = NA
        )
      }
    })

  return(
    list(
      correlations = sort(correlations, decreasing = TRUE),
      comparison = comparison
    )
  )
}

tool_correlate_with_anomalies <- function(data) {

  func <- purrr::partial(correlate_with_anomalies, data = data)

  ellmer::tool(
    .name = "correlate_with_anomalies",
    .description = "Analyzes correlations and differences between anomalies and normal data",
    column_name = ellmer::type_string("Column name with anomalies"),
    anomaly_indices = ellmer::type_array(
      items = ellmer::type_integer(
        description = "Indices of anomalous rows",
        required = TRUE
      )
    )
  )
}

# google maps -----------------------------------------------------------------------------------------------------

#' @rdname tools
#' @export
#' @importFrom ellmer tool
#' @importFrom purrr partial
#' @importFrom memoise memoise
tool_gmaps_geocode_address <- function(use_cache = TRUE, cache = NULL) {

  func <- purrr::partial(gmaps_geocode_address, api_key = get_gmaps_api_key())
  if (use_cache) {
    if (is.null(cache)) cache <- cachem::cache_mem(max_size = 1024 * 1024^2)
    func <- memoise::memoise(f = func, cache = cache, omit_args = c("api_key"))
  }

  rlang::inject(
    ellmer::tool(
      .name = "gmaps_geocode_address",
      .description = paste0(
        "Geocode an address using the Google Maps Geocoding API.\n",
        "This tool returns the formatted address, latitude, longitude, place ID, and place types."
      ),
      .fun = func,
      !!!.gmaps_geocode_address_types
    )
  )

}

#' @rdname tools
#' @export
#' @importFrom ellmer tool
#' @importFrom purrr partial
#' @importFrom memoise memoise
#' @importFrom cachem cache_mem
tool_gmaps_places_search <- function(use_cache = TRUE, cache = NULL) {

  func <- purrr::partial(gmaps_places_search, api_key = get_gmaps_api_key())

  if (use_cache) {
    if (is.null(cache)) cache <- cachem::cache_mem(max_size = 1024 * 1024^2)
    func <- memoise::memoise(f = func, cache = cache, omit_args = c("api_key"))
  }

  rlang::inject(
    ellmer::tool(
      .name = "gmaps_places_search",
      .description = paste0(
        "Search via the Google Maps Places (New) API to find information about a place.\n",
        "This tool queries the Places Text Search API using a query and address.\n",
        "The response back will be a parsed list of the results."
      ),
      .fun = func,
      !!!.gmaps_places_search_types
    )
  )

}


#' #' @rdname tools
#' #' @export
#' tool_mermaid_diagram <- function() {
#'
#'   ellmer::tool(
#'     .name = "mermaid_diagram",
#'     .description = paste0(
#'       "Generates a mermaid diagram from a text description.\n",
#'       "This tool uses the mermaid.js library to generate diagrams from text descriptions.\n",
#'       "Should prioritize generating graph and flowchart diagrams.\n",
#'       "The output should contain a markdown formatted code block for the diagram."
#'     ),
#'     .fun =
#'
#' }


# internal custom types -------------------------------------------------------------------------------------------

#' @keywords internal
#' @noRd
#' @importFrom ellmer type_string type_object type_array type_number type_boolean
.extract_code_types <- list(
  text = ellmer::type_string("Text containing code block(s).", required = TRUE),
  lang = ellmer::type_string("Language of code block to extract (i.e. 'r', 'python', 'sql', etc.).", required = FALSE)
)

#' @keywords internal
#' @noRd
#' @importFrom ellmer type_string
.gmaps_geocode_address_types <- list(
  address = ellmer::type_string("The address to geocode.", required = TRUE)
)

#' @keywords internal
#' @noRd
#' @importFrom ellmer type_string type_number
.gmaps_places_search_types <- list(
  query = ellmer::type_string("The search query to find places.", required = TRUE),
  address = ellmer::type_string("The address to search for places near.", required = FALSE),
  radius = ellmer::type_number("The radius in meters to search for places near the address.", required = FALSE)
)

================
File: R/types.R
================
#  ------------------------------------------------------------------------
#
# Title : Custom Type Definitions
#    By : Jimmy Briggs
#  Date : 2025-03-09
#
#  ------------------------------------------------------------------------

#' Custom Type Definitions
#'
#' @name types
#'
#' @description
#' Functions for defining and maintaining various custom [ellmer::Type] definitions.
NULL

type_gmaps_response <- function() {

  ellmer::type_object(
    status = ellmer::type_string(description = "API Response Status Message", required = TRUE),
    error_message = ellmer::type_string(description = "API Response Error Message", required = FALSE)
  )

}

type_gmaps_geocode_response <- function() {

  ellmer::type_object(
    status = ellmer::type_string(description = "API Response Status Message", required = TRUE),
    error_message = ellmer::type_string(description = "API Response Error Message", required = FALSE),
    results = ellmer::type_array(
      description = "Google Maps Geocode API Response",
      required = TRUE,
      items = ellmer::type_object(
        .description = "Geocode Result",
        .required = TRUE,
        place_id = ellmer::type_string(description = "Google Maps Place ID", required = TRUE),
        formatted_address = ellmer::type_string(description = "Formatted Address", required = TRUE),
        geometry = ellmer::type_object(
          .description = "Geographic Coordinates",
          .required = TRUE,
          location = ellmer::type_object(
            .description = "Geographic Location",
            .required = TRUE,
            lat = ellmer::type_number(description = "Latitude", required = TRUE),
            lng = ellmer::type_number(description = "Longitude", required = TRUE)
          )
        ),
        address_components = ellmer::type_array(
          .description = "Address Components",
          .required = TRUE,
          items = ellmer::type_object(
            .description = "Address Component",
            .required = TRUE,
            long_name = ellmer::type_string(description = "Long Name", required = TRUE),
            short_name = ellmer::type_string(description = "Short Name", required = TRUE),
            types = ellmer::type_array(
              .description = "Address Component Types",
              .required = TRUE,
              items = ellmer::type_string(description = "Address Component Type", required = TRUE)
            )
          )
        )
      )
    )
  )

}

type_gmaps_places_search_response <- function() {
  ellmer::type_object(
    status = ellmer::type_string(description = "API Response Status Message", required = TRUE),
    error_message = ellmer::type_string(description = "API Response Error Message", required = FALSE),
    results = ellmer::type_array(
      description = "Places Search Results",
      required = TRUE,
      items = ellmer::type_object(
        .description = "Place Search Result",
        .required = TRUE,
        name = ellmer::type_string(description = "Place Name", required = TRUE),
        place_id = ellmer::type_string(description = "Google Maps Place ID", required = TRUE),
        formatted_address = ellmer::type_string(description = "Formatted Address", required = TRUE),
        geometry = ellmer::type_object(
          .description = "Geographic Coordinates",
          .required = TRUE,
          location = ellmer::type_object(
            .description = "Geographic Location",
            .required = TRUE,
            lat = ellmer::type_number(description = "Latitude", required = TRUE),
            lng = ellmer::type_number(description = "Longitude", required = TRUE)
          )
        ),
        rating = ellmer::type_number(description = "Place Rating", required = FALSE),
        types = ellmer::type_array(
          description = "Place Types",
          required = TRUE,
          items = ellmer::type_string(description = "Place Type", required = TRUE)
        )
      )
    )
  )
}

type_gmaps_place_details_response <- function() {
  ellmer::type_object(
    .description = "Google Maps Place Details API Response",
    .required = TRUE,
    status = ellmer::type_string(description = "API Response Status Message", required = TRUE),
    error_message = ellmer::type_string(description = "API Response Error Message", required = FALSE),
    result = ellmer::type_object(
      .description = "Place Details Result",
      .required = TRUE,
      name = ellmer::type_string(description = "Place Name", required = TRUE),
      place_id = ellmer::type_string(description = "Google Maps Place ID", required = TRUE),
      formatted_address = ellmer::type_string(description = "Formatted Address", required = TRUE),
      formatted_phone_number = ellmer::type_string(description = "Formatted Phone Number", required = FALSE),
      website = ellmer::type_string(description = "Website URL", required = FALSE),
      rating = ellmer::type_number(description = "Place Rating", required = FALSE),
      reviews = ellmer::type_array(
        description = "Place Reviews",
        required = FALSE,
        items = ellmer::type_object(
          .description = "Review",
          .required = TRUE,
          author_name = ellmer::type_string(description = "Author Name", required = TRUE),
          rating = ellmer::type_number(description = "Review Rating", required = TRUE),
          text = ellmer::type_string(description = "Review Text", required = TRUE),
          time = ellmer::type_number(description = "Review Timestamp", required = TRUE)
        )
      ),
      opening_hours = ellmer::type_object(
        .description = "Opening Hours",
        .required = FALSE,
        weekday_text = ellmer::type_array(
          description = "Weekday Text",
          required = TRUE,
          items = ellmer::type_string(description = "Day Hours Text", required = TRUE)
        ),
        open_now = ellmer::type_boolean(description = "Currently Open Status", required = TRUE)
      ),
      geometry = ellmer::type_object(
        .description = "Geographic Coordinates",
        .required = TRUE,
        location = ellmer::type_object(
          .description = "Geographic Location",
          .required = TRUE,
          lat = ellmer::type_number(description = "Latitude", required = TRUE),
          lng = ellmer::type_number(description = "Longitude", required = TRUE)
        )
      )
    )
  )
}

type_dataset_docs <- function() {

  ellmer::type_object(
    .description = "A roxygen2 skeleton for a dataset",
    .required = TRUE,
    title = ellmer::type_string(description = "Title of the dataset", required = TRUE),
    description = ellmer::type_string(description = "Description of the dataset", required = TRUE),
    format = ellmer::type_string(description = "Format of the dataset", required = TRUE),
    source = ellmer::type_string(description = "Source of the dataset", required = FALSE),
    url = ellmer::type_string(description = "URL of the dataset", required = FALSE),
    column_docs = ellmer::type_array(
      description = "Column documentation",
      required = TRUE,
      items = ellmer::type_object(
        .description = "Column documentation",
        .required = TRUE,
        name = ellmer::type_string(description = "Name of the column", required = TRUE),
        type = ellmer::type_string(description = "Type of the column", required = TRUE),
        description = ellmer::type_string(description = "Description of the column", required = TRUE)
      )
    ),
    examples = ellmer::type_array(
      description = "Examples of the dataset",
      required = FALSE,
      items = ellmer::type_string(description = "Example of the dataset", required = TRUE)
    )
  )

}

================
File: R/utils.R
================
#  ------------------------------------------------------------------------
#
# Title : General Utilities
#    By : Jimmy Briggs
#  Date : 2025-02-25
#
#  ------------------------------------------------------------------------



# environment -----------------------------------------------------------------------------------------------------

env_is_testing <- function() {
  Sys.getenv("TESTTHAT") == "true"
}

env_is_rstudio <- function() {
  Sys.getenv("RSTUDIO") == "true"
}

env_is_positron <- function() {
  Sys.getenv("POSITRON") == "true"
}

env_is_github <- function() {
  Sys.getenv("GITHUB_ACTIONS") == "true"
}

env_is_vscode <- function() {
  Sys.getenv("VSCODE_IPYNB_PATH") != ""
}


`%||%` <- function(x, y) if (is.null(x)) y else x


# lists -----------------------------------------------------------------------------------------------------------

view_list <- function(list, ...) {

  listviewer::jsonedit(list, ...)

}


# R code evaluation -----------------------------------------------------------------------------------------------



evaluate_r_code <- function(code, on_console_out, on_console_err, on_plot, on_dataframe) {

  cli::cli_alert_info("Running R Code...\n")
  cli::cli_alert_info("Code: {cat(code, '\n', sep = '')}")

  evaluate::evaluate(
    code,
    envir = globalenv(),
    stop_on_error = 1L,
    output_handler = evaluate::new_output_handler(
      text = function(value) {
        on_console_out(as_str(value))
      },
      graphics = function(recorded_plot) {
        plot <- recorded_plot_to_png(recorded_plot)
        on_plot(plot$mime, plot$content)
      },
      message = function(cond) {
        on_console_out(as_str(conditionMessage(cond), "\n"))
      },
      warning = function(cond) {
        on_console_out(as_str("Warning: ", conditionMessage(cond), "\n"))
      },
      error = function(cond) {
        on_console_out(as_str("Error: ", conditionMessage(cond), "\n"))
      },
      value = function(value) {
        if (is.data.frame(value)) {
          on_dataframe(value)
        } else {
          printed_str <- as_str(capture.output(print(value)))
          if (nchar(printed_str) > 0 && !grepl("\n$", printed_str)) {
            printed_str <- paste0(printed_str, "\n")
          }
          on_console_out(printed_str)
        }
      }
    )
  )
  invisible()
}

#' Save a recorded plot to base64 encoded PNG
#'
#' @param recorded_plot Recorded plot to save
#' @param ... Additional arguments passed to [png()]
#' @noRd
recorded_plot_to_png <- function(recorded_plot, ...) {
  plot_file <- tempfile(fileext = ".png")
  on.exit(if (plot_file != "" && file.exists(plot_file)) unlink(plot_file))

  png(plot_file, ...)
  tryCatch(
    {
      replayPlot(recorded_plot)
    },
    finally = {
      dev.off()
    }
  )

  # Convert the plot to base64
  plot_data <- base64enc::base64encode(plot_file)
  list(mime = "image/png", content = plot_data)
}


# encoding --------------------------------------------------------------------------------------------------------

encode_df <- function(df, max_rows = 100, show_end = 10) {
  if (nrow(df) == 0) {
    return(paste(collapse = "\n", capture.output(print(tibble::as.tibble(df)))))
  }
  if (nrow(df) <= max_rows) {
    return(df_to_json(df))
  }
  head_rows <- df[1:max_rows, ]
  tail_rows <- df[(nrow(df) - show_end + 1):nrow(df), ]
  paste(collapse = "\n", c(
    df_to_json(head_rows),
    sprintf("... %d rows omitted ...", nrow(df) - max_rows),
    df_to_json(tail_rows))
  )
}

df_to_json <- function(df) {
  jsonlite::toJSON(df, dataframe = "rows", na = "string")
}

# pkg_sys ---------------------------------------------------------------------------------------------------------

#' Package System File
#'
#' @rdname pkg_sys
#'
#' @description
#' Get the path to a system file within the package.
#'
#' Various other `pkg_sys_*` functions are available to help with specific file paths:
#'
#' - `pkg_sys_template()`: Get the path to a template file.
#' - `pkg_sys_prompt()`: Get the path to a prompt file.
#' - `pkg_sys_extdata()`: Get the path to an external data file.
#' - `pkg_sys_config()`: Get the path to a configuration file.
#' - `pkg_sys_database()`: Get the path to a database file.
#' - `pkg_sys_www()`: Get the path to a `www` (i.e. Shiny App Resource) file.
#'
#' @param ... Additional arguments passed to `system.file()`.
#'
#' @returns
#' A character string representing the path to the system file.
#'
#' @export
#'
#' @importFrom fs path
#'
#' @examples
#' # retrieve the path to the package configuration file
#' pkg_sys("config/config.yml")
#'
#' # or use the shorthand function dedicated for configs
#' pkg_sys_config("config.yml")
pkg_sys <- function(...) {
  system.file(..., package = "noclocksai")
}

#' @rdname pkg_sys
#' @export
pkg_sys_template <- function(...) {
  pkg_sys(fs::path("templates", ...))
}

#' @rdname pkg_sys
#' @export
pkg_sys_prompt <- function(...) {
  pkg_sys(fs::path("prompts", ...))
}

#' @rdname pkg_sys
#' @export
pkg_sys_extdata <- function(...) {
  pkg_sys(fs::path("extdata", ...))
}

#' @rdname pkg_sys
#' @export
pkg_sys_config <- function(...) {
  pkg_sys(fs::path("config", ...))
}

#' @rdname pkg_sys
#' @export
pkg_sys_database <- function(...) {
  pkg_sys(fs::path("db", ...))
}

#' @rdname pkg_sys
#' @export
pkg_sys_www <- function(...) {
  pkg_sys(fs::path("www", ...))
}

# regex patterns / extraction -------------------------------------------------------------------------------------

#' Get Regex Code Pattern
#'
#' @description
#' Get a regular expression pattern for extracting code blocks from a markdown string.
#'
#' For example, to extract R code from a string, you need a pattern to match the following:
#'
#' ````
#' ```R
#' # some R code
#' ```
#' ````
#'
#' This function returns a pattern that can be used to extract the code block from the string.
#'
#' In the above example with R code the pattern would be: `(?s)(?<=```(r|R)\n).*?(?=```)`.
#'
#' @param lang The language of the code block to extract. If left `NULL`, the pattern will match any language
#'   using a wildcard `.*?` to match the language name.
#'
#' @returns
#' A regular expression pattern for extracting code blocks from a markdown string.
#'
#' @export
#'
#' @importFrom glue glue
#'
#' @examples examples/ex_get_regex_code_pattern.R
get_regex_code_pattern <- function(lang = NULL) {

  if (is.null(lang)) return("(?s)(?<=```).*?(?=```)")

  lang_match <- paste0("(", tolower(lang), "|", toupper(lang), ")")

  glue::glue("(?s)(?<=```{lang_match}\\n).*?(?=```)")
}

#' Extract Code
#'
#' @description
#' Extract code blocks from a markdown string.
#'
#' This function extracts code blocks from a markdown string using a regular expression pattern.
#'
#' @param text A character string representing the text to extract code blocks from.
#'
#' @param lang The language of the code block to extract. If left `NULL`, the pattern will attempt to
#'   match any language.
#'
#' @param print Logical. If `TRUE`, the extracted code block content will be printed to the console.
#'   Defaults to `FALSE`.
#'
#' @returns
#' A character string representing the extracted code block content.
#'
#' @export
#'
#' @seealso [get_regex_code_pattern()] for more information on the regular expression pattern used to extract code blocks.
#'
#' @importFrom stringr str_extract
#' @importFrom cli cli_abort
#'
#' @examples examples/ex_extract_code.R
extract_code <- function(text, lang = NULL, print = FALSE) {

  pattern <- get_regex_code_pattern(lang)
  content <- stringr::str_extract(text, pattern)

  if (length(content) == 0) {
    cli::cli_abort("No code block content found in provided {.arg resp} argument.")
  }

  if (print) cat(content, sep = "\n")

  content
}

================
File: R/zzz.R
================
#  ------------------------------------------------------------------------
#
# Title : Package onLoad
#    By : Jimmy Briggs
#  Date : 2025-03-14
#
#  ------------------------------------------------------------------------

# onLoad ------------------------------------------------------------------

#' @keywords internal
#' @noRd
#' @importFrom rlang run_on_load
.onLoan <- function(libname, pkgname) {
  rlang::run_on_load()
}

# onAttach ----------------------------------------------------------------

#' @keywords internal
#' @noRd
.onAttach <- function(libname, pkgname) {
  packageStartupMessage("Welcome to the No Clocks AI package (https://github.com/noclocks/noclocksai/)!")
}

================
File: README.md
================
# noclocksai <img src="man/figures/logo.png" align="right" height="120" alt="" />


<!-- badges: start -->
[![Codecov test coverage](https://codecov.io/gh/noclocks/noclocksai/graph/badge.svg)](https://app.codecov.io/gh/noclocks/noclocksai)
<!-- badges: end -->

The goal of noclocksai is to ...

## Installation

You can install the development version of noclocksai like so:

``` r
# FILL THIS IN! HOW CAN PEOPLE INSTALL YOUR DEV PACKAGE?
```

## Example

This is a basic example which shows you how to solve a common problem:

``` r
library(noclocksai)
## basic example code
```

================
File: vignettes/.gitignore
================
*.html
*.R

================
File: vignettes/examples.Rmd
================
---
title: "Examples"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  out.width = "100%"
)

# library(noclocksai)
pkgload::load_all()

library(ellmer)
library(DiagrammeR)
```

```{r load_cached_resources, echo=FALSE, include=FALSE}
mermaid_vignette_resources <- qs2::qs_read(pkg_sys_extdata("vignettes/mermaid_vignette_resources.qs"))
mermaid_code <- mermaid_vignette_resources$mermaid_code
resp <- mermaid_vignette_resources$resp
mermaid_workflow_code <- mermaid_vignette_resources$mermaid_workflow_code
resp_workflow <- mermaid_vignette_resources$resp_workflow
```

## Example: Mermaid.js Diagram Generation

This example demonstrates how to use `noclocksai`'s features that build on top of the `ellmer`
package to generate a [Mermaid.js](https://mermaid-js.github.io/mermaid/#/) diagram based on a provided R code snippet. 
The `ellmer` package provides a simple interface to interact with the OpenAI API, allowing you to generate
the diagrams based on user-provided context or code snippets.

`noclocksai` comes with a set of pre-defined prompts for generating Mermaid.js diagrams, making it easy to
generate diagrams without having to write the prompts from scratch.

In this example the following steps will be taken:

1. Initialize a chat with OpenAI using the Mermaid.js system prompt.
2. Pass an example R code snippet to the chat.
3. Extract the generated Mermaid.js diagram code block from the response.
4. Render the Mermaid.js diagram using the extracted code block.

### Prompts

The `noclocksai` package provides two prompts for generating Mermaid.js diagrams. These prompts can be found in the package's `prompts/mermaid/` installed directory and retrieved via the `noclocksai::pkg_sys_prompt()` utility function or directly called using the `prompt_mermaid_sys()` and `prompt_mermaid_user()` functions.

Expand the following sections to view the Mermaid.js system and user prompts, respectively.

<br>

<details><summary>View [Mermaid.js System Prompt](../inst/prompts/mermaid/system.prompt.md)</summary><p>

````markdown

```{r child="../inst/prompts/mermaid/system.prompt.md"}
```

````

</p></details>

<br>

<details><summary>View [Mermaid.js User Prompt](../inst/prompts/mermaid/user.prompt.md)</summary><p>

````markdown

```{r child="../inst/prompts/mermaid/user.prompt.md"}
```

````

</p></details>

### Diagram Generation Workflow

The following code demonstrates how to generate a Mermaid.js diagram based on a provided R code snippet
using the `noclocksai` package:

```{r mermaid_diagram_generation_chat, eval=FALSE}
# initialize a chat with OpenAI using the mermaid.js system prompt
chat <- ellmer::chat_openai(
  system_prompt = prompt_mermaid_sys(),
  echo = TRUE,
  api_args = list(temperature = 0)
)

# example code to pass to chat
example <- "starwars |>
  group_by(species) |>
  summarise(
    n = n(),
    mass = mean(mass, na.rm = TRUE)
  ) |>
  filter(
    n > 1,
    mass > 50
  )"

# send the example code to the chat
resp <- chat$chat(prompt_mermaid_user(context = example))
```

The response from the chat will contain the generated Mermaid.js diagram code block:

```{r mermaid_diagram_generation_chat_output, echo=FALSE}
cat(resp, sep = "\n")
```

Now that the chat has been initialized and the example R code snippet has been passed to the chat,
we can extract the generated Mermaid.js diagram code block from the response using the
provided utility function `extract_code()`:

```{r extract_mermaid_diagram_code, eval=FALSE}
# extract mermaid diagram code block from response
mermaid_code <- extract_code(resp, lang = "mermaid", print = TRUE)
```

preview the extracted Mermaid.js diagram code block:

```{r extract_mermaid_diagram_code_output, echo=FALSE}
cat(mermaid_code, sep = "\n")
```

Then you can use this generated Mermaid.js code block to render a diagram for the example R code:

```{r render_mermaid_diagram, out.height="400px", fig.dim=c(6,4), fig.align="center", fig.cap="Mermaid.js Diagram for the Example R Code Snippet"}
# render the mermaid diagram
DiagrammeR::DiagrammeR(mermaid_code)
```

<br>

The generated Mermaid.js diagram should represent the flow of the provided R code snippet.

### Mermaid for this Workflow

Let's generate a diagram for the workflow defined above:

```{r mermaid_workflow, eval=FALSE}
workflow <- "
1. Initialize a chat with OpenAI using the mermaid.js system prompt
2. Pass an example R code snippet to the chat
3. Extract the generated Mermaid.js diagram code block from the response
4. Render the Mermaid.js diagram using the extracted code block
"

resp <- chat$chat(prompt_mermaid_user(context = workflow))
```

The response from the chat will contain the generated Mermaid.js diagram code block:

```{r mermaid_workflow_output, eval=FALSE}
cat(resp_workflow, sep = "\n")
```

Extract the generated Mermaid.js diagram code block:

```{r extract_mermaid_workflow_code, eval=FALSE}
# extract mermaid diagram code block from response
mermaid_workflow_code <- extract_code(resp, lang = "mermaid", print = TRUE)
```

preview the extracted Mermaid.js diagram code block:

```{r extract_mermaid_workflow_code_output, eval=FALSE}
cat(mermaid_workflow_code, sep = "\n")
```

Render the Mermaid.js diagram for this workflow:

```{r render_mermaid_workflow, out.height="400px", fig.dim=c(6,4), fig.align="center", fig.cap="Mermaid.js Diagram for the Workflow of Generating a Mermaid.js Diagram"}
# render the mermaid diagram
DiagrammeR::DiagrammeR(mermaid_workflow_code)
```

<br>

The generated Mermaid.js diagram should represent the workflow of generating a Mermaid.js diagram based on an R code snippet.

================
File: vignettes/noclocksai.Rmd
================
---
title: "Getting Started"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(noclocksai)
```



================================================================
End of Codebase
================================================================
